
/* eslint-disable no-template-curly-in-string, no-multi-assign */
const policies = globalThis.LavamoatPolicies = globalThis.LavamoatPolicies || {}
policies.node = {
  'primary': {
    'resources': {
      '@babel/code-frame': {
        'globals': {
          'console.warn': true,
          'process.emitWarning': true,
        },
        'packages': {
          '@babel/highlight': true,
        },
      },
      '@babel/generator': {
        'globals': {
          'console.error': true,
        },
        'packages': {
          '@babel/types': true,
          'jsesc': true,
          'source-map': true,
        },
      },
      '@babel/helper-function-name': {
        'packages': {
          '@babel/helper-get-function-arity': true,
          '@babel/template': true,
          '@babel/types': true,
        },
      },
      '@babel/helper-get-function-arity': {
        'packages': {
          '@babel/types': true,
        },
      },
      '@babel/helper-split-export-declaration': {
        'packages': {
          '@babel/types': true,
        },
      },
      '@babel/highlight': {
        'packages': {
          '@babel/helper-validator-identifier': true,
          'chalk': true,
          'js-tokens': true,
        },
      },
      '@babel/parser': {
        'globals': {
          'BigInt': true,
        },
      },
      '@babel/template': {
        'packages': {
          '@babel/code-frame': true,
          '@babel/parser': true,
          '@babel/types': true,
        },
      },
      '@babel/traverse': {
        'globals': {
          'console.log': true,
          'console.trace': true,
          'process.env.NODE_ENV': true,
        },
        'packages': {
          '@babel/code-frame': true,
          '@babel/generator': true,
          '@babel/helper-function-name': true,
          '@babel/helper-split-export-declaration': true,
          '@babel/parser': true,
          '@babel/types': true,
          'debug': true,
          'globals': true,
        },
      },
      '@babel/types': {
        'globals': {
          'console.trace': true,
          'process.env.BABEL_TYPES_8_BREAKING': true,
        },
        'packages': {
          '@babel/helper-validator-identifier': true,
          'lodash': true,
          'to-fast-properties': true,
        },
      },
      'JSONStream': {
        'globals': {
          'Buffer': true,
        },
        'packages': {
          'jsonparse': true,
          'through': true,
        },
      },
      'acorn': {
        'globals': {
          'BigInt': true,
          'define': true,
        },
      },
      'acorn-node': {
        'globals': {
          'BigInt': true,
        },
        'packages': {
          'acorn': true,
          'acorn-walk': true,
          'xtend': true,
        },
      },
      'acorn-walk': {
        'globals': {
          'define': true,
        },
      },
      'ansi-styles': {
        'packages': {
          'color-convert': true,
        },
      },
      'browser-pack': {
        'builtin': {
          'fs.readFileSync': true,
          'path.join': true,
          'path.relative': true,
        },
        'globals': {
          '__dirname': true,
          'process.cwd': true,
        },
        'packages': {
          'JSONStream': true,
          'combine-source-map': true,
          'defined': true,
          'safe-buffer': true,
          'through2': true,
          'umd': true,
        },
      },
      'browser-resolve': {
        'builtin': {
          'fs.readFile': true,
          'fs.readFileSync': true,
          'path': true,
        },
        'globals': {
          '__dirname': true,
          'process.platform': true,
        },
        'packages': {
          'resolve': true,
        },
      },
      'browserify': {
        'builtin': {
          'events.EventEmitter': true,
          'fs.realpath': true,
          'path.dirname': true,
          'path.join': true,
          'path.relative': true,
          'path.resolve': true,
          'path.sep': true,
        },
        'globals': {
          '__dirname': true,
          'process.cwd': true,
          'process.nextTick': true,
          'process.platform': true,
        },
        'packages': {
          'browser-pack': true,
          'browser-resolve': true,
          'cached-path-relative': true,
          'concat-stream': true,
          'defined': true,
          'deps-sort': true,
          'has': true,
          'htmlescape': true,
          'inherits': true,
          'insert-module-globals': true,
          'labeled-stream-splicer': true,
          'module-deps': true,
          'read-only-stream': true,
          'resolve': true,
          'shasum-object': true,
          'syntax-error': true,
          'through2': true,
          'xtend': true,
        },
      },
      'browserify-package-json': {
        'builtin': {
          'stream.PassThrough': true,
          'stream.Transform': true,
        },
      },
      'buffer-from': {
        'globals': {
          'Buffer': true,
        },
      },
      'cached-path-relative': {
        'builtin': {
          'path': true,
        },
        'globals': {
          'process.cwd': true,
        },
      },
      'chalk': {
        'globals': {
          'process.env.TERM': true,
          'process.platform': true,
        },
        'packages': {
          'ansi-styles': true,
          'escape-string-regexp': true,
          'supports-color': true,
        },
      },
      'clone': {
        'globals': {
          'Buffer': true,
        },
      },
      'clone-deep': {
        'packages': {
          'for-own': true,
          'is-plain-object': true,
          'kind-of': true,
          'lazy-cache': true,
          'shallow-clone': true,
        },
      },
      'color-convert': {
        'packages': {
          'color-name': true,
        },
      },
      'combine-source-map': {
        'builtin': {
          'path.dirname': true,
          'path.join': true,
        },
        'globals': {
          'process.platform': true,
        },
        'packages': {
          'convert-source-map': true,
          'inline-source-map': true,
          'lodash.memoize': true,
          'source-map': true,
        },
      },
      'concat-stream': {
        'globals': {
          'Buffer.concat': true,
          'Buffer.isBuffer': true,
        },
        'packages': {
          'buffer-from': true,
          'inherits': true,
          'readable-stream': true,
          'typedarray': true,
        },
      },
      'convert-source-map': {
        'builtin': {
          'fs.readFileSync': true,
          'path.join': true,
          'path.resolve': true,
        },
        'globals': {
          'Buffer': true,
        },
        'packages': {
          'safe-buffer': true,
        },
      },
      'core-util-is': {
        'globals': {
          'Buffer.isBuffer': true,
        },
      },
      'dash-ast': {
        'builtin': {
          'assert': true,
        },
      },
      'debug': {
        'builtin': {
          'tty.isatty': true,
          'util.deprecate': true,
          'util.format': true,
          'util.inspect': true,
        },
        'globals': {
          'console': true,
          'document': true,
          'localStorage': true,
          'navigator': true,
          'process': true,
        },
        'packages': {
          'ms': true,
          'supports-color': true,
        },
      },
      'deps-sort': {
        'packages': {
          'shasum-object': true,
          'through2': true,
        },
      },
      'detective': {
        'packages': {
          'acorn-node': true,
          'defined': true,
        },
      },
      'duplexer2': {
        'packages': {
          'readable-stream': true,
        },
      },
      'duplexify': {
        'globals': {
          'Buffer': true,
          'process.nextTick': true,
        },
        'packages': {
          'end-of-stream': true,
          'inherits': true,
          'readable-stream': true,
          'stream-shift': true,
        },
      },
      'end-of-stream': {
        'packages': {
          'once': true,
        },
      },
      'for-own': {
        'packages': {
          'for-in': true,
        },
      },
      'get-assigned-identifiers': {
        'builtin': {
          'assert.equal': true,
        },
      },
      'has': {
        'packages': {
          'function-bind': true,
        },
      },
      'has-flag': {
        'globals': {
          'process.argv': true,
        },
      },
      'inherits': {
        'builtin': {
          'util.inherits': true,
        },
      },
      'inline-source-map': {
        'globals': {
          'Buffer': true,
        },
        'packages': {
          'source-map': true,
        },
      },
      'insert-module-globals': {
        'builtin': {
          'path.dirname': true,
          'path.isAbsolute': true,
          'path.relative': true,
          'path.sep': true,
        },
        'globals': {
          'Buffer.concat': true,
          'Buffer.isBuffer': true,
        },
        'packages': {
          'acorn-node': true,
          'combine-source-map': true,
          'path-is-absolute': true,
          'through2': true,
          'undeclared-identifiers': true,
          'xtend': true,
        },
      },
      'is-core-module': {
        'globals': {
          'process.versions': true,
        },
        'packages': {
          'has': true,
        },
      },
      'is-plain-object': {
        'packages': {
          'isobject': true,
        },
      },
      'jsesc': {
        'globals': {
          'Buffer.isBuffer': true,
        },
      },
      'json-stable-stringify': {
        'packages': {
          'jsonify': true,
        },
      },
      'jsonparse': {
        'globals': {
          'Buffer': true,
        },
      },
      'kind-of': {
        'globals': {
          'Buffer': true,
        },
        'packages': {
          'is-buffer': true,
        },
      },
      'labeled-stream-splicer': {
        'packages': {
          'inherits': true,
          'stream-splicer': true,
        },
      },
      'lavamoat-browserify': {
        'builtin': {
          'assert': true,
          'fs.existsSync': true,
          'fs.mkdirSync': true,
          'fs.readFileSync': true,
          'fs.writeFile': true,
          'fs.writeFileSync': true,
          'path.dirname': true,
          'path.extname': true,
          'path.join': true,
          'path.relative': true,
          'path.resolve': true,
          'util.callbackify': true,
        },
        'globals': {
          '__MODULE_CONTENT__': true,
          '__dirname': true,
          'console.log': true,
          'console.warn': true,
          'process.cwd': true,
        },
        'packages': {
          'JSONStream': true,
          'clone': true,
          'combine-source-map': true,
          'concat-stream': true,
          'convert-source-map': true,
          'duplexify': true,
          'json-stable-stringify': true,
          'lavamoat-core': true,
          'merge-deep': true,
          'offset-sourcemap-lines': true,
          'readable-stream': true,
          'safe-buffer': true,
          'through2': true,
          'umd': true,
        },
      },
      'lavamoat-core': {
        'builtin': {
          'events': true,
          'fs.readFileSync': true,
          'module.createRequire': true,
          'module.createRequireFromPath': true,
          'path.extname': true,
          'path.join': true,
          'path.sep': true,
        },
        'globals': {
          '__dirname': true,
          'console.warn': true,
        },
        'packages': {
          'fromentries': true,
          'json-stable-stringify': true,
          'lavamoat-tofu': true,
          'merge-deep': true,
          'resolve': true,
        },
      },
      'lavamoat-tofu': {
        'globals': {
          'console.log': true,
        },
        'packages': {
          '@babel/parser': true,
          '@babel/traverse': true,
        },
      },
      'lazy-cache': {
        'globals': {
          'process.env.TRAVIS': true,
          'process.env.UNLAZY': true,
        },
      },
      'merge-deep': {
        'packages': {
          'arr-union': true,
          'clone-deep': true,
          'kind-of': true,
        },
      },
      'mixin-object': {
        'packages': {
          'for-in': true,
          'is-extendable': true,
        },
      },
      'module-deps': {
        'builtin': {
          'fs.createReadStream': true,
          'fs.readFile': true,
          'path.delimiter': true,
          'path.dirname': true,
          'path.join': true,
          'path.resolve': true,
        },
        'globals': {
          'process.cwd': true,
          'process.env.NODE_PATH': true,
          'process.nextTick': true,
          'process.platform': true,
          'setTimeout': true,
          'tr': true,
        },
        'packages': {
          'browser-resolve': true,
          'cached-path-relative': true,
          'concat-stream': true,
          'defined': true,
          'detective': true,
          'duplexer2': true,
          'inherits': true,
          'parents': true,
          'readable-stream': true,
          'resolve': true,
          'stream-combiner2': true,
          'through2': true,
          'xtend': true,
        },
      },
      'offset-sourcemap-lines': {
        'packages': {
          'source-map': true,
        },
      },
      'once': {
        'packages': {
          'wrappy': true,
        },
      },
      'package-json-versionify': {
        'packages': {
          'browserify-package-json': true,
        },
      },
      'parents': {
        'globals': {
          'process.cwd': true,
          'process.platform': true,
        },
        'packages': {
          'path-platform': true,
        },
      },
      'path-is-absolute': {
        'globals': {
          'process.platform': true,
        },
      },
      'path-parse': {
        'globals': {
          'process.platform': true,
        },
      },
      'path-platform': {
        'builtin': {
          'path': true,
          'util.isObject': true,
          'util.isString': true,
        },
        'globals': {
          'process.cwd': true,
          'process.env': true,
          'process.platform': true,
        },
      },
      'process-nextick-args': {
        'globals': {
          'process': true,
        },
      },
      'read-only-stream': {
        'packages': {
          'readable-stream': true,
        },
      },
      'readable-stream': {
        'builtin': {
          'buffer.Buffer': true,
          'events.EventEmitter': true,
          'stream': true,
          'util': true,
        },
        'globals': {
          'process.browser': true,
          'process.env.READABLE_STREAM': true,
          'process.nextTick': true,
          'process.stderr': true,
          'process.stdout': true,
          'process.version.slice': true,
          'setImmediate': true,
        },
        'packages': {
          'core-util-is': true,
          'inherits': true,
          'isarray': true,
          'process-nextick-args': true,
          'safe-buffer': true,
          'string_decoder': true,
          'util-deprecate': true,
        },
      },
      'resolve': {
        'builtin': {
          'fs.readFile': true,
          'fs.readFileSync': true,
          'fs.realpath': true,
          'fs.realpathSync': true,
          'fs.stat': true,
          'fs.statSync': true,
          'path.dirname': true,
          'path.join': true,
          'path.parse': true,
          'path.relative': true,
          'path.resolve': true,
        },
        'globals': {
          'process.nextTick': true,
          'process.platform': true,
          'process.versions': true,
        },
        'packages': {
          'is-core-module': true,
          'path-parse': true,
        },
      },
      'safe-buffer': {
        'builtin': {
          'buffer': true,
        },
      },
      'shallow-clone': {
        'packages': {
          'is-extendable': true,
          'kind-of': true,
          'lazy-cache': true,
          'mixin-object': true,
        },
      },
      'shasum-object': {
        'builtin': {
          'crypto.createHash': true,
        },
        'globals': {
          'Buffer.isBuffer': true,
        },
        'packages': {
          'fast-safe-stringify': true,
        },
      },
      'stream-combiner2': {
        'packages': {
          'duplexer2': true,
          'readable-stream': true,
        },
      },
      'stream-splicer': {
        'globals': {
          'process.nextTick': true,
          'setImmediate': true,
        },
        'packages': {
          'inherits': true,
          'readable-stream': true,
        },
      },
      'string_decoder': {
        'packages': {
          'safe-buffer': true,
        },
      },
      'supports-color': {
        'builtin': {
          'os.release': true,
          'tty.isatty': true,
        },
        'globals': {
          'process.env': true,
          'process.platform': true,
          'process.stderr': true,
          'process.stdout': true,
          'process.versions.node.split': true,
        },
        'packages': {
          'has-flag': true,
        },
      },
      'syntax-error': {
        'packages': {
          'acorn-node': true,
        },
      },
      'through': {
        'builtin': {
          'stream': true,
        },
        'globals': {
          'process.nextTick': true,
        },
      },
      'through2': {
        'builtin': {
          'util.inherits': true,
        },
        'globals': {
          'process.nextTick': true,
        },
        'packages': {
          'inherits': true,
          'readable-stream': true,
          'xtend': true,
        },
      },
      'undeclared-identifiers': {
        'packages': {
          'acorn-node': true,
          'dash-ast': true,
          'get-assigned-identifiers': true,
          'xtend': true,
        },
      },
      'util-deprecate': {
        'builtin': {
          'util.deprecate': true,
        },
      },
    },
  },
  'override': {
    'resources': {
      'module-deps': {
        'packages': {
          'package-json-versionify': true,
        },
      },
    },
  },
  'debug': {
    'debugInfo': {
      '/home/xyz/Development/webtorrent/build.js': {
        'moduleRecord': {
          'content': "const { createWriteStream } = require('fs')\nconst browserify = require('browserify')\n// const minify = require('babel-minify')\n\n// browserify --standalone WebTorrent . | minify --mangle=false > webtorrent.min.js\n\nrequire(\"package-json-versionify\")\n\nbrowserify(['.'], { standalone: 'WebTorrent' })\n  .bundle()\n  .pipe(createWriteStream('./webtorrent.min.js'))\n\n",
          'file': '/home/xyz/Development/webtorrent/build.js',
          'importMap': {
            'browserify': '/home/xyz/Development/webtorrent/node_modules/browserify/index.js',
            'fs': 'fs',
            'package-json-versionify': '/home/xyz/Development/webtorrent/node_modules/package-json-versionify/index.js',
          },
          'packageName': '<root>',
          'specifier': '/home/xyz/Development/webtorrent/build.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/JSONStream/index.js': {
        'globals': {
          'Buffer': 'read',
        },
        'moduleRecord': {
          'content': "'use strict'\n\nvar Parser = require('jsonparse')\n  , through = require('through')\n\nvar bufferFrom = Buffer.from && Buffer.from !== Uint8Array.from\n\n/*\n\n  the value of this.stack that creationix's jsonparse has is weird.\n\n  it makes this code ugly, but his problem is way harder that mine,\n  so i'll forgive him.\n\n*/\n\nexports.parse = function (path, map) {\n  var header, footer\n  var parser = new Parser()\n  var stream = through(function (chunk) {\n    if('string' === typeof chunk)\n      chunk = bufferFrom ? Buffer.from(chunk) : new Buffer(chunk)\n    parser.write(chunk)\n  },\n  function (data) {\n    if(data)\n      stream.write(data)\n    if (header)\n        stream.emit('header', header)\n    if (footer)\n      stream.emit('footer', footer)\n    stream.queue(null)\n  })\n\n  if('string' === typeof path)\n    path = path.split('.').map(function (e) {\n      if (e === '$*')\n        return {emitKey: true}\n      else if (e === '*')\n        return true\n      else if (e === '') // '..'.split('.') returns an empty string\n        return {recurse: true}\n      else\n        return e\n    })\n\n\n  var count = 0, _key\n  if(!path || !path.length)\n    path = null\n\n  parser.onValue = function (value) {\n    if (!this.root)\n      stream.root = value\n\n    if(! path) return\n\n    var i = 0 // iterates on path\n    var j  = 0 // iterates on stack\n    var emitKey = false;\n    var emitPath = false;\n    while (i < path.length) {\n      var key = path[i]\n      var c\n      j++\n\n      if (key && !key.recurse) {\n        c = (j === this.stack.length) ? this : this.stack[j]\n        if (!c) return\n        if (! check(key, c.key)) {\n          setHeaderFooter(c.key, value)\n          return\n        }\n        emitKey = !!key.emitKey;\n        emitPath = !!key.emitPath;\n        i++\n      } else {\n        i++\n        var nextKey = path[i]\n        if (! nextKey) return\n        while (true) {\n          c = (j === this.stack.length) ? this : this.stack[j]\n          if (!c) return\n          if (check(nextKey, c.key)) {\n            i++;\n            if (!Object.isFrozen(this.stack[j]))\n              this.stack[j].value = null\n            break\n          } else {\n            setHeaderFooter(c.key, value)\n          }\n          j++\n        }\n      }\n\n    }\n\n    // emit header\n    if (header) {\n      stream.emit('header', header);\n      header = false;\n    }\n    if (j !== this.stack.length) return\n\n    count ++\n    var actualPath = this.stack.slice(1).map(function(element) { return element.key }).concat([this.key])\n    var data = value\n    if(null != data)\n      if(null != (data = map ? map(data, actualPath) : data)) {\n        if (emitKey || emitPath) {\n          data = { value: data };\n          if (emitKey)\n            data[\"key\"] = this.key;\n          if (emitPath)\n            data[\"path\"] = actualPath;\n        }\n\n        stream.queue(data)\n      }\n    if (this.value) delete this.value[this.key]\n    for(var k in this.stack)\n      if (!Object.isFrozen(this.stack[k]))\n        this.stack[k].value = null\n  }\n  parser._onToken = parser.onToken;\n\n  parser.onToken = function (token, value) {\n    parser._onToken(token, value);\n    if (this.stack.length === 0) {\n      if (stream.root) {\n        if(!path)\n          stream.queue(stream.root)\n        count = 0;\n        stream.root = null;\n      }\n    }\n  }\n\n  parser.onError = function (err) {\n    if(err.message.indexOf(\"at position\") > -1)\n      err.message = \"Invalid JSON (\" + err.message + \")\";\n    stream.emit('error', err)\n  }\n\n  return stream\n\n  function setHeaderFooter(key, value) {\n    // header has not been emitted yet\n    if (header !== false) {\n      header = header || {}\n      header[key] = value\n    }\n\n    // footer has not been emitted yet but header has\n    if (footer !== false && header === false) {\n      footer = footer || {}\n      footer[key] = value\n    }\n  }\n}\n\nfunction check (x, y) {\n  if ('string' === typeof x)\n    return y == x\n  else if (x && 'function' === typeof x.exec)\n    return x.exec(y)\n  else if ('boolean' === typeof x || 'object' === typeof x)\n    return x\n  else if ('function' === typeof x)\n    return x(y)\n  return false\n}\n\nexports.stringify = function (op, sep, cl, indent) {\n  indent = indent || 0\n  if (op === false){\n    op = ''\n    sep = '\\n'\n    cl = ''\n  } else if (op == null) {\n\n    op = '[\\n'\n    sep = '\\n,\\n'\n    cl = '\\n]\\n'\n\n  }\n\n  //else, what ever you like\n\n  var stream\n    , first = true\n    , anyData = false\n  stream = through(function (data) {\n    anyData = true\n    try {\n      var json = JSON.stringify(data, null, indent)\n    } catch (err) {\n      return stream.emit('error', err)\n    }\n    if(first) { first = false ; stream.queue(op + json)}\n    else stream.queue(sep + json)\n  },\n  function (data) {\n    if(!anyData)\n      stream.queue(op)\n    stream.queue(cl)\n    stream.queue(null)\n  })\n\n  return stream\n}\n\nexports.stringifyObject = function (op, sep, cl, indent) {\n  indent = indent || 0\n  if (op === false){\n    op = ''\n    sep = '\\n'\n    cl = ''\n  } else if (op == null) {\n\n    op = '{\\n'\n    sep = '\\n,\\n'\n    cl = '\\n}\\n'\n\n  }\n\n  //else, what ever you like\n\n  var first = true\n  var anyData = false\n  var stream = through(function (data) {\n    anyData = true\n    var json = JSON.stringify(data[0]) + ':' + JSON.stringify(data[1], null, indent)\n    if(first) { first = false ; this.queue(op + json)}\n    else this.queue(sep + json)\n  },\n  function (data) {\n    if(!anyData) this.queue(op)\n    this.queue(cl)\n\n    this.queue(null)\n  })\n\n  return stream\n}\n\n\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/JSONStream/index.js',
          'importMap': {
            'jsonparse': '/home/xyz/Development/webtorrent/node_modules/jsonparse/jsonparse.js',
            'through': '/home/xyz/Development/webtorrent/node_modules/through/index.js',
          },
          'packageName': 'JSONStream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/JSONStream/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn-node/index.js': {
        'moduleRecord': {
          'content': "var acorn = require('acorn')\nvar xtend = require('xtend')\n\nvar CJSParser = acorn.Parser\n  .extend(require('./lib/bigint'))\n  .extend(require('./lib/class-fields'))\n  .extend(require('./lib/static-class-features'))\n  .extend(require('./lib/numeric-separator'))\n  .extend(require('./lib/dynamic-import').default)\nvar ESModulesParser = CJSParser\n  .extend(require('./lib/export-ns-from'))\n  .extend(require('./lib/import-meta'))\n\nfunction mapOptions (opts) {\n  if (!opts) opts = {}\n  return xtend({\n    ecmaVersion: 2020,\n    allowHashBang: true,\n    allowReturnOutsideFunction: true\n  }, opts)\n}\n\nfunction getParser (opts) {\n  if (!opts) opts = {}\n  return opts.sourceType === 'module' ? ESModulesParser : CJSParser\n}\n\nmodule.exports = exports = xtend(acorn, {\n  parse: function parse (src, opts) {\n    return getParser(opts).parse(src, mapOptions(opts))\n  },\n  parseExpressionAt: function parseExpressionAt (src, offset, opts) {\n    return getParser(opts).parseExpressionAt(src, offset, mapOptions(opts))\n  },\n  tokenizer: function tokenizer (src, opts) {\n    return getParser(opts).tokenizer(src, mapOptions(opts))\n  }\n})\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn-node/index.js',
          'importMap': {
            './lib/bigint': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/bigint/index.js',
            './lib/class-fields': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/class-fields/index.js',
            './lib/dynamic-import': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/dynamic-import/index.js',
            './lib/export-ns-from': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/export-ns-from/index.js',
            './lib/import-meta': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/import-meta/index.js',
            './lib/numeric-separator': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/numeric-separator/index.js',
            './lib/static-class-features': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/static-class-features/index.js',
            'acorn': '/home/xyz/Development/webtorrent/node_modules/acorn/dist/acorn.js',
            'xtend': '/home/xyz/Development/webtorrent/node_modules/xtend/immutable.js',
          },
          'packageName': 'acorn-node',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn-node/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/bigint/index.js': {
        'globals': {
          'BigInt': 'read',
        },
        'moduleRecord': {
          'content': '/* Generated by `npm run build`, do not edit! */\n\n"use strict"\n\nvar acorn = require("acorn")\nvar tt = acorn.tokTypes\nvar isIdentifierStart = acorn.isIdentifierStart\n\nmodule.exports = function(Parser) {\n  return /*@__PURE__*/(function (Parser) {\n    function anonymous () {\n      Parser.apply(this, arguments);\n    }\n\n    if ( Parser ) anonymous.__proto__ = Parser;\n    anonymous.prototype = Object.create( Parser && Parser.prototype );\n    anonymous.prototype.constructor = anonymous;\n\n    anonymous.prototype.parseLiteral = function parseLiteral (value) {\n      var node = Parser.prototype.parseLiteral.call(this, value)\n      if (node.raw.charCodeAt(node.raw.length - 1) == 110) { node.bigint = this.getNumberInput(node.start, node.end) }\n      return node\n    };\n\n    anonymous.prototype.readRadixNumber = function readRadixNumber (radix) {\n      var start = this.pos\n      this.pos += 2 // 0x\n      var val = this.readInt(radix)\n      if (val === null) { this.raise(this.start + 2, ("Expected number in radix " + radix)) }\n      if (this.input.charCodeAt(this.pos) == 110) {\n        var str = this.getNumberInput(start, this.pos)\n        val = typeof BigInt !== "undefined" ? BigInt(str) : null\n        ++this.pos\n      } else if (isIdentifierStart(this.fullCharCodeAtPos())) { this.raise(this.pos, "Identifier directly after number") }\n      return this.finishToken(tt.num, val)\n    };\n\n    anonymous.prototype.readNumber = function readNumber (startsWithDot) {\n      var start = this.pos\n\n      // Not an int\n      if (startsWithDot) { return Parser.prototype.readNumber.call(this, startsWithDot) }\n\n      // Legacy octal\n      if (this.input.charCodeAt(start) === 48 && this.input.charCodeAt(start + 1) !== 110) {\n        return Parser.prototype.readNumber.call(this, startsWithDot)\n      }\n\n      if (this.readInt(10) === null) { this.raise(start, "Invalid number") }\n\n      // Not a BigInt, reset and parse again\n      if (this.input.charCodeAt(this.pos) != 110) {\n        this.pos = start\n        return Parser.prototype.readNumber.call(this, startsWithDot)\n      }\n\n      var str = this.getNumberInput(start, this.pos)\n      var val = typeof BigInt !== "undefined" ? BigInt(str) : null\n      ++this.pos\n      return this.finishToken(tt.num, val)\n    };\n\n    // This is basically a hook for acorn-numeric-separator\n    anonymous.prototype.getNumberInput = function getNumberInput (start, end) {\n      if (Parser.prototype.getNumberInput) { return Parser.prototype.getNumberInput.call(this, start, end) }\n      return this.input.slice(start, end)\n    };\n\n    return anonymous;\n  }(Parser))\n}\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/bigint/index.js',
          'importMap': {
            'acorn': '/home/xyz/Development/webtorrent/node_modules/acorn/dist/acorn.js',
          },
          'packageName': 'acorn-node',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/bigint/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/class-fields/index.js': {
        'moduleRecord': {
          'content': '/* Generated by `npm run build`, do not edit! */\n\n"use strict"\n\nvar acorn = require("acorn")\nvar tt = acorn.tokTypes\nvar privateClassElements = require("../private-class-elements")\n\nfunction maybeParseFieldValue(field) {\n  if (this.eat(tt.eq)) {\n    var oldInFieldValue = this._inFieldValue\n    this._inFieldValue = true\n    field.value = this.parseExpression()\n    this._inFieldValue = oldInFieldValue\n  } else { field.value = null }\n}\n\nmodule.exports = function(Parser) {\n  Parser = privateClassElements(Parser)\n  return /*@__PURE__*/(function (Parser) {\n    function anonymous () {\n      Parser.apply(this, arguments);\n    }\n\n    if ( Parser ) anonymous.__proto__ = Parser;\n    anonymous.prototype = Object.create( Parser && Parser.prototype );\n    anonymous.prototype.constructor = anonymous;\n\n    anonymous.prototype.parseClassElement = function parseClassElement (_constructorAllowsSuper) {\n      if (this.options.ecmaVersion >= 8 && (this.type == tt.name || this.type == this.privateNameToken || this.type == tt.bracketL || this.type == tt.string)) {\n        var branch = this._branch()\n        if (branch.type == tt.bracketL) {\n          var count = 0\n          do {\n            if (branch.eat(tt.bracketL)) { ++count }\n            else if (branch.eat(tt.bracketR)) { --count }\n            else { branch.next() }\n          } while (count > 0)\n        } else { branch.next() }\n        if (branch.type == tt.eq || branch.canInsertSemicolon() || branch.type == tt.semi) {\n          var node = this.startNode()\n          if (this.type == this.privateNameToken) {\n            this.parsePrivateClassElementName(node)\n          } else {\n            this.parsePropertyName(node)\n          }\n          if ((node.key.type === "Identifier" && node.key.name === "constructor") ||\n              (node.key.type === "Literal" && node.key.value === "constructor")) {\n            this.raise(node.key.start, "Classes may not have a field called constructor")\n          }\n          maybeParseFieldValue.call(this, node)\n          this.finishNode(node, "FieldDefinition")\n          this.semicolon()\n          return node\n        }\n      }\n\n      return Parser.prototype.parseClassElement.apply(this, arguments)\n    };\n\n    // Prohibit arguments in class field initializers\n    anonymous.prototype.parseIdent = function parseIdent (liberal, isBinding) {\n      var ident = Parser.prototype.parseIdent.call(this, liberal, isBinding)\n      if (this._inFieldValue && ident.name == "arguments") { this.raise(ident.start, "A class field initializer may not contain arguments") }\n      return ident\n    };\n\n    return anonymous;\n  }(Parser))\n}\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/class-fields/index.js',
          'importMap': {
            '../private-class-elements': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/private-class-elements/index.js',
            'acorn': '/home/xyz/Development/webtorrent/node_modules/acorn/dist/acorn.js',
          },
          'packageName': 'acorn-node',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/class-fields/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/dynamic-import/index.js': {
        'moduleRecord': {
          'content': "/* Generated by `npm run build`, do not edit! */\n\n'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.DynamicImportKey = undefined;\n\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) { descriptor.writable = true; } Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) { defineProperties(Constructor.prototype, protoProps); } if (staticProps) { defineProperties(Constructor, staticProps); } return Constructor; }; }();\n\nvar _get = function () {\n  function get(object, property, receiver) { if (object === null) { object = Function.prototype; } var desc = Object.getOwnPropertyDescriptor(object, property); if (desc === undefined) { var parent = Object.getPrototypeOf(object); if (parent === null) { return undefined; } else { return get(parent, property, receiver); } } else if (\"value\" in desc) { return desc.value; } else { var getter = desc.get; if (getter === undefined) { return undefined; } return getter.call(receiver); } }\n\n  return get;\n}();\n\nexports['default'] = dynamicImport;\n\nvar _acorn = require('acorn');\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) { Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; } } /* eslint-disable no-underscore-dangle */\n\n\nvar DynamicImportKey = exports.DynamicImportKey = 'Import';\n\n// NOTE: This allows `yield import()` to parse correctly.\n_acorn.tokTypes._import.startsExpr = true;\n\nfunction parseDynamicImport() {\n  var node = this.startNode();\n  this.next();\n  if (this.type !== _acorn.tokTypes.parenL) {\n    this.unexpected();\n  }\n  return this.finishNode(node, DynamicImportKey);\n}\n\nfunction parenAfter() {\n  return (/^(\\s|\\/\\/.*|\\/\\*[^]*?\\*\\/)*\\(/.test(this.input.slice(this.pos))\n  );\n}\n\nfunction dynamicImport(Parser) {\n  return function (_Parser) {\n    _inherits(_class, _Parser);\n\n    function _class() {\n      _classCallCheck(this, _class);\n\n      return _possibleConstructorReturn(this, (_class.__proto__ || Object.getPrototypeOf(_class)).apply(this, arguments));\n    }\n\n    _createClass(_class, [{\n      key: 'parseStatement',\n      value: function () {\n        function parseStatement(context, topLevel, exports) {\n          if (this.type === _acorn.tokTypes._import && parenAfter.call(this)) {\n            return this.parseExpressionStatement(this.startNode(), this.parseExpression());\n          }\n          return _get(_class.prototype.__proto__ || Object.getPrototypeOf(_class.prototype), 'parseStatement', this).call(this, context, topLevel, exports);\n        }\n\n        return parseStatement;\n      }()\n    }, {\n      key: 'parseExprAtom',\n      value: function () {\n        function parseExprAtom(refDestructuringErrors) {\n          if (this.type === _acorn.tokTypes._import) {\n            return parseDynamicImport.call(this);\n          }\n          return _get(_class.prototype.__proto__ || Object.getPrototypeOf(_class.prototype), 'parseExprAtom', this).call(this, refDestructuringErrors);\n        }\n\n        return parseExprAtom;\n      }()\n    }]);\n\n    return _class;\n  }(Parser);\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/dynamic-import/index.js',
          'importMap': {
            'acorn': '/home/xyz/Development/webtorrent/node_modules/acorn/dist/acorn.js',
          },
          'packageName': 'acorn-node',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/dynamic-import/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/export-ns-from/index.js': {
        'moduleRecord': {
          'content': '/* Generated by `npm run build`, do not edit! */\n\n"use strict"\n\nvar skipWhiteSpace = /(?:\\s|\\/\\/.*|\\/\\*[^]*?\\*\\/)*/g\n\nvar tt = require("acorn").tokTypes\n\nmodule.exports = function(Parser) {\n  return /*@__PURE__*/(function (Parser) {\n    function anonymous () {\n      Parser.apply(this, arguments);\n    }\n\n    if ( Parser ) anonymous.__proto__ = Parser;\n    anonymous.prototype = Object.create( Parser && Parser.prototype );\n    anonymous.prototype.constructor = anonymous;\n\n    anonymous.prototype.parseExport = function parseExport (node, exports) {\n      skipWhiteSpace.lastIndex = this.pos\n      var skip = skipWhiteSpace.exec(this.input)\n      var next = this.input.charAt(this.pos + skip[0].length)\n      if (next !== "*") { return Parser.prototype.parseExport.call(this, node, exports) }\n\n      this.next()\n      var specifier = this.startNode()\n      this.expect(tt.star)\n      if (this.eatContextual("as")) {\n        node.declaration = null\n        specifier.exported = this.parseIdent(true)\n        this.checkExport(exports, specifier.exported.name, this.lastTokStart)\n        node.specifiers = [this.finishNode(specifier, "ExportNamespaceSpecifier")]\n      }\n      this.expectContextual("from")\n      if (this.type !== tt.string) { this.unexpected() }\n      node.source = this.parseExprAtom()\n      this.semicolon()\n      return this.finishNode(node, node.specifiers ? "ExportNamedDeclaration" : "ExportAllDeclaration")\n    };\n\n    return anonymous;\n  }(Parser))\n}\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/export-ns-from/index.js',
          'importMap': {
            'acorn': '/home/xyz/Development/webtorrent/node_modules/acorn/dist/acorn.js',
          },
          'packageName': 'acorn-node',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/export-ns-from/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/import-meta/index.js': {
        'moduleRecord': {
          'content': "/* Generated by `npm run build`, do not edit! */\n\n\"use strict\"\n\nvar tt = require(\"acorn\").tokTypes\n\nvar skipWhiteSpace = /(?:\\s|\\/\\/.*|\\/\\*[^]*?\\*\\/)*/g\n\nvar nextTokenIsDot = function (parser) {\n  skipWhiteSpace.lastIndex = parser.pos\n  var skip = skipWhiteSpace.exec(parser.input)\n  var next = parser.pos + skip[0].length\n  return parser.input.slice(next, next + 1) === \".\"\n}\n\nmodule.exports = function(Parser) {\n  return /*@__PURE__*/(function (Parser) {\n    function anonymous () {\n      Parser.apply(this, arguments);\n    }\n\n    if ( Parser ) anonymous.__proto__ = Parser;\n    anonymous.prototype = Object.create( Parser && Parser.prototype );\n    anonymous.prototype.constructor = anonymous;\n\n    anonymous.prototype.parseExprAtom = function parseExprAtom (refDestructuringErrors) {\n      if (this.type !== tt._import || !nextTokenIsDot(this)) { return Parser.prototype.parseExprAtom.call(this, refDestructuringErrors) }\n\n      if (!this.options.allowImportExportEverywhere && !this.inModule) {\n        this.raise(this.start, \"'import' and 'export' may appear only with 'sourceType: module'\")\n      }\n\n      var node = this.startNode()\n      node.meta = this.parseIdent(true)\n      this.expect(tt.dot)\n      node.property = this.parseIdent(true)\n      if (node.property.name !== \"meta\") {\n        this.raiseRecoverable(node.property.start, \"The only valid meta property for import is import.meta\")\n      }\n      return this.finishNode(node, \"MetaProperty\")\n    };\n\n    anonymous.prototype.parseStatement = function parseStatement (context, topLevel, exports) {\n      if (this.type !== tt._import || !nextTokenIsDot(this)) {\n        return Parser.prototype.parseStatement.call(this, context, topLevel, exports)\n      }\n\n      var node = this.startNode()\n      var expr = this.parseExpression()\n      return this.parseExpressionStatement(node, expr)\n    };\n\n    return anonymous;\n  }(Parser))\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/import-meta/index.js',
          'importMap': {
            'acorn': '/home/xyz/Development/webtorrent/node_modules/acorn/dist/acorn.js',
          },
          'packageName': 'acorn-node',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/import-meta/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/numeric-separator/index.js': {
        'moduleRecord': {
          'content': '/* Generated by `npm run build`, do not edit! */\n\n"use strict"\n\nmodule.exports = function(Parser) {\n  return /*@__PURE__*/(function (Parser) {\n    function anonymous () {\n      Parser.apply(this, arguments);\n    }\n\n    if ( Parser ) anonymous.__proto__ = Parser;\n    anonymous.prototype = Object.create( Parser && Parser.prototype );\n    anonymous.prototype.constructor = anonymous;\n\n    anonymous.prototype.readInt = function readInt (radix, len) {\n      // Hack: len is only != null for unicode escape sequences,\n      // where numeric separators are not allowed\n      if (len != null) { return Parser.prototype.readInt.call(this, radix, len) }\n\n      var start = this.pos, total = 0, acceptUnderscore = false\n      for (;;) {\n        var code = this.input.charCodeAt(this.pos), val = (void 0)\n        if (code >= 97) { val = code - 97 + 10 } // a\n        else if (code == 95) {\n          if (!acceptUnderscore) { this.raise(this.pos, "Invalid numeric separator") }\n          ++this.pos\n          acceptUnderscore = false\n          continue\n        } else if (code >= 65) { val = code - 65 + 10 } // A\n        else if (code >= 48 && code <= 57) { val = code - 48 } // 0-9\n        else { val = Infinity }\n        if (val >= radix) { break }\n        ++this.pos\n        total = total * radix + val\n        acceptUnderscore = true\n      }\n      if (this.pos === start) { return null }\n      if (!acceptUnderscore) { this.raise(this.pos - 1, "Invalid numeric separator") }\n\n      return total\n    };\n\n    anonymous.prototype.readNumber = function readNumber (startsWithDot) {\n      var token = Parser.prototype.readNumber.call(this, startsWithDot)\n      var octal = this.end - this.start >= 2 && this.input.charCodeAt(this.start) === 48\n      var stripped = this.getNumberInput(this.start, this.end)\n      if (stripped.length < this.end - this.start) {\n        if (octal) { this.raise(this.start, "Invalid number") }\n        this.value = parseFloat(stripped)\n      }\n      return token\n    };\n\n    // This is used by acorn-bigint\n    anonymous.prototype.getNumberInput = function getNumberInput (start, end) {\n      return this.input.slice(start, end).replace(/_/g, "")\n    };\n\n    return anonymous;\n  }(Parser))\n}\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/numeric-separator/index.js',
          'importMap': {},
          'packageName': 'acorn-node',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/numeric-separator/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/private-class-elements/index.js': {
        'moduleRecord': {
          'content': '/* Generated by `npm run build`, do not edit! */\n\n"use strict"\n\nvar acorn = require("acorn")\nif (false) {\n  throw new Error(("acorn-private-class-elements requires acorn@^6.1.0, not " + (acorn.version)))\n}\nvar tt = acorn.tokTypes\nvar TokenType = acorn.TokenType\n\nmodule.exports = function(Parser) {\n  // Only load this plugin once.\n  if (Parser.prototype.parsePrivateName) {\n    return Parser\n  }\n\n  // Make sure `Parser` comes from the same acorn as our `tt`,\n  // otherwise the comparisons fail.\n  var cur = Parser\n  while (cur && cur !== acorn.Parser) {\n    cur = cur.__proto__\n  }\n  if (cur !== acorn.Parser) {\n    throw new Error("acorn-private-class-elements does not support mixing different acorn copies")\n  }\n\n  Parser = /*@__PURE__*/(function (Parser) {\n    function Parser_ () {\n      Parser.apply(this, arguments);\n    }\n\n    if ( Parser ) Parser_.__proto__ = Parser;\n    Parser_.prototype = Object.create( Parser && Parser.prototype );\n    Parser_.prototype.constructor = Parser_;\n\n    Parser_.prototype._branch = function _branch () {\n      this.__branch = this.__branch || new Parser({ecmaVersion: this.options.ecmaVersion}, this.input)\n      this.__branch.end = this.end\n      this.__branch.pos = this.pos\n      this.__branch.type = this.type\n      this.__branch.value = this.value\n      this.__branch.containsEsc = this.containsEsc\n      return this.__branch\n    };\n\n    Parser_.prototype.parsePrivateClassElementName = function parsePrivateClassElementName (element) {\n      element.computed = false\n      element.key = this.parsePrivateName()\n      if (element.key.name == "constructor") { this.raise(element.key.start, "Classes may not have a private element named constructor") }\n      var accept = {get: "set", set: "get"}[element.kind]\n      var privateBoundNames = this._privateBoundNamesStack[this._privateBoundNamesStack.length - 1]\n      if (Object.prototype.hasOwnProperty.call(privateBoundNames, element.key.name) && privateBoundNames[element.key.name] !== accept) {\n        this.raise(element.start, "Duplicate private element")\n      }\n      privateBoundNames[element.key.name] = element.kind || true\n      delete this._unresolvedPrivateNamesStack[this._unresolvedPrivateNamesStack.length - 1][element.key.name]\n      return element.key\n    };\n\n    Parser_.prototype.parsePrivateName = function parsePrivateName () {\n      var node = this.startNode()\n      node.name = this.value\n      this.next()\n      this.finishNode(node, "PrivateName")\n      if (this.options.allowReserved == "never") { this.checkUnreserved(node) }\n      return node\n    };\n\n    // Parse # token\n    Parser_.prototype.getTokenFromCode = function getTokenFromCode (code) {\n      if (code === 35) {\n        ++this.pos\n        var word = this.readWord1()\n        return this.finishToken(this.privateNameToken, word)\n      }\n      return Parser.prototype.getTokenFromCode.call(this, code)\n    };\n\n    // Manage stacks and check for undeclared private names\n    Parser_.prototype.parseClass = function parseClass (node, isStatement) {\n      this._privateBoundNamesStack = this._privateBoundNamesStack || []\n      var privateBoundNames = Object.create(this._privateBoundNamesStack[this._privateBoundNamesStack.length - 1] || null)\n      this._privateBoundNamesStack.push(privateBoundNames)\n      this._unresolvedPrivateNamesStack = this._unresolvedPrivateNamesStack || []\n      var unresolvedPrivateNames = Object.create(null)\n      this._unresolvedPrivateNamesStack.push(unresolvedPrivateNames)\n      var _return = Parser.prototype.parseClass.call(this, node, isStatement)\n      this._privateBoundNamesStack.pop()\n      this._unresolvedPrivateNamesStack.pop()\n      if (!this._unresolvedPrivateNamesStack.length) {\n        var names = Object.keys(unresolvedPrivateNames)\n        if (names.length) {\n          names.sort(function (n1, n2) { return unresolvedPrivateNames[n1] - unresolvedPrivateNames[n2]; })\n          this.raise(unresolvedPrivateNames[names[0]], "Usage of undeclared private name")\n        }\n      } else { Object.assign(this._unresolvedPrivateNamesStack[this._unresolvedPrivateNamesStack.length - 1], unresolvedPrivateNames) }\n      return _return\n    };\n\n    // Parse private element access\n    Parser_.prototype.parseSubscript = function parseSubscript (base, startPos, startLoc, noCalls, maybeAsyncArrow) {\n      if (!this.eat(tt.dot)) {\n        return Parser.prototype.parseSubscript.call(this, base, startPos, startLoc, noCalls, maybeAsyncArrow)\n      }\n      var node = this.startNodeAt(startPos, startLoc)\n      node.object = base\n      node.computed = false\n      if (this.type == this.privateNameToken) {\n        node.property = this.parsePrivateName()\n        if (!this._privateBoundNamesStack.length || !this._privateBoundNamesStack[this._privateBoundNamesStack.length - 1][node.property.name]) {\n          this._unresolvedPrivateNamesStack[this._unresolvedPrivateNamesStack.length - 1][node.property.name] = node.property.start\n        }\n      } else {\n        node.property = this.parseIdent(true)\n      }\n      return this.finishNode(node, "MemberExpression")\n    };\n\n    // Prohibit delete of private class elements\n    Parser_.prototype.parseMaybeUnary = function parseMaybeUnary (refDestructuringErrors, sawUnary) {\n      var _return = Parser.prototype.parseMaybeUnary.call(this, refDestructuringErrors, sawUnary)\n      if (_return.operator == "delete") {\n        if (_return.argument.type == "MemberExpression" && _return.argument.property.type == "PrivateName") {\n          this.raise(_return.start, "Private elements may not be deleted")\n        }\n      }\n      return _return\n    };\n\n    return Parser_;\n  }(Parser))\n  Parser.prototype.privateNameToken = new TokenType("privateName")\n  return Parser\n}\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/private-class-elements/index.js',
          'importMap': {
            'acorn': '/home/xyz/Development/webtorrent/node_modules/acorn/dist/acorn.js',
          },
          'packageName': 'acorn-node',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/private-class-elements/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/static-class-features/index.js': {
        'moduleRecord': {
          'content': '/* Generated by `npm run build`, do not edit! */\n\n"use strict"\n\nvar skipWhiteSpace = /(?:\\s|\\/\\/.*|\\/\\*[^]*?\\*\\/)*/g\n\nvar acorn = require("acorn")\nvar tt = acorn.tokTypes\n\nfunction maybeParseFieldValue(field) {\n  if (this.eat(tt.eq)) {\n    var oldInFieldValue = this._inStaticFieldValue\n    this._inStaticFieldValue = true\n    field.value = this.parseExpression()\n    this._inStaticFieldValue = oldInFieldValue\n  } else { field.value = null }\n}\n\nvar privateClassElements = require("../private-class-elements")\n\nmodule.exports = function(Parser) {\n  var ExtendedParser = privateClassElements(Parser)\n\n  return /*@__PURE__*/(function (ExtendedParser) {\n    function anonymous () {\n      ExtendedParser.apply(this, arguments);\n    }\n\n    if ( ExtendedParser ) anonymous.__proto__ = ExtendedParser;\n    anonymous.prototype = Object.create( ExtendedParser && ExtendedParser.prototype );\n    anonymous.prototype.constructor = anonymous;\n\n    anonymous.prototype.parseClassElement = function parseClassElement (_constructorAllowsSuper) {\n      var this$1 = this;\n\n      if (this.eat(tt.semi)) { return null }\n\n      var node = this.startNode()\n\n      var tryContextual = function (k, noLineBreak) {\n        if (typeof noLineBreak == "undefined") { noLineBreak = false }\n        var start = this$1.start, startLoc = this$1.startLoc\n        if (!this$1.eatContextual(k)) { return false }\n        if (this$1.type !== tt.parenL && (!noLineBreak || !this$1.canInsertSemicolon())) { return true }\n        if (node.key) { this$1.unexpected() }\n        node.computed = false\n        node.key = this$1.startNodeAt(start, startLoc)\n        node.key.name = k\n        this$1.finishNode(node.key, "Identifier")\n        return false\n      }\n\n      node.static = tryContextual("static")\n      if (!node.static) { return ExtendedParser.prototype.parseClassElement.apply(this, arguments) }\n\n      var isGenerator = this.eat(tt.star)\n      var isAsync = false\n      if (!isGenerator) {\n        // Special-case for `async`, since `parseClassMember` currently looks\n        // for `(` to determine whether `async` is a method name\n        if (this.options.ecmaVersion >= 8 && this.isContextual("async")) {\n          skipWhiteSpace.lastIndex = this.pos\n          var skip = skipWhiteSpace.exec(this.input)\n          var next = this.input.charAt(this.pos + skip[0].length)\n          if (next === ";" || next === "=") {\n            node.key = this.parseIdent(true)\n            node.computed = false\n            maybeParseFieldValue.call(this, node)\n            this.finishNode(node, "FieldDefinition")\n            this.semicolon()\n            return node\n          } else if (this.options.ecmaVersion >= 8 && tryContextual("async", true)) {\n            isAsync = true\n            isGenerator = this.options.ecmaVersion >= 9 && this.eat(tt.star)\n          }\n        } else if (tryContextual("get")) {\n          node.kind = "get"\n        } else if (tryContextual("set")) {\n          node.kind = "set"\n        }\n      }\n      if (this.type === this.privateNameToken) {\n        this.parsePrivateClassElementName(node)\n        if (this.type !== tt.parenL) {\n          if (node.key.name === "prototype") {\n            this.raise(node.key.start, "Classes may not have a private static property named prototype")\n          }\n          maybeParseFieldValue.call(this, node)\n          this.finishNode(node, "FieldDefinition")\n          this.semicolon()\n          return node\n        }\n      } else if (!node.key) {\n        this.parsePropertyName(node)\n        if ((node.key.name || node.key.value) === "prototype" && !node.computed) {\n          this.raise(node.key.start, "Classes may not have a static property named prototype")\n        }\n      }\n      if (!node.kind) { node.kind = "method" }\n      this.parseClassMethod(node, isGenerator, isAsync)\n      if (!node.kind && (node.key.name || node.key.value) === "constructor" && !node.computed) {\n        this.raise(node.key.start, "Classes may not have a static field named constructor")\n      }\n      if (node.kind === "get" && node.value.params.length !== 0) {\n        this.raiseRecoverable(node.value.start, "getter should have no params")\n      }\n      if (node.kind === "set" && node.value.params.length !== 1) {\n        this.raiseRecoverable(node.value.start, "setter should have exactly one param")\n      }\n      if (node.kind === "set" && node.value.params[0].type === "RestElement") {\n        this.raiseRecoverable(node.value.params[0].start, "Setter cannot use rest params")\n      }\n\n      return node\n\n    };\n\n    // Parse public static fields\n    anonymous.prototype.parseClassMethod = function parseClassMethod (method, isGenerator, isAsync, _allowsDirectSuper) {\n      if (isGenerator || isAsync || method.kind != "method" || !method.static || this.options.ecmaVersion < 8 || this.type == tt.parenL) {\n        return ExtendedParser.prototype.parseClassMethod.apply(this, arguments)\n      }\n      maybeParseFieldValue.call(this, method)\n      delete method.kind\n      method = this.finishNode(method, "FieldDefinition")\n      this.semicolon()\n      return method\n    };\n\n    // Prohibit arguments in class field initializers\n    anonymous.prototype.parseIdent = function parseIdent (liberal, isBinding) {\n      var ident = ExtendedParser.prototype.parseIdent.call(this, liberal, isBinding)\n      if (this._inStaticFieldValue && ident.name == "arguments") { this.raise(ident.start, "A static class field initializer may not contain arguments") }\n      return ident\n    };\n\n    return anonymous;\n  }(ExtendedParser))\n}\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/static-class-features/index.js',
          'importMap': {
            '../private-class-elements': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/private-class-elements/index.js',
            'acorn': '/home/xyz/Development/webtorrent/node_modules/acorn/dist/acorn.js',
          },
          'packageName': 'acorn-node',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn-node/lib/static-class-features/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn-node/walk.js': {
        'moduleRecord': {
          'content': "var xtend = require('xtend')\nvar walk = require('acorn-walk')\n\nvar base = xtend(walk.base)\nbase.Import = function () {}\n\nfunction simple (node, visitors, baseVisitor, state, override) {\n  return walk.simple(node, visitors, baseVisitor || base, state, override)\n}\n\nfunction ancestor (node, visitors, baseVisitor, state) {\n  return walk.ancestor(node, visitors, baseVisitor || base, state)\n}\n\nfunction recursive (node, state, funcs, baseVisitor, override) {\n  return walk.recursive(node, state, funcs, baseVisitor || base, override)\n}\n\nfunction full (node, callback, baseVisitor, state, override) {\n  return walk.full(node, callback, baseVisitor || base, state, override)\n}\n\nfunction fullAncestor (node, callback, baseVisitor, state) {\n  return walk.fullAncestor(node, callback, baseVisitor || base, state)\n}\n\nfunction findNodeAt (node, start, end, test, baseVisitor, state) {\n  return walk.findNodeAt(node, start, end, test, baseVisitor || base, state)\n}\n\nfunction findNodeAround (node, pos, test, baseVisitor, state) {\n  return walk.findNodeAround(node, pos, test, baseVisitor || base, state)\n}\n\nfunction findNodeAfter (node, pos, test, baseVisitor, state) {\n  return walk.findNodeAfter(node, pos, test, baseVisitor || base, state)\n}\n\nfunction findNodeBefore (node, pos, test, baseVisitor, state) {\n  return walk.findNodeBefore(node, pos, test, baseVisitor || base, state)\n}\n\nfunction make (funcs, baseVisitor) {\n  return walk.make(funcs, baseVisitor || base)\n}\n\nexports.simple = simple\nexports.ancestor = ancestor\nexports.recursive = recursive\nexports.full = full\nexports.fullAncestor = fullAncestor\nexports.findNodeAt = findNodeAt\nexports.findNodeAround = findNodeAround\nexports.findNodeAfter = findNodeAfter\nexports.findNodeBefore = findNodeBefore\nexports.make = make\nexports.base = base\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn-node/walk.js',
          'importMap': {
            'acorn-walk': '/home/xyz/Development/webtorrent/node_modules/acorn-walk/dist/walk.js',
            'xtend': '/home/xyz/Development/webtorrent/node_modules/xtend/immutable.js',
          },
          'packageName': 'acorn-node',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn-node/walk.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn-walk/dist/walk.js': {
        'globals': {
          'define': 'read',
        },
        'moduleRecord': {
          'content': "(function (global, factory) {\n  typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :\n  typeof define === 'function' && define.amd ? define(['exports'], factory) :\n  (global = global || self, factory((global.acorn = global.acorn || {}, global.acorn.walk = {})));\n}(this, (function (exports) { 'use strict';\n\n  // AST walker module for Mozilla Parser API compatible trees\n\n  // A simple walk is one where you simply specify callbacks to be\n  // called on specific nodes. The last two arguments are optional. A\n  // simple use would be\n  //\n  //     walk.simple(myTree, {\n  //         Expression: function(node) { ... }\n  //     });\n  //\n  // to do something with all expressions. All Parser API node types\n  // can be used to identify node types, as well as Expression and\n  // Statement, which denote categories of nodes.\n  //\n  // The base argument can be used to pass a custom (recursive)\n  // walker, and state can be used to give this walked an initial\n  // state.\n\n  function simple(node, visitors, baseVisitor, state, override) {\n    if (!baseVisitor) { baseVisitor = base\n    ; }(function c(node, st, override) {\n      var type = override || node.type, found = visitors[type];\n      baseVisitor[type](node, st, c);\n      if (found) { found(node, st); }\n    })(node, state, override);\n  }\n\n  // An ancestor walk keeps an array of ancestor nodes (including the\n  // current node) and passes them to the callback as third parameter\n  // (and also as state parameter when no other state is present).\n  function ancestor(node, visitors, baseVisitor, state, override) {\n    var ancestors = [];\n    if (!baseVisitor) { baseVisitor = base\n    ; }(function c(node, st, override) {\n      var type = override || node.type, found = visitors[type];\n      var isNew = node !== ancestors[ancestors.length - 1];\n      if (isNew) { ancestors.push(node); }\n      baseVisitor[type](node, st, c);\n      if (found) { found(node, st || ancestors, ancestors); }\n      if (isNew) { ancestors.pop(); }\n    })(node, state, override);\n  }\n\n  // A recursive walk is one where your functions override the default\n  // walkers. They can modify and replace the state parameter that's\n  // threaded through the walk, and can opt how and whether to walk\n  // their child nodes (by calling their third argument on these\n  // nodes).\n  function recursive(node, state, funcs, baseVisitor, override) {\n    var visitor = funcs ? make(funcs, baseVisitor || undefined) : baseVisitor\n    ;(function c(node, st, override) {\n      visitor[override || node.type](node, st, c);\n    })(node, state, override);\n  }\n\n  function makeTest(test) {\n    if (typeof test === \"string\")\n      { return function (type) { return type === test; } }\n    else if (!test)\n      { return function () { return true; } }\n    else\n      { return test }\n  }\n\n  var Found = function Found(node, state) { this.node = node; this.state = state; };\n\n  // A full walk triggers the callback on each node\n  function full(node, callback, baseVisitor, state, override) {\n    if (!baseVisitor) { baseVisitor = base\n    ; }(function c(node, st, override) {\n      var type = override || node.type;\n      baseVisitor[type](node, st, c);\n      if (!override) { callback(node, st, type); }\n    })(node, state, override);\n  }\n\n  // An fullAncestor walk is like an ancestor walk, but triggers\n  // the callback on each node\n  function fullAncestor(node, callback, baseVisitor, state) {\n    if (!baseVisitor) { baseVisitor = base; }\n    var ancestors = []\n    ;(function c(node, st, override) {\n      var type = override || node.type;\n      var isNew = node !== ancestors[ancestors.length - 1];\n      if (isNew) { ancestors.push(node); }\n      baseVisitor[type](node, st, c);\n      if (!override) { callback(node, st || ancestors, ancestors, type); }\n      if (isNew) { ancestors.pop(); }\n    })(node, state);\n  }\n\n  // Find a node with a given start, end, and type (all are optional,\n  // null can be used as wildcard). Returns a {node, state} object, or\n  // undefined when it doesn't find a matching node.\n  function findNodeAt(node, start, end, test, baseVisitor, state) {\n    if (!baseVisitor) { baseVisitor = base; }\n    test = makeTest(test);\n    try {\n      (function c(node, st, override) {\n        var type = override || node.type;\n        if ((start == null || node.start <= start) &&\n            (end == null || node.end >= end))\n          { baseVisitor[type](node, st, c); }\n        if ((start == null || node.start === start) &&\n            (end == null || node.end === end) &&\n            test(type, node))\n          { throw new Found(node, st) }\n      })(node, state);\n    } catch (e) {\n      if (e instanceof Found) { return e }\n      throw e\n    }\n  }\n\n  // Find the innermost node of a given type that contains the given\n  // position. Interface similar to findNodeAt.\n  function findNodeAround(node, pos, test, baseVisitor, state) {\n    test = makeTest(test);\n    if (!baseVisitor) { baseVisitor = base; }\n    try {\n      (function c(node, st, override) {\n        var type = override || node.type;\n        if (node.start > pos || node.end < pos) { return }\n        baseVisitor[type](node, st, c);\n        if (test(type, node)) { throw new Found(node, st) }\n      })(node, state);\n    } catch (e) {\n      if (e instanceof Found) { return e }\n      throw e\n    }\n  }\n\n  // Find the outermost matching node after a given position.\n  function findNodeAfter(node, pos, test, baseVisitor, state) {\n    test = makeTest(test);\n    if (!baseVisitor) { baseVisitor = base; }\n    try {\n      (function c(node, st, override) {\n        if (node.end < pos) { return }\n        var type = override || node.type;\n        if (node.start >= pos && test(type, node)) { throw new Found(node, st) }\n        baseVisitor[type](node, st, c);\n      })(node, state);\n    } catch (e) {\n      if (e instanceof Found) { return e }\n      throw e\n    }\n  }\n\n  // Find the outermost matching node before a given position.\n  function findNodeBefore(node, pos, test, baseVisitor, state) {\n    test = makeTest(test);\n    if (!baseVisitor) { baseVisitor = base; }\n    var max\n    ;(function c(node, st, override) {\n      if (node.start > pos) { return }\n      var type = override || node.type;\n      if (node.end <= pos && (!max || max.node.end < node.end) && test(type, node))\n        { max = new Found(node, st); }\n      baseVisitor[type](node, st, c);\n    })(node, state);\n    return max\n  }\n\n  // Fallback to an Object.create polyfill for older environments.\n  var create = Object.create || function(proto) {\n    function Ctor() {}\n    Ctor.prototype = proto;\n    return new Ctor\n  };\n\n  // Used to create a custom walker. Will fill in all missing node\n  // type properties with the defaults.\n  function make(funcs, baseVisitor) {\n    var visitor = create(baseVisitor || base);\n    for (var type in funcs) { visitor[type] = funcs[type]; }\n    return visitor\n  }\n\n  function skipThrough(node, st, c) { c(node, st); }\n  function ignore(_node, _st, _c) {}\n\n  // Node walkers.\n\n  var base = {};\n\n  base.Program = base.BlockStatement = function (node, st, c) {\n    for (var i = 0, list = node.body; i < list.length; i += 1)\n      {\n      var stmt = list[i];\n\n      c(stmt, st, \"Statement\");\n    }\n  };\n  base.Statement = skipThrough;\n  base.EmptyStatement = ignore;\n  base.ExpressionStatement = base.ParenthesizedExpression = base.ChainExpression =\n    function (node, st, c) { return c(node.expression, st, \"Expression\"); };\n  base.IfStatement = function (node, st, c) {\n    c(node.test, st, \"Expression\");\n    c(node.consequent, st, \"Statement\");\n    if (node.alternate) { c(node.alternate, st, \"Statement\"); }\n  };\n  base.LabeledStatement = function (node, st, c) { return c(node.body, st, \"Statement\"); };\n  base.BreakStatement = base.ContinueStatement = ignore;\n  base.WithStatement = function (node, st, c) {\n    c(node.object, st, \"Expression\");\n    c(node.body, st, \"Statement\");\n  };\n  base.SwitchStatement = function (node, st, c) {\n    c(node.discriminant, st, \"Expression\");\n    for (var i$1 = 0, list$1 = node.cases; i$1 < list$1.length; i$1 += 1) {\n      var cs = list$1[i$1];\n\n      if (cs.test) { c(cs.test, st, \"Expression\"); }\n      for (var i = 0, list = cs.consequent; i < list.length; i += 1)\n        {\n        var cons = list[i];\n\n        c(cons, st, \"Statement\");\n      }\n    }\n  };\n  base.SwitchCase = function (node, st, c) {\n    if (node.test) { c(node.test, st, \"Expression\"); }\n    for (var i = 0, list = node.consequent; i < list.length; i += 1)\n      {\n      var cons = list[i];\n\n      c(cons, st, \"Statement\");\n    }\n  };\n  base.ReturnStatement = base.YieldExpression = base.AwaitExpression = function (node, st, c) {\n    if (node.argument) { c(node.argument, st, \"Expression\"); }\n  };\n  base.ThrowStatement = base.SpreadElement =\n    function (node, st, c) { return c(node.argument, st, \"Expression\"); };\n  base.TryStatement = function (node, st, c) {\n    c(node.block, st, \"Statement\");\n    if (node.handler) { c(node.handler, st); }\n    if (node.finalizer) { c(node.finalizer, st, \"Statement\"); }\n  };\n  base.CatchClause = function (node, st, c) {\n    if (node.param) { c(node.param, st, \"Pattern\"); }\n    c(node.body, st, \"Statement\");\n  };\n  base.WhileStatement = base.DoWhileStatement = function (node, st, c) {\n    c(node.test, st, \"Expression\");\n    c(node.body, st, \"Statement\");\n  };\n  base.ForStatement = function (node, st, c) {\n    if (node.init) { c(node.init, st, \"ForInit\"); }\n    if (node.test) { c(node.test, st, \"Expression\"); }\n    if (node.update) { c(node.update, st, \"Expression\"); }\n    c(node.body, st, \"Statement\");\n  };\n  base.ForInStatement = base.ForOfStatement = function (node, st, c) {\n    c(node.left, st, \"ForInit\");\n    c(node.right, st, \"Expression\");\n    c(node.body, st, \"Statement\");\n  };\n  base.ForInit = function (node, st, c) {\n    if (node.type === \"VariableDeclaration\") { c(node, st); }\n    else { c(node, st, \"Expression\"); }\n  };\n  base.DebuggerStatement = ignore;\n\n  base.FunctionDeclaration = function (node, st, c) { return c(node, st, \"Function\"); };\n  base.VariableDeclaration = function (node, st, c) {\n    for (var i = 0, list = node.declarations; i < list.length; i += 1)\n      {\n      var decl = list[i];\n\n      c(decl, st);\n    }\n  };\n  base.VariableDeclarator = function (node, st, c) {\n    c(node.id, st, \"Pattern\");\n    if (node.init) { c(node.init, st, \"Expression\"); }\n  };\n\n  base.Function = function (node, st, c) {\n    if (node.id) { c(node.id, st, \"Pattern\"); }\n    for (var i = 0, list = node.params; i < list.length; i += 1)\n      {\n      var param = list[i];\n\n      c(param, st, \"Pattern\");\n    }\n    c(node.body, st, node.expression ? \"Expression\" : \"Statement\");\n  };\n\n  base.Pattern = function (node, st, c) {\n    if (node.type === \"Identifier\")\n      { c(node, st, \"VariablePattern\"); }\n    else if (node.type === \"MemberExpression\")\n      { c(node, st, \"MemberPattern\"); }\n    else\n      { c(node, st); }\n  };\n  base.VariablePattern = ignore;\n  base.MemberPattern = skipThrough;\n  base.RestElement = function (node, st, c) { return c(node.argument, st, \"Pattern\"); };\n  base.ArrayPattern = function (node, st, c) {\n    for (var i = 0, list = node.elements; i < list.length; i += 1) {\n      var elt = list[i];\n\n      if (elt) { c(elt, st, \"Pattern\"); }\n    }\n  };\n  base.ObjectPattern = function (node, st, c) {\n    for (var i = 0, list = node.properties; i < list.length; i += 1) {\n      var prop = list[i];\n\n      if (prop.type === \"Property\") {\n        if (prop.computed) { c(prop.key, st, \"Expression\"); }\n        c(prop.value, st, \"Pattern\");\n      } else if (prop.type === \"RestElement\") {\n        c(prop.argument, st, \"Pattern\");\n      }\n    }\n  };\n\n  base.Expression = skipThrough;\n  base.ThisExpression = base.Super = base.MetaProperty = ignore;\n  base.ArrayExpression = function (node, st, c) {\n    for (var i = 0, list = node.elements; i < list.length; i += 1) {\n      var elt = list[i];\n\n      if (elt) { c(elt, st, \"Expression\"); }\n    }\n  };\n  base.ObjectExpression = function (node, st, c) {\n    for (var i = 0, list = node.properties; i < list.length; i += 1)\n      {\n      var prop = list[i];\n\n      c(prop, st);\n    }\n  };\n  base.FunctionExpression = base.ArrowFunctionExpression = base.FunctionDeclaration;\n  base.SequenceExpression = function (node, st, c) {\n    for (var i = 0, list = node.expressions; i < list.length; i += 1)\n      {\n      var expr = list[i];\n\n      c(expr, st, \"Expression\");\n    }\n  };\n  base.TemplateLiteral = function (node, st, c) {\n    for (var i = 0, list = node.quasis; i < list.length; i += 1)\n      {\n      var quasi = list[i];\n\n      c(quasi, st);\n    }\n\n    for (var i$1 = 0, list$1 = node.expressions; i$1 < list$1.length; i$1 += 1)\n      {\n      var expr = list$1[i$1];\n\n      c(expr, st, \"Expression\");\n    }\n  };\n  base.TemplateElement = ignore;\n  base.UnaryExpression = base.UpdateExpression = function (node, st, c) {\n    c(node.argument, st, \"Expression\");\n  };\n  base.BinaryExpression = base.LogicalExpression = function (node, st, c) {\n    c(node.left, st, \"Expression\");\n    c(node.right, st, \"Expression\");\n  };\n  base.AssignmentExpression = base.AssignmentPattern = function (node, st, c) {\n    c(node.left, st, \"Pattern\");\n    c(node.right, st, \"Expression\");\n  };\n  base.ConditionalExpression = function (node, st, c) {\n    c(node.test, st, \"Expression\");\n    c(node.consequent, st, \"Expression\");\n    c(node.alternate, st, \"Expression\");\n  };\n  base.NewExpression = base.CallExpression = function (node, st, c) {\n    c(node.callee, st, \"Expression\");\n    if (node.arguments)\n      { for (var i = 0, list = node.arguments; i < list.length; i += 1)\n        {\n          var arg = list[i];\n\n          c(arg, st, \"Expression\");\n        } }\n  };\n  base.MemberExpression = function (node, st, c) {\n    c(node.object, st, \"Expression\");\n    if (node.computed) { c(node.property, st, \"Expression\"); }\n  };\n  base.ExportNamedDeclaration = base.ExportDefaultDeclaration = function (node, st, c) {\n    if (node.declaration)\n      { c(node.declaration, st, node.type === \"ExportNamedDeclaration\" || node.declaration.id ? \"Statement\" : \"Expression\"); }\n    if (node.source) { c(node.source, st, \"Expression\"); }\n  };\n  base.ExportAllDeclaration = function (node, st, c) {\n    if (node.exported)\n      { c(node.exported, st); }\n    c(node.source, st, \"Expression\");\n  };\n  base.ImportDeclaration = function (node, st, c) {\n    for (var i = 0, list = node.specifiers; i < list.length; i += 1)\n      {\n      var spec = list[i];\n\n      c(spec, st);\n    }\n    c(node.source, st, \"Expression\");\n  };\n  base.ImportExpression = function (node, st, c) {\n    c(node.source, st, \"Expression\");\n  };\n  base.ImportSpecifier = base.ImportDefaultSpecifier = base.ImportNamespaceSpecifier = base.Identifier = base.Literal = ignore;\n\n  base.TaggedTemplateExpression = function (node, st, c) {\n    c(node.tag, st, \"Expression\");\n    c(node.quasi, st, \"Expression\");\n  };\n  base.ClassDeclaration = base.ClassExpression = function (node, st, c) { return c(node, st, \"Class\"); };\n  base.Class = function (node, st, c) {\n    if (node.id) { c(node.id, st, \"Pattern\"); }\n    if (node.superClass) { c(node.superClass, st, \"Expression\"); }\n    c(node.body, st);\n  };\n  base.ClassBody = function (node, st, c) {\n    for (var i = 0, list = node.body; i < list.length; i += 1)\n      {\n      var elt = list[i];\n\n      c(elt, st);\n    }\n  };\n  base.MethodDefinition = base.Property = function (node, st, c) {\n    if (node.computed) { c(node.key, st, \"Expression\"); }\n    c(node.value, st, \"Expression\");\n  };\n\n  exports.ancestor = ancestor;\n  exports.base = base;\n  exports.findNodeAfter = findNodeAfter;\n  exports.findNodeAround = findNodeAround;\n  exports.findNodeAt = findNodeAt;\n  exports.findNodeBefore = findNodeBefore;\n  exports.full = full;\n  exports.fullAncestor = fullAncestor;\n  exports.make = make;\n  exports.recursive = recursive;\n  exports.simple = simple;\n\n  Object.defineProperty(exports, '__esModule', { value: true });\n\n})));\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn-walk/dist/walk.js',
          'importMap': {},
          'packageName': 'acorn-walk',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn-walk/dist/walk.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/acorn/dist/acorn.js': {
        'globals': {
          'BigInt': 'read',
          'define': 'read',
        },
        'moduleRecord': {
          'content': "(function (global, factory) {\n  typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :\n  typeof define === 'function' && define.amd ? define(['exports'], factory) :\n  (global = global || self, factory(global.acorn = {}));\n}(this, (function (exports) { 'use strict';\n\n  // Reserved word lists for various dialects of the language\n\n  var reservedWords = {\n    3: \"abstract boolean byte char class double enum export extends final float goto implements import int interface long native package private protected public short static super synchronized throws transient volatile\",\n    5: \"class enum extends super const export import\",\n    6: \"enum\",\n    strict: \"implements interface let package private protected public static yield\",\n    strictBind: \"eval arguments\"\n  };\n\n  // And the keywords\n\n  var ecma5AndLessKeywords = \"break case catch continue debugger default do else finally for function if return switch throw try var while with null true false instanceof typeof void delete new in this\";\n\n  var keywords = {\n    5: ecma5AndLessKeywords,\n    \"5module\": ecma5AndLessKeywords + \" export import\",\n    6: ecma5AndLessKeywords + \" const class extends export import super\"\n  };\n\n  var keywordRelationalOperator = /^in(stanceof)?$/;\n\n  // ## Character categories\n\n  // Big ugly regular expressions that match characters in the\n  // whitespace, identifier, and identifier-start categories. These\n  // are only applied when a character is found to actually have a\n  // code point above 128.\n  // Generated by `bin/generate-identifier-regex.js`.\n  var nonASCIIidentifierStartChars = \"\\xaa\\xb5\\xba\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02c1\\u02c6-\\u02d1\\u02e0-\\u02e4\\u02ec\\u02ee\\u0370-\\u0374\\u0376\\u0377\\u037a-\\u037d\\u037f\\u0386\\u0388-\\u038a\\u038c\\u038e-\\u03a1\\u03a3-\\u03f5\\u03f7-\\u0481\\u048a-\\u052f\\u0531-\\u0556\\u0559\\u0560-\\u0588\\u05d0-\\u05ea\\u05ef-\\u05f2\\u0620-\\u064a\\u066e\\u066f\\u0671-\\u06d3\\u06d5\\u06e5\\u06e6\\u06ee\\u06ef\\u06fa-\\u06fc\\u06ff\\u0710\\u0712-\\u072f\\u074d-\\u07a5\\u07b1\\u07ca-\\u07ea\\u07f4\\u07f5\\u07fa\\u0800-\\u0815\\u081a\\u0824\\u0828\\u0840-\\u0858\\u0860-\\u086a\\u08a0-\\u08b4\\u08b6-\\u08c7\\u0904-\\u0939\\u093d\\u0950\\u0958-\\u0961\\u0971-\\u0980\\u0985-\\u098c\\u098f\\u0990\\u0993-\\u09a8\\u09aa-\\u09b0\\u09b2\\u09b6-\\u09b9\\u09bd\\u09ce\\u09dc\\u09dd\\u09df-\\u09e1\\u09f0\\u09f1\\u09fc\\u0a05-\\u0a0a\\u0a0f\\u0a10\\u0a13-\\u0a28\\u0a2a-\\u0a30\\u0a32\\u0a33\\u0a35\\u0a36\\u0a38\\u0a39\\u0a59-\\u0a5c\\u0a5e\\u0a72-\\u0a74\\u0a85-\\u0a8d\\u0a8f-\\u0a91\\u0a93-\\u0aa8\\u0aaa-\\u0ab0\\u0ab2\\u0ab3\\u0ab5-\\u0ab9\\u0abd\\u0ad0\\u0ae0\\u0ae1\\u0af9\\u0b05-\\u0b0c\\u0b0f\\u0b10\\u0b13-\\u0b28\\u0b2a-\\u0b30\\u0b32\\u0b33\\u0b35-\\u0b39\\u0b3d\\u0b5c\\u0b5d\\u0b5f-\\u0b61\\u0b71\\u0b83\\u0b85-\\u0b8a\\u0b8e-\\u0b90\\u0b92-\\u0b95\\u0b99\\u0b9a\\u0b9c\\u0b9e\\u0b9f\\u0ba3\\u0ba4\\u0ba8-\\u0baa\\u0bae-\\u0bb9\\u0bd0\\u0c05-\\u0c0c\\u0c0e-\\u0c10\\u0c12-\\u0c28\\u0c2a-\\u0c39\\u0c3d\\u0c58-\\u0c5a\\u0c60\\u0c61\\u0c80\\u0c85-\\u0c8c\\u0c8e-\\u0c90\\u0c92-\\u0ca8\\u0caa-\\u0cb3\\u0cb5-\\u0cb9\\u0cbd\\u0cde\\u0ce0\\u0ce1\\u0cf1\\u0cf2\\u0d04-\\u0d0c\\u0d0e-\\u0d10\\u0d12-\\u0d3a\\u0d3d\\u0d4e\\u0d54-\\u0d56\\u0d5f-\\u0d61\\u0d7a-\\u0d7f\\u0d85-\\u0d96\\u0d9a-\\u0db1\\u0db3-\\u0dbb\\u0dbd\\u0dc0-\\u0dc6\\u0e01-\\u0e30\\u0e32\\u0e33\\u0e40-\\u0e46\\u0e81\\u0e82\\u0e84\\u0e86-\\u0e8a\\u0e8c-\\u0ea3\\u0ea5\\u0ea7-\\u0eb0\\u0eb2\\u0eb3\\u0ebd\\u0ec0-\\u0ec4\\u0ec6\\u0edc-\\u0edf\\u0f00\\u0f40-\\u0f47\\u0f49-\\u0f6c\\u0f88-\\u0f8c\\u1000-\\u102a\\u103f\\u1050-\\u1055\\u105a-\\u105d\\u1061\\u1065\\u1066\\u106e-\\u1070\\u1075-\\u1081\\u108e\\u10a0-\\u10c5\\u10c7\\u10cd\\u10d0-\\u10fa\\u10fc-\\u1248\\u124a-\\u124d\\u1250-\\u1256\\u1258\\u125a-\\u125d\\u1260-\\u1288\\u128a-\\u128d\\u1290-\\u12b0\\u12b2-\\u12b5\\u12b8-\\u12be\\u12c0\\u12c2-\\u12c5\\u12c8-\\u12d6\\u12d8-\\u1310\\u1312-\\u1315\\u1318-\\u135a\\u1380-\\u138f\\u13a0-\\u13f5\\u13f8-\\u13fd\\u1401-\\u166c\\u166f-\\u167f\\u1681-\\u169a\\u16a0-\\u16ea\\u16ee-\\u16f8\\u1700-\\u170c\\u170e-\\u1711\\u1720-\\u1731\\u1740-\\u1751\\u1760-\\u176c\\u176e-\\u1770\\u1780-\\u17b3\\u17d7\\u17dc\\u1820-\\u1878\\u1880-\\u18a8\\u18aa\\u18b0-\\u18f5\\u1900-\\u191e\\u1950-\\u196d\\u1970-\\u1974\\u1980-\\u19ab\\u19b0-\\u19c9\\u1a00-\\u1a16\\u1a20-\\u1a54\\u1aa7\\u1b05-\\u1b33\\u1b45-\\u1b4b\\u1b83-\\u1ba0\\u1bae\\u1baf\\u1bba-\\u1be5\\u1c00-\\u1c23\\u1c4d-\\u1c4f\\u1c5a-\\u1c7d\\u1c80-\\u1c88\\u1c90-\\u1cba\\u1cbd-\\u1cbf\\u1ce9-\\u1cec\\u1cee-\\u1cf3\\u1cf5\\u1cf6\\u1cfa\\u1d00-\\u1dbf\\u1e00-\\u1f15\\u1f18-\\u1f1d\\u1f20-\\u1f45\\u1f48-\\u1f4d\\u1f50-\\u1f57\\u1f59\\u1f5b\\u1f5d\\u1f5f-\\u1f7d\\u1f80-\\u1fb4\\u1fb6-\\u1fbc\\u1fbe\\u1fc2-\\u1fc4\\u1fc6-\\u1fcc\\u1fd0-\\u1fd3\\u1fd6-\\u1fdb\\u1fe0-\\u1fec\\u1ff2-\\u1ff4\\u1ff6-\\u1ffc\\u2071\\u207f\\u2090-\\u209c\\u2102\\u2107\\u210a-\\u2113\\u2115\\u2118-\\u211d\\u2124\\u2126\\u2128\\u212a-\\u2139\\u213c-\\u213f\\u2145-\\u2149\\u214e\\u2160-\\u2188\\u2c00-\\u2c2e\\u2c30-\\u2c5e\\u2c60-\\u2ce4\\u2ceb-\\u2cee\\u2cf2\\u2cf3\\u2d00-\\u2d25\\u2d27\\u2d2d\\u2d30-\\u2d67\\u2d6f\\u2d80-\\u2d96\\u2da0-\\u2da6\\u2da8-\\u2dae\\u2db0-\\u2db6\\u2db8-\\u2dbe\\u2dc0-\\u2dc6\\u2dc8-\\u2dce\\u2dd0-\\u2dd6\\u2dd8-\\u2dde\\u3005-\\u3007\\u3021-\\u3029\\u3031-\\u3035\\u3038-\\u303c\\u3041-\\u3096\\u309b-\\u309f\\u30a1-\\u30fa\\u30fc-\\u30ff\\u3105-\\u312f\\u3131-\\u318e\\u31a0-\\u31bf\\u31f0-\\u31ff\\u3400-\\u4dbf\\u4e00-\\u9ffc\\ua000-\\ua48c\\ua4d0-\\ua4fd\\ua500-\\ua60c\\ua610-\\ua61f\\ua62a\\ua62b\\ua640-\\ua66e\\ua67f-\\ua69d\\ua6a0-\\ua6ef\\ua717-\\ua71f\\ua722-\\ua788\\ua78b-\\ua7bf\\ua7c2-\\ua7ca\\ua7f5-\\ua801\\ua803-\\ua805\\ua807-\\ua80a\\ua80c-\\ua822\\ua840-\\ua873\\ua882-\\ua8b3\\ua8f2-\\ua8f7\\ua8fb\\ua8fd\\ua8fe\\ua90a-\\ua925\\ua930-\\ua946\\ua960-\\ua97c\\ua984-\\ua9b2\\ua9cf\\ua9e0-\\ua9e4\\ua9e6-\\ua9ef\\ua9fa-\\ua9fe\\uaa00-\\uaa28\\uaa40-\\uaa42\\uaa44-\\uaa4b\\uaa60-\\uaa76\\uaa7a\\uaa7e-\\uaaaf\\uaab1\\uaab5\\uaab6\\uaab9-\\uaabd\\uaac0\\uaac2\\uaadb-\\uaadd\\uaae0-\\uaaea\\uaaf2-\\uaaf4\\uab01-\\uab06\\uab09-\\uab0e\\uab11-\\uab16\\uab20-\\uab26\\uab28-\\uab2e\\uab30-\\uab5a\\uab5c-\\uab69\\uab70-\\uabe2\\uac00-\\ud7a3\\ud7b0-\\ud7c6\\ud7cb-\\ud7fb\\uf900-\\ufa6d\\ufa70-\\ufad9\\ufb00-\\ufb06\\ufb13-\\ufb17\\ufb1d\\ufb1f-\\ufb28\\ufb2a-\\ufb36\\ufb38-\\ufb3c\\ufb3e\\ufb40\\ufb41\\ufb43\\ufb44\\ufb46-\\ufbb1\\ufbd3-\\ufd3d\\ufd50-\\ufd8f\\ufd92-\\ufdc7\\ufdf0-\\ufdfb\\ufe70-\\ufe74\\ufe76-\\ufefc\\uff21-\\uff3a\\uff41-\\uff5a\\uff66-\\uffbe\\uffc2-\\uffc7\\uffca-\\uffcf\\uffd2-\\uffd7\\uffda-\\uffdc\";\n  var nonASCIIidentifierChars = \"\\u200c\\u200d\\xb7\\u0300-\\u036f\\u0387\\u0483-\\u0487\\u0591-\\u05bd\\u05bf\\u05c1\\u05c2\\u05c4\\u05c5\\u05c7\\u0610-\\u061a\\u064b-\\u0669\\u0670\\u06d6-\\u06dc\\u06df-\\u06e4\\u06e7\\u06e8\\u06ea-\\u06ed\\u06f0-\\u06f9\\u0711\\u0730-\\u074a\\u07a6-\\u07b0\\u07c0-\\u07c9\\u07eb-\\u07f3\\u07fd\\u0816-\\u0819\\u081b-\\u0823\\u0825-\\u0827\\u0829-\\u082d\\u0859-\\u085b\\u08d3-\\u08e1\\u08e3-\\u0903\\u093a-\\u093c\\u093e-\\u094f\\u0951-\\u0957\\u0962\\u0963\\u0966-\\u096f\\u0981-\\u0983\\u09bc\\u09be-\\u09c4\\u09c7\\u09c8\\u09cb-\\u09cd\\u09d7\\u09e2\\u09e3\\u09e6-\\u09ef\\u09fe\\u0a01-\\u0a03\\u0a3c\\u0a3e-\\u0a42\\u0a47\\u0a48\\u0a4b-\\u0a4d\\u0a51\\u0a66-\\u0a71\\u0a75\\u0a81-\\u0a83\\u0abc\\u0abe-\\u0ac5\\u0ac7-\\u0ac9\\u0acb-\\u0acd\\u0ae2\\u0ae3\\u0ae6-\\u0aef\\u0afa-\\u0aff\\u0b01-\\u0b03\\u0b3c\\u0b3e-\\u0b44\\u0b47\\u0b48\\u0b4b-\\u0b4d\\u0b55-\\u0b57\\u0b62\\u0b63\\u0b66-\\u0b6f\\u0b82\\u0bbe-\\u0bc2\\u0bc6-\\u0bc8\\u0bca-\\u0bcd\\u0bd7\\u0be6-\\u0bef\\u0c00-\\u0c04\\u0c3e-\\u0c44\\u0c46-\\u0c48\\u0c4a-\\u0c4d\\u0c55\\u0c56\\u0c62\\u0c63\\u0c66-\\u0c6f\\u0c81-\\u0c83\\u0cbc\\u0cbe-\\u0cc4\\u0cc6-\\u0cc8\\u0cca-\\u0ccd\\u0cd5\\u0cd6\\u0ce2\\u0ce3\\u0ce6-\\u0cef\\u0d00-\\u0d03\\u0d3b\\u0d3c\\u0d3e-\\u0d44\\u0d46-\\u0d48\\u0d4a-\\u0d4d\\u0d57\\u0d62\\u0d63\\u0d66-\\u0d6f\\u0d81-\\u0d83\\u0dca\\u0dcf-\\u0dd4\\u0dd6\\u0dd8-\\u0ddf\\u0de6-\\u0def\\u0df2\\u0df3\\u0e31\\u0e34-\\u0e3a\\u0e47-\\u0e4e\\u0e50-\\u0e59\\u0eb1\\u0eb4-\\u0ebc\\u0ec8-\\u0ecd\\u0ed0-\\u0ed9\\u0f18\\u0f19\\u0f20-\\u0f29\\u0f35\\u0f37\\u0f39\\u0f3e\\u0f3f\\u0f71-\\u0f84\\u0f86\\u0f87\\u0f8d-\\u0f97\\u0f99-\\u0fbc\\u0fc6\\u102b-\\u103e\\u1040-\\u1049\\u1056-\\u1059\\u105e-\\u1060\\u1062-\\u1064\\u1067-\\u106d\\u1071-\\u1074\\u1082-\\u108d\\u108f-\\u109d\\u135d-\\u135f\\u1369-\\u1371\\u1712-\\u1714\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17b4-\\u17d3\\u17dd\\u17e0-\\u17e9\\u180b-\\u180d\\u1810-\\u1819\\u18a9\\u1920-\\u192b\\u1930-\\u193b\\u1946-\\u194f\\u19d0-\\u19da\\u1a17-\\u1a1b\\u1a55-\\u1a5e\\u1a60-\\u1a7c\\u1a7f-\\u1a89\\u1a90-\\u1a99\\u1ab0-\\u1abd\\u1abf\\u1ac0\\u1b00-\\u1b04\\u1b34-\\u1b44\\u1b50-\\u1b59\\u1b6b-\\u1b73\\u1b80-\\u1b82\\u1ba1-\\u1bad\\u1bb0-\\u1bb9\\u1be6-\\u1bf3\\u1c24-\\u1c37\\u1c40-\\u1c49\\u1c50-\\u1c59\\u1cd0-\\u1cd2\\u1cd4-\\u1ce8\\u1ced\\u1cf4\\u1cf7-\\u1cf9\\u1dc0-\\u1df9\\u1dfb-\\u1dff\\u203f\\u2040\\u2054\\u20d0-\\u20dc\\u20e1\\u20e5-\\u20f0\\u2cef-\\u2cf1\\u2d7f\\u2de0-\\u2dff\\u302a-\\u302f\\u3099\\u309a\\ua620-\\ua629\\ua66f\\ua674-\\ua67d\\ua69e\\ua69f\\ua6f0\\ua6f1\\ua802\\ua806\\ua80b\\ua823-\\ua827\\ua82c\\ua880\\ua881\\ua8b4-\\ua8c5\\ua8d0-\\ua8d9\\ua8e0-\\ua8f1\\ua8ff-\\ua909\\ua926-\\ua92d\\ua947-\\ua953\\ua980-\\ua983\\ua9b3-\\ua9c0\\ua9d0-\\ua9d9\\ua9e5\\ua9f0-\\ua9f9\\uaa29-\\uaa36\\uaa43\\uaa4c\\uaa4d\\uaa50-\\uaa59\\uaa7b-\\uaa7d\\uaab0\\uaab2-\\uaab4\\uaab7\\uaab8\\uaabe\\uaabf\\uaac1\\uaaeb-\\uaaef\\uaaf5\\uaaf6\\uabe3-\\uabea\\uabec\\uabed\\uabf0-\\uabf9\\ufb1e\\ufe00-\\ufe0f\\ufe20-\\ufe2f\\ufe33\\ufe34\\ufe4d-\\ufe4f\\uff10-\\uff19\\uff3f\";\n\n  var nonASCIIidentifierStart = new RegExp(\"[\" + nonASCIIidentifierStartChars + \"]\");\n  var nonASCIIidentifier = new RegExp(\"[\" + nonASCIIidentifierStartChars + nonASCIIidentifierChars + \"]\");\n\n  nonASCIIidentifierStartChars = nonASCIIidentifierChars = null;\n\n  // These are a run-length and offset encoded representation of the\n  // >0xffff code points that are a valid part of identifiers. The\n  // offset starts at 0x10000, and each pair of numbers represents an\n  // offset to the next range, and then a size of the range. They were\n  // generated by bin/generate-identifier-regex.js\n\n  // eslint-disable-next-line comma-spacing\n  var astralIdentifierStartCodes = [0,11,2,25,2,18,2,1,2,14,3,13,35,122,70,52,268,28,4,48,48,31,14,29,6,37,11,29,3,35,5,7,2,4,43,157,19,35,5,35,5,39,9,51,157,310,10,21,11,7,153,5,3,0,2,43,2,1,4,0,3,22,11,22,10,30,66,18,2,1,11,21,11,25,71,55,7,1,65,0,16,3,2,2,2,28,43,28,4,28,36,7,2,27,28,53,11,21,11,18,14,17,111,72,56,50,14,50,14,35,349,41,7,1,79,28,11,0,9,21,107,20,28,22,13,52,76,44,33,24,27,35,30,0,3,0,9,34,4,0,13,47,15,3,22,0,2,0,36,17,2,24,85,6,2,0,2,3,2,14,2,9,8,46,39,7,3,1,3,21,2,6,2,1,2,4,4,0,19,0,13,4,159,52,19,3,21,2,31,47,21,1,2,0,185,46,42,3,37,47,21,0,60,42,14,0,72,26,230,43,117,63,32,7,3,0,3,7,2,1,2,23,16,0,2,0,95,7,3,38,17,0,2,0,29,0,11,39,8,0,22,0,12,45,20,0,35,56,264,8,2,36,18,0,50,29,113,6,2,1,2,37,22,0,26,5,2,1,2,31,15,0,328,18,190,0,80,921,103,110,18,195,2749,1070,4050,582,8634,568,8,30,114,29,19,47,17,3,32,20,6,18,689,63,129,74,6,0,67,12,65,1,2,0,29,6135,9,1237,43,8,8952,286,50,2,18,3,9,395,2309,106,6,12,4,8,8,9,5991,84,2,70,2,1,3,0,3,1,3,3,2,11,2,0,2,6,2,64,2,3,3,7,2,6,2,27,2,3,2,4,2,0,4,6,2,339,3,24,2,24,2,30,2,24,2,30,2,24,2,30,2,24,2,30,2,24,2,7,2357,44,11,6,17,0,370,43,1301,196,60,67,8,0,1205,3,2,26,2,1,2,0,3,0,2,9,2,3,2,0,2,0,7,0,5,0,2,0,2,0,2,2,2,1,2,0,3,0,2,0,2,0,2,0,2,0,2,1,2,0,3,3,2,6,2,3,2,3,2,0,2,9,2,16,6,2,2,4,2,16,4421,42717,35,4148,12,221,3,5761,15,7472,3104,541,1507,4938];\n\n  // eslint-disable-next-line comma-spacing\n  var astralIdentifierCodes = [509,0,227,0,150,4,294,9,1368,2,2,1,6,3,41,2,5,0,166,1,574,3,9,9,370,1,154,10,176,2,54,14,32,9,16,3,46,10,54,9,7,2,37,13,2,9,6,1,45,0,13,2,49,13,9,3,2,11,83,11,7,0,161,11,6,9,7,3,56,1,2,6,3,1,3,2,10,0,11,1,3,6,4,4,193,17,10,9,5,0,82,19,13,9,214,6,3,8,28,1,83,16,16,9,82,12,9,9,84,14,5,9,243,14,166,9,71,5,2,1,3,3,2,0,2,1,13,9,120,6,3,6,4,0,29,9,41,6,2,3,9,0,10,10,47,15,406,7,2,7,17,9,57,21,2,13,123,5,4,0,2,1,2,6,2,0,9,9,49,4,2,1,2,4,9,9,330,3,19306,9,135,4,60,6,26,9,1014,0,2,54,8,3,82,0,12,1,19628,1,5319,4,4,5,9,7,3,6,31,3,149,2,1418,49,513,54,5,49,9,0,15,0,23,4,2,14,1361,6,2,16,3,6,2,1,2,4,262,6,10,9,419,13,1495,6,110,6,6,9,4759,9,787719,239];\n\n  // This has a complexity linear to the value of the code. The\n  // assumption is that looking up astral identifier characters is\n  // rare.\n  function isInAstralSet(code, set) {\n    var pos = 0x10000;\n    for (var i = 0; i < set.length; i += 2) {\n      pos += set[i];\n      if (pos > code) { return false }\n      pos += set[i + 1];\n      if (pos >= code) { return true }\n    }\n  }\n\n  // Test whether a given character code starts an identifier.\n\n  function isIdentifierStart(code, astral) {\n    if (code < 65) { return code === 36 }\n    if (code < 91) { return true }\n    if (code < 97) { return code === 95 }\n    if (code < 123) { return true }\n    if (code <= 0xffff) { return code >= 0xaa && nonASCIIidentifierStart.test(String.fromCharCode(code)) }\n    if (astral === false) { return false }\n    return isInAstralSet(code, astralIdentifierStartCodes)\n  }\n\n  // Test whether a given character is part of an identifier.\n\n  function isIdentifierChar(code, astral) {\n    if (code < 48) { return code === 36 }\n    if (code < 58) { return true }\n    if (code < 65) { return false }\n    if (code < 91) { return true }\n    if (code < 97) { return code === 95 }\n    if (code < 123) { return true }\n    if (code <= 0xffff) { return code >= 0xaa && nonASCIIidentifier.test(String.fromCharCode(code)) }\n    if (astral === false) { return false }\n    return isInAstralSet(code, astralIdentifierStartCodes) || isInAstralSet(code, astralIdentifierCodes)\n  }\n\n  // ## Token types\n\n  // The assignment of fine-grained, information-carrying type objects\n  // allows the tokenizer to store the information it has about a\n  // token in a way that is very cheap for the parser to look up.\n\n  // All token type variables start with an underscore, to make them\n  // easy to recognize.\n\n  // The `beforeExpr` property is used to disambiguate between regular\n  // expressions and divisions. It is set on all token types that can\n  // be followed by an expression (thus, a slash after them would be a\n  // regular expression).\n  //\n  // The `startsExpr` property is used to check if the token ends a\n  // `yield` expression. It is set on all token types that either can\n  // directly start an expression (like a quotation mark) or can\n  // continue an expression (like the body of a string).\n  //\n  // `isLoop` marks a keyword as starting a loop, which is important\n  // to know when parsing a label, in order to allow or disallow\n  // continue jumps to that label.\n\n  var TokenType = function TokenType(label, conf) {\n    if ( conf === void 0 ) conf = {};\n\n    this.label = label;\n    this.keyword = conf.keyword;\n    this.beforeExpr = !!conf.beforeExpr;\n    this.startsExpr = !!conf.startsExpr;\n    this.isLoop = !!conf.isLoop;\n    this.isAssign = !!conf.isAssign;\n    this.prefix = !!conf.prefix;\n    this.postfix = !!conf.postfix;\n    this.binop = conf.binop || null;\n    this.updateContext = null;\n  };\n\n  function binop(name, prec) {\n    return new TokenType(name, {beforeExpr: true, binop: prec})\n  }\n  var beforeExpr = {beforeExpr: true}, startsExpr = {startsExpr: true};\n\n  // Map keyword names to token types.\n\n  var keywords$1 = {};\n\n  // Succinct definitions of keyword token types\n  function kw(name, options) {\n    if ( options === void 0 ) options = {};\n\n    options.keyword = name;\n    return keywords$1[name] = new TokenType(name, options)\n  }\n\n  var types = {\n    num: new TokenType(\"num\", startsExpr),\n    regexp: new TokenType(\"regexp\", startsExpr),\n    string: new TokenType(\"string\", startsExpr),\n    name: new TokenType(\"name\", startsExpr),\n    eof: new TokenType(\"eof\"),\n\n    // Punctuation token types.\n    bracketL: new TokenType(\"[\", {beforeExpr: true, startsExpr: true}),\n    bracketR: new TokenType(\"]\"),\n    braceL: new TokenType(\"{\", {beforeExpr: true, startsExpr: true}),\n    braceR: new TokenType(\"}\"),\n    parenL: new TokenType(\"(\", {beforeExpr: true, startsExpr: true}),\n    parenR: new TokenType(\")\"),\n    comma: new TokenType(\",\", beforeExpr),\n    semi: new TokenType(\";\", beforeExpr),\n    colon: new TokenType(\":\", beforeExpr),\n    dot: new TokenType(\".\"),\n    question: new TokenType(\"?\", beforeExpr),\n    questionDot: new TokenType(\"?.\"),\n    arrow: new TokenType(\"=>\", beforeExpr),\n    template: new TokenType(\"template\"),\n    invalidTemplate: new TokenType(\"invalidTemplate\"),\n    ellipsis: new TokenType(\"...\", beforeExpr),\n    backQuote: new TokenType(\"`\", startsExpr),\n    dollarBraceL: new TokenType(\"${\", {beforeExpr: true, startsExpr: true}),\n\n    // Operators. These carry several kinds of properties to help the\n    // parser use them properly (the presence of these properties is\n    // what categorizes them as operators).\n    //\n    // `binop`, when present, specifies that this operator is a binary\n    // operator, and will refer to its precedence.\n    //\n    // `prefix` and `postfix` mark the operator as a prefix or postfix\n    // unary operator.\n    //\n    // `isAssign` marks all of `=`, `+=`, `-=` etcetera, which act as\n    // binary operators with a very low precedence, that should result\n    // in AssignmentExpression nodes.\n\n    eq: new TokenType(\"=\", {beforeExpr: true, isAssign: true}),\n    assign: new TokenType(\"_=\", {beforeExpr: true, isAssign: true}),\n    incDec: new TokenType(\"++/--\", {prefix: true, postfix: true, startsExpr: true}),\n    prefix: new TokenType(\"!/~\", {beforeExpr: true, prefix: true, startsExpr: true}),\n    logicalOR: binop(\"||\", 1),\n    logicalAND: binop(\"&&\", 2),\n    bitwiseOR: binop(\"|\", 3),\n    bitwiseXOR: binop(\"^\", 4),\n    bitwiseAND: binop(\"&\", 5),\n    equality: binop(\"==/!=/===/!==\", 6),\n    relational: binop(\"</>/<=/>=\", 7),\n    bitShift: binop(\"<</>>/>>>\", 8),\n    plusMin: new TokenType(\"+/-\", {beforeExpr: true, binop: 9, prefix: true, startsExpr: true}),\n    modulo: binop(\"%\", 10),\n    star: binop(\"*\", 10),\n    slash: binop(\"/\", 10),\n    starstar: new TokenType(\"**\", {beforeExpr: true}),\n    coalesce: binop(\"??\", 1),\n\n    // Keyword token types.\n    _break: kw(\"break\"),\n    _case: kw(\"case\", beforeExpr),\n    _catch: kw(\"catch\"),\n    _continue: kw(\"continue\"),\n    _debugger: kw(\"debugger\"),\n    _default: kw(\"default\", beforeExpr),\n    _do: kw(\"do\", {isLoop: true, beforeExpr: true}),\n    _else: kw(\"else\", beforeExpr),\n    _finally: kw(\"finally\"),\n    _for: kw(\"for\", {isLoop: true}),\n    _function: kw(\"function\", startsExpr),\n    _if: kw(\"if\"),\n    _return: kw(\"return\", beforeExpr),\n    _switch: kw(\"switch\"),\n    _throw: kw(\"throw\", beforeExpr),\n    _try: kw(\"try\"),\n    _var: kw(\"var\"),\n    _const: kw(\"const\"),\n    _while: kw(\"while\", {isLoop: true}),\n    _with: kw(\"with\"),\n    _new: kw(\"new\", {beforeExpr: true, startsExpr: true}),\n    _this: kw(\"this\", startsExpr),\n    _super: kw(\"super\", startsExpr),\n    _class: kw(\"class\", startsExpr),\n    _extends: kw(\"extends\", beforeExpr),\n    _export: kw(\"export\"),\n    _import: kw(\"import\", startsExpr),\n    _null: kw(\"null\", startsExpr),\n    _true: kw(\"true\", startsExpr),\n    _false: kw(\"false\", startsExpr),\n    _in: kw(\"in\", {beforeExpr: true, binop: 7}),\n    _instanceof: kw(\"instanceof\", {beforeExpr: true, binop: 7}),\n    _typeof: kw(\"typeof\", {beforeExpr: true, prefix: true, startsExpr: true}),\n    _void: kw(\"void\", {beforeExpr: true, prefix: true, startsExpr: true}),\n    _delete: kw(\"delete\", {beforeExpr: true, prefix: true, startsExpr: true})\n  };\n\n  // Matches a whole line break (where CRLF is considered a single\n  // line break). Used to count lines.\n\n  var lineBreak = /\\r\\n?|\\n|\\u2028|\\u2029/;\n  var lineBreakG = new RegExp(lineBreak.source, \"g\");\n\n  function isNewLine(code, ecma2019String) {\n    return code === 10 || code === 13 || (!ecma2019String && (code === 0x2028 || code === 0x2029))\n  }\n\n  var nonASCIIwhitespace = /[\\u1680\\u2000-\\u200a\\u202f\\u205f\\u3000\\ufeff]/;\n\n  var skipWhiteSpace = /(?:\\s|\\/\\/.*|\\/\\*[^]*?\\*\\/)*/g;\n\n  var ref = Object.prototype;\n  var hasOwnProperty = ref.hasOwnProperty;\n  var toString = ref.toString;\n\n  // Checks if an object has a property.\n\n  function has(obj, propName) {\n    return hasOwnProperty.call(obj, propName)\n  }\n\n  var isArray = Array.isArray || (function (obj) { return (\n    toString.call(obj) === \"[object Array]\"\n  ); });\n\n  function wordsRegexp(words) {\n    return new RegExp(\"^(?:\" + words.replace(/ /g, \"|\") + \")$\")\n  }\n\n  // These are used when `options.locations` is on, for the\n  // `startLoc` and `endLoc` properties.\n\n  var Position = function Position(line, col) {\n    this.line = line;\n    this.column = col;\n  };\n\n  Position.prototype.offset = function offset (n) {\n    return new Position(this.line, this.column + n)\n  };\n\n  var SourceLocation = function SourceLocation(p, start, end) {\n    this.start = start;\n    this.end = end;\n    if (p.sourceFile !== null) { this.source = p.sourceFile; }\n  };\n\n  // The `getLineInfo` function is mostly useful when the\n  // `locations` option is off (for performance reasons) and you\n  // want to find the line/column position for a given character\n  // offset. `input` should be the code string that the offset refers\n  // into.\n\n  function getLineInfo(input, offset) {\n    for (var line = 1, cur = 0;;) {\n      lineBreakG.lastIndex = cur;\n      var match = lineBreakG.exec(input);\n      if (match && match.index < offset) {\n        ++line;\n        cur = match.index + match[0].length;\n      } else {\n        return new Position(line, offset - cur)\n      }\n    }\n  }\n\n  // A second optional argument can be given to further configure\n  // the parser process. These options are recognized:\n\n  var defaultOptions = {\n    // `ecmaVersion` indicates the ECMAScript version to parse. Must be\n    // either 3, 5, 6 (2015), 7 (2016), 8 (2017), 9 (2018), or 10\n    // (2019). This influences support for strict mode, the set of\n    // reserved words, and support for new syntax features. The default\n    // is 10.\n    ecmaVersion: 10,\n    // `sourceType` indicates the mode the code should be parsed in.\n    // Can be either `\"script\"` or `\"module\"`. This influences global\n    // strict mode and parsing of `import` and `export` declarations.\n    sourceType: \"script\",\n    // `onInsertedSemicolon` can be a callback that will be called\n    // when a semicolon is automatically inserted. It will be passed\n    // the position of the comma as an offset, and if `locations` is\n    // enabled, it is given the location as a `{line, column}` object\n    // as second argument.\n    onInsertedSemicolon: null,\n    // `onTrailingComma` is similar to `onInsertedSemicolon`, but for\n    // trailing commas.\n    onTrailingComma: null,\n    // By default, reserved words are only enforced if ecmaVersion >= 5.\n    // Set `allowReserved` to a boolean value to explicitly turn this on\n    // an off. When this option has the value \"never\", reserved words\n    // and keywords can also not be used as property names.\n    allowReserved: null,\n    // When enabled, a return at the top level is not considered an\n    // error.\n    allowReturnOutsideFunction: false,\n    // When enabled, import/export statements are not constrained to\n    // appearing at the top of the program.\n    allowImportExportEverywhere: false,\n    // When enabled, await identifiers are allowed to appear at the top-level scope,\n    // but they are still not allowed in non-async functions.\n    allowAwaitOutsideFunction: false,\n    // When enabled, hashbang directive in the beginning of file\n    // is allowed and treated as a line comment.\n    allowHashBang: false,\n    // When `locations` is on, `loc` properties holding objects with\n    // `start` and `end` properties in `{line, column}` form (with\n    // line being 1-based and column 0-based) will be attached to the\n    // nodes.\n    locations: false,\n    // A function can be passed as `onToken` option, which will\n    // cause Acorn to call that function with object in the same\n    // format as tokens returned from `tokenizer().getToken()`. Note\n    // that you are not allowed to call the parser from the\n    // callbackthat will corrupt its internal state.\n    onToken: null,\n    // A function can be passed as `onComment` option, which will\n    // cause Acorn to call that function with `(block, text, start,\n    // end)` parameters whenever a comment is skipped. `block` is a\n    // boolean indicating whether this is a block (`/* */`) comment,\n    // `text` is the content of the comment, and `start` and `end` are\n    // character offsets that denote the start and end of the comment.\n    // When the `locations` option is on, two more parameters are\n    // passed, the full `{line, column}` locations of the start and\n    // end of the comments. Note that you are not allowed to call the\n    // parser from the callbackthat will corrupt its internal state.\n    onComment: null,\n    // Nodes have their start and end characters offsets recorded in\n    // `start` and `end` properties (directly on the node, rather than\n    // the `loc` object, which holds line/column data. To also add a\n    // [semi-standardized][range] `range` property holding a `[start,\n    // end]` array with the same numbers, set the `ranges` option to\n    // `true`.\n    //\n    // [range]: https://bugzilla.mozilla.org/show_bug.cgi?id=745678\n    ranges: false,\n    // It is possible to parse multiple files into a single AST by\n    // passing the tree produced by parsing the first file as\n    // `program` option in subsequent parses. This will add the\n    // toplevel forms of the parsed file to the `Program` (top) node\n    // of an existing parse tree.\n    program: null,\n    // When `locations` is on, you can pass this to record the source\n    // file in every node's `loc` object.\n    sourceFile: null,\n    // This value, if given, is stored in every node, whether\n    // `locations` is on or off.\n    directSourceFile: null,\n    // When enabled, parenthesized expressions are represented by\n    // (non-standard) ParenthesizedExpression nodes\n    preserveParens: false\n  };\n\n  // Interpret and default an options object\n\n  function getOptions(opts) {\n    var options = {};\n\n    for (var opt in defaultOptions)\n      { options[opt] = opts && has(opts, opt) ? opts[opt] : defaultOptions[opt]; }\n\n    if (options.ecmaVersion >= 2015)\n      { options.ecmaVersion -= 2009; }\n\n    if (options.allowReserved == null)\n      { options.allowReserved = options.ecmaVersion < 5; }\n\n    if (isArray(options.onToken)) {\n      var tokens = options.onToken;\n      options.onToken = function (token) { return tokens.push(token); };\n    }\n    if (isArray(options.onComment))\n      { options.onComment = pushComment(options, options.onComment); }\n\n    return options\n  }\n\n  function pushComment(options, array) {\n    return function(block, text, start, end, startLoc, endLoc) {\n      var comment = {\n        type: block ? \"Block\" : \"Line\",\n        value: text,\n        start: start,\n        end: end\n      };\n      if (options.locations)\n        { comment.loc = new SourceLocation(this, startLoc, endLoc); }\n      if (options.ranges)\n        { comment.range = [start, end]; }\n      array.push(comment);\n    }\n  }\n\n  // Each scope gets a bitset that may contain these flags\n  var\n      SCOPE_TOP = 1,\n      SCOPE_FUNCTION = 2,\n      SCOPE_VAR = SCOPE_TOP | SCOPE_FUNCTION,\n      SCOPE_ASYNC = 4,\n      SCOPE_GENERATOR = 8,\n      SCOPE_ARROW = 16,\n      SCOPE_SIMPLE_CATCH = 32,\n      SCOPE_SUPER = 64,\n      SCOPE_DIRECT_SUPER = 128;\n\n  function functionFlags(async, generator) {\n    return SCOPE_FUNCTION | (async ? SCOPE_ASYNC : 0) | (generator ? SCOPE_GENERATOR : 0)\n  }\n\n  // Used in checkLVal and declareName to determine the type of a binding\n  var\n      BIND_NONE = 0, // Not a binding\n      BIND_VAR = 1, // Var-style binding\n      BIND_LEXICAL = 2, // Let- or const-style binding\n      BIND_FUNCTION = 3, // Function declaration\n      BIND_SIMPLE_CATCH = 4, // Simple (identifier pattern) catch binding\n      BIND_OUTSIDE = 5; // Special case for function names as bound inside the function\n\n  var Parser = function Parser(options, input, startPos) {\n    this.options = options = getOptions(options);\n    this.sourceFile = options.sourceFile;\n    this.keywords = wordsRegexp(keywords[options.ecmaVersion >= 6 ? 6 : options.sourceType === \"module\" ? \"5module\" : 5]);\n    var reserved = \"\";\n    if (options.allowReserved !== true) {\n      for (var v = options.ecmaVersion;; v--)\n        { if (reserved = reservedWords[v]) { break } }\n      if (options.sourceType === \"module\") { reserved += \" await\"; }\n    }\n    this.reservedWords = wordsRegexp(reserved);\n    var reservedStrict = (reserved ? reserved + \" \" : \"\") + reservedWords.strict;\n    this.reservedWordsStrict = wordsRegexp(reservedStrict);\n    this.reservedWordsStrictBind = wordsRegexp(reservedStrict + \" \" + reservedWords.strictBind);\n    this.input = String(input);\n\n    // Used to signal to callers of `readWord1` whether the word\n    // contained any escape sequences. This is needed because words with\n    // escape sequences must not be interpreted as keywords.\n    this.containsEsc = false;\n\n    // Set up token state\n\n    // The current position of the tokenizer in the input.\n    if (startPos) {\n      this.pos = startPos;\n      this.lineStart = this.input.lastIndexOf(\"\\n\", startPos - 1) + 1;\n      this.curLine = this.input.slice(0, this.lineStart).split(lineBreak).length;\n    } else {\n      this.pos = this.lineStart = 0;\n      this.curLine = 1;\n    }\n\n    // Properties of the current token:\n    // Its type\n    this.type = types.eof;\n    // For tokens that include more information than their type, the value\n    this.value = null;\n    // Its start and end offset\n    this.start = this.end = this.pos;\n    // And, if locations are used, the {line, column} object\n    // corresponding to those offsets\n    this.startLoc = this.endLoc = this.curPosition();\n\n    // Position information for the previous token\n    this.lastTokEndLoc = this.lastTokStartLoc = null;\n    this.lastTokStart = this.lastTokEnd = this.pos;\n\n    // The context stack is used to superficially track syntactic\n    // context to predict whether a regular expression is allowed in a\n    // given position.\n    this.context = this.initialContext();\n    this.exprAllowed = true;\n\n    // Figure out if it's a module code.\n    this.inModule = options.sourceType === \"module\";\n    this.strict = this.inModule || this.strictDirective(this.pos);\n\n    // Used to signify the start of a potential arrow function\n    this.potentialArrowAt = -1;\n\n    // Positions to delayed-check that yield/await does not exist in default parameters.\n    this.yieldPos = this.awaitPos = this.awaitIdentPos = 0;\n    // Labels in scope.\n    this.labels = [];\n    // Thus-far undefined exports.\n    this.undefinedExports = {};\n\n    // If enabled, skip leading hashbang line.\n    if (this.pos === 0 && options.allowHashBang && this.input.slice(0, 2) === \"#!\")\n      { this.skipLineComment(2); }\n\n    // Scope tracking for duplicate variable names (see scope.js)\n    this.scopeStack = [];\n    this.enterScope(SCOPE_TOP);\n\n    // For RegExp validation\n    this.regexpState = null;\n  };\n\n  var prototypeAccessors = { inFunction: { configurable: true },inGenerator: { configurable: true },inAsync: { configurable: true },allowSuper: { configurable: true },allowDirectSuper: { configurable: true },treatFunctionsAsVar: { configurable: true } };\n\n  Parser.prototype.parse = function parse () {\n    var node = this.options.program || this.startNode();\n    this.nextToken();\n    return this.parseTopLevel(node)\n  };\n\n  prototypeAccessors.inFunction.get = function () { return (this.currentVarScope().flags & SCOPE_FUNCTION) > 0 };\n  prototypeAccessors.inGenerator.get = function () { return (this.currentVarScope().flags & SCOPE_GENERATOR) > 0 };\n  prototypeAccessors.inAsync.get = function () { return (this.currentVarScope().flags & SCOPE_ASYNC) > 0 };\n  prototypeAccessors.allowSuper.get = function () { return (this.currentThisScope().flags & SCOPE_SUPER) > 0 };\n  prototypeAccessors.allowDirectSuper.get = function () { return (this.currentThisScope().flags & SCOPE_DIRECT_SUPER) > 0 };\n  prototypeAccessors.treatFunctionsAsVar.get = function () { return this.treatFunctionsAsVarInScope(this.currentScope()) };\n\n  // Switch to a getter for 7.0.0.\n  Parser.prototype.inNonArrowFunction = function inNonArrowFunction () { return (this.currentThisScope().flags & SCOPE_FUNCTION) > 0 };\n\n  Parser.extend = function extend () {\n      var plugins = [], len = arguments.length;\n      while ( len-- ) plugins[ len ] = arguments[ len ];\n\n    var cls = this;\n    for (var i = 0; i < plugins.length; i++) { cls = plugins[i](cls); }\n    return cls\n  };\n\n  Parser.parse = function parse (input, options) {\n    return new this(options, input).parse()\n  };\n\n  Parser.parseExpressionAt = function parseExpressionAt (input, pos, options) {\n    var parser = new this(options, input, pos);\n    parser.nextToken();\n    return parser.parseExpression()\n  };\n\n  Parser.tokenizer = function tokenizer (input, options) {\n    return new this(options, input)\n  };\n\n  Object.defineProperties( Parser.prototype, prototypeAccessors );\n\n  var pp = Parser.prototype;\n\n  // ## Parser utilities\n\n  var literal = /^(?:'((?:\\\\.|[^'\\\\])*?)'|\"((?:\\\\.|[^\"\\\\])*?)\")/;\n  pp.strictDirective = function(start) {\n    for (;;) {\n      // Try to find string literal.\n      skipWhiteSpace.lastIndex = start;\n      start += skipWhiteSpace.exec(this.input)[0].length;\n      var match = literal.exec(this.input.slice(start));\n      if (!match) { return false }\n      if ((match[1] || match[2]) === \"use strict\") {\n        skipWhiteSpace.lastIndex = start + match[0].length;\n        var spaceAfter = skipWhiteSpace.exec(this.input), end = spaceAfter.index + spaceAfter[0].length;\n        var next = this.input.charAt(end);\n        return next === \";\" || next === \"}\" ||\n          (lineBreak.test(spaceAfter[0]) &&\n           !(/[(`.[+\\-/*%<>=,?^&]/.test(next) || next === \"!\" && this.input.charAt(end + 1) === \"=\"))\n      }\n      start += match[0].length;\n\n      // Skip semicolon, if any.\n      skipWhiteSpace.lastIndex = start;\n      start += skipWhiteSpace.exec(this.input)[0].length;\n      if (this.input[start] === \";\")\n        { start++; }\n    }\n  };\n\n  // Predicate that tests whether the next token is of the given\n  // type, and if yes, consumes it as a side effect.\n\n  pp.eat = function(type) {\n    if (this.type === type) {\n      this.next();\n      return true\n    } else {\n      return false\n    }\n  };\n\n  // Tests whether parsed token is a contextual keyword.\n\n  pp.isContextual = function(name) {\n    return this.type === types.name && this.value === name && !this.containsEsc\n  };\n\n  // Consumes contextual keyword if possible.\n\n  pp.eatContextual = function(name) {\n    if (!this.isContextual(name)) { return false }\n    this.next();\n    return true\n  };\n\n  // Asserts that following token is given contextual keyword.\n\n  pp.expectContextual = function(name) {\n    if (!this.eatContextual(name)) { this.unexpected(); }\n  };\n\n  // Test whether a semicolon can be inserted at the current position.\n\n  pp.canInsertSemicolon = function() {\n    return this.type === types.eof ||\n      this.type === types.braceR ||\n      lineBreak.test(this.input.slice(this.lastTokEnd, this.start))\n  };\n\n  pp.insertSemicolon = function() {\n    if (this.canInsertSemicolon()) {\n      if (this.options.onInsertedSemicolon)\n        { this.options.onInsertedSemicolon(this.lastTokEnd, this.lastTokEndLoc); }\n      return true\n    }\n  };\n\n  // Consume a semicolon, or, failing that, see if we are allowed to\n  // pretend that there is a semicolon at this position.\n\n  pp.semicolon = function() {\n    if (!this.eat(types.semi) && !this.insertSemicolon()) { this.unexpected(); }\n  };\n\n  pp.afterTrailingComma = function(tokType, notNext) {\n    if (this.type === tokType) {\n      if (this.options.onTrailingComma)\n        { this.options.onTrailingComma(this.lastTokStart, this.lastTokStartLoc); }\n      if (!notNext)\n        { this.next(); }\n      return true\n    }\n  };\n\n  // Expect a token of a given type. If found, consume it, otherwise,\n  // raise an unexpected token error.\n\n  pp.expect = function(type) {\n    this.eat(type) || this.unexpected();\n  };\n\n  // Raise an unexpected token error.\n\n  pp.unexpected = function(pos) {\n    this.raise(pos != null ? pos : this.start, \"Unexpected token\");\n  };\n\n  function DestructuringErrors() {\n    this.shorthandAssign =\n    this.trailingComma =\n    this.parenthesizedAssign =\n    this.parenthesizedBind =\n    this.doubleProto =\n      -1;\n  }\n\n  pp.checkPatternErrors = function(refDestructuringErrors, isAssign) {\n    if (!refDestructuringErrors) { return }\n    if (refDestructuringErrors.trailingComma > -1)\n      { this.raiseRecoverable(refDestructuringErrors.trailingComma, \"Comma is not permitted after the rest element\"); }\n    var parens = isAssign ? refDestructuringErrors.parenthesizedAssign : refDestructuringErrors.parenthesizedBind;\n    if (parens > -1) { this.raiseRecoverable(parens, \"Parenthesized pattern\"); }\n  };\n\n  pp.checkExpressionErrors = function(refDestructuringErrors, andThrow) {\n    if (!refDestructuringErrors) { return false }\n    var shorthandAssign = refDestructuringErrors.shorthandAssign;\n    var doubleProto = refDestructuringErrors.doubleProto;\n    if (!andThrow) { return shorthandAssign >= 0 || doubleProto >= 0 }\n    if (shorthandAssign >= 0)\n      { this.raise(shorthandAssign, \"Shorthand property assignments are valid only in destructuring patterns\"); }\n    if (doubleProto >= 0)\n      { this.raiseRecoverable(doubleProto, \"Redefinition of __proto__ property\"); }\n  };\n\n  pp.checkYieldAwaitInDefaultParams = function() {\n    if (this.yieldPos && (!this.awaitPos || this.yieldPos < this.awaitPos))\n      { this.raise(this.yieldPos, \"Yield expression cannot be a default value\"); }\n    if (this.awaitPos)\n      { this.raise(this.awaitPos, \"Await expression cannot be a default value\"); }\n  };\n\n  pp.isSimpleAssignTarget = function(expr) {\n    if (expr.type === \"ParenthesizedExpression\")\n      { return this.isSimpleAssignTarget(expr.expression) }\n    return expr.type === \"Identifier\" || expr.type === \"MemberExpression\"\n  };\n\n  var pp$1 = Parser.prototype;\n\n  // ### Statement parsing\n\n  // Parse a program. Initializes the parser, reads any number of\n  // statements, and wraps them in a Program node.  Optionally takes a\n  // `program` argument.  If present, the statements will be appended\n  // to its body instead of creating a new node.\n\n  pp$1.parseTopLevel = function(node) {\n    var exports = {};\n    if (!node.body) { node.body = []; }\n    while (this.type !== types.eof) {\n      var stmt = this.parseStatement(null, true, exports);\n      node.body.push(stmt);\n    }\n    if (this.inModule)\n      { for (var i = 0, list = Object.keys(this.undefinedExports); i < list.length; i += 1)\n        {\n          var name = list[i];\n\n          this.raiseRecoverable(this.undefinedExports[name].start, (\"Export '\" + name + \"' is not defined\"));\n        } }\n    this.adaptDirectivePrologue(node.body);\n    this.next();\n    node.sourceType = this.options.sourceType;\n    return this.finishNode(node, \"Program\")\n  };\n\n  var loopLabel = {kind: \"loop\"}, switchLabel = {kind: \"switch\"};\n\n  pp$1.isLet = function(context) {\n    if (this.options.ecmaVersion < 6 || !this.isContextual(\"let\")) { return false }\n    skipWhiteSpace.lastIndex = this.pos;\n    var skip = skipWhiteSpace.exec(this.input);\n    var next = this.pos + skip[0].length, nextCh = this.input.charCodeAt(next);\n    // For ambiguous cases, determine if a LexicalDeclaration (or only a\n    // Statement) is allowed here. If context is not empty then only a Statement\n    // is allowed. However, `let [` is an explicit negative lookahead for\n    // ExpressionStatement, so special-case it first.\n    if (nextCh === 91) { return true } // '['\n    if (context) { return false }\n\n    if (nextCh === 123) { return true } // '{'\n    if (isIdentifierStart(nextCh, true)) {\n      var pos = next + 1;\n      while (isIdentifierChar(this.input.charCodeAt(pos), true)) { ++pos; }\n      var ident = this.input.slice(next, pos);\n      if (!keywordRelationalOperator.test(ident)) { return true }\n    }\n    return false\n  };\n\n  // check 'async [no LineTerminator here] function'\n  // - 'async /*foo*/ function' is OK.\n  // - 'async /*\\n*/ function' is invalid.\n  pp$1.isAsyncFunction = function() {\n    if (this.options.ecmaVersion < 8 || !this.isContextual(\"async\"))\n      { return false }\n\n    skipWhiteSpace.lastIndex = this.pos;\n    var skip = skipWhiteSpace.exec(this.input);\n    var next = this.pos + skip[0].length;\n    return !lineBreak.test(this.input.slice(this.pos, next)) &&\n      this.input.slice(next, next + 8) === \"function\" &&\n      (next + 8 === this.input.length || !isIdentifierChar(this.input.charAt(next + 8)))\n  };\n\n  // Parse a single statement.\n  //\n  // If expecting a statement and finding a slash operator, parse a\n  // regular expression literal. This is to handle cases like\n  // `if (foo) /blah/.exec(foo)`, where looking at the previous token\n  // does not help.\n\n  pp$1.parseStatement = function(context, topLevel, exports) {\n    var starttype = this.type, node = this.startNode(), kind;\n\n    if (this.isLet(context)) {\n      starttype = types._var;\n      kind = \"let\";\n    }\n\n    // Most types of statements are recognized by the keyword they\n    // start with. Many are trivial to parse, some require a bit of\n    // complexity.\n\n    switch (starttype) {\n    case types._break: case types._continue: return this.parseBreakContinueStatement(node, starttype.keyword)\n    case types._debugger: return this.parseDebuggerStatement(node)\n    case types._do: return this.parseDoStatement(node)\n    case types._for: return this.parseForStatement(node)\n    case types._function:\n      // Function as sole body of either an if statement or a labeled statement\n      // works, but not when it is part of a labeled statement that is the sole\n      // body of an if statement.\n      if ((context && (this.strict || context !== \"if\" && context !== \"label\")) && this.options.ecmaVersion >= 6) { this.unexpected(); }\n      return this.parseFunctionStatement(node, false, !context)\n    case types._class:\n      if (context) { this.unexpected(); }\n      return this.parseClass(node, true)\n    case types._if: return this.parseIfStatement(node)\n    case types._return: return this.parseReturnStatement(node)\n    case types._switch: return this.parseSwitchStatement(node)\n    case types._throw: return this.parseThrowStatement(node)\n    case types._try: return this.parseTryStatement(node)\n    case types._const: case types._var:\n      kind = kind || this.value;\n      if (context && kind !== \"var\") { this.unexpected(); }\n      return this.parseVarStatement(node, kind)\n    case types._while: return this.parseWhileStatement(node)\n    case types._with: return this.parseWithStatement(node)\n    case types.braceL: return this.parseBlock(true, node)\n    case types.semi: return this.parseEmptyStatement(node)\n    case types._export:\n    case types._import:\n      if (this.options.ecmaVersion > 10 && starttype === types._import) {\n        skipWhiteSpace.lastIndex = this.pos;\n        var skip = skipWhiteSpace.exec(this.input);\n        var next = this.pos + skip[0].length, nextCh = this.input.charCodeAt(next);\n        if (nextCh === 40 || nextCh === 46) // '(' or '.'\n          { return this.parseExpressionStatement(node, this.parseExpression()) }\n      }\n\n      if (!this.options.allowImportExportEverywhere) {\n        if (!topLevel)\n          { this.raise(this.start, \"'import' and 'export' may only appear at the top level\"); }\n        if (!this.inModule)\n          { this.raise(this.start, \"'import' and 'export' may appear only with 'sourceType: module'\"); }\n      }\n      return starttype === types._import ? this.parseImport(node) : this.parseExport(node, exports)\n\n      // If the statement does not start with a statement keyword or a\n      // brace, it's an ExpressionStatement or LabeledStatement. We\n      // simply start parsing an expression, and afterwards, if the\n      // next token is a colon and the expression was a simple\n      // Identifier node, we switch to interpreting it as a label.\n    default:\n      if (this.isAsyncFunction()) {\n        if (context) { this.unexpected(); }\n        this.next();\n        return this.parseFunctionStatement(node, true, !context)\n      }\n\n      var maybeName = this.value, expr = this.parseExpression();\n      if (starttype === types.name && expr.type === \"Identifier\" && this.eat(types.colon))\n        { return this.parseLabeledStatement(node, maybeName, expr, context) }\n      else { return this.parseExpressionStatement(node, expr) }\n    }\n  };\n\n  pp$1.parseBreakContinueStatement = function(node, keyword) {\n    var isBreak = keyword === \"break\";\n    this.next();\n    if (this.eat(types.semi) || this.insertSemicolon()) { node.label = null; }\n    else if (this.type !== types.name) { this.unexpected(); }\n    else {\n      node.label = this.parseIdent();\n      this.semicolon();\n    }\n\n    // Verify that there is an actual destination to break or\n    // continue to.\n    var i = 0;\n    for (; i < this.labels.length; ++i) {\n      var lab = this.labels[i];\n      if (node.label == null || lab.name === node.label.name) {\n        if (lab.kind != null && (isBreak || lab.kind === \"loop\")) { break }\n        if (node.label && isBreak) { break }\n      }\n    }\n    if (i === this.labels.length) { this.raise(node.start, \"Unsyntactic \" + keyword); }\n    return this.finishNode(node, isBreak ? \"BreakStatement\" : \"ContinueStatement\")\n  };\n\n  pp$1.parseDebuggerStatement = function(node) {\n    this.next();\n    this.semicolon();\n    return this.finishNode(node, \"DebuggerStatement\")\n  };\n\n  pp$1.parseDoStatement = function(node) {\n    this.next();\n    this.labels.push(loopLabel);\n    node.body = this.parseStatement(\"do\");\n    this.labels.pop();\n    this.expect(types._while);\n    node.test = this.parseParenExpression();\n    if (this.options.ecmaVersion >= 6)\n      { this.eat(types.semi); }\n    else\n      { this.semicolon(); }\n    return this.finishNode(node, \"DoWhileStatement\")\n  };\n\n  // Disambiguating between a `for` and a `for`/`in` or `for`/`of`\n  // loop is non-trivial. Basically, we have to parse the init `var`\n  // statement or expression, disallowing the `in` operator (see\n  // the second parameter to `parseExpression`), and then check\n  // whether the next token is `in` or `of`. When there is no init\n  // part (semicolon immediately after the opening parenthesis), it\n  // is a regular `for` loop.\n\n  pp$1.parseForStatement = function(node) {\n    this.next();\n    var awaitAt = (this.options.ecmaVersion >= 9 && (this.inAsync || (!this.inFunction && this.options.allowAwaitOutsideFunction)) && this.eatContextual(\"await\")) ? this.lastTokStart : -1;\n    this.labels.push(loopLabel);\n    this.enterScope(0);\n    this.expect(types.parenL);\n    if (this.type === types.semi) {\n      if (awaitAt > -1) { this.unexpected(awaitAt); }\n      return this.parseFor(node, null)\n    }\n    var isLet = this.isLet();\n    if (this.type === types._var || this.type === types._const || isLet) {\n      var init$1 = this.startNode(), kind = isLet ? \"let\" : this.value;\n      this.next();\n      this.parseVar(init$1, true, kind);\n      this.finishNode(init$1, \"VariableDeclaration\");\n      if ((this.type === types._in || (this.options.ecmaVersion >= 6 && this.isContextual(\"of\"))) && init$1.declarations.length === 1) {\n        if (this.options.ecmaVersion >= 9) {\n          if (this.type === types._in) {\n            if (awaitAt > -1) { this.unexpected(awaitAt); }\n          } else { node.await = awaitAt > -1; }\n        }\n        return this.parseForIn(node, init$1)\n      }\n      if (awaitAt > -1) { this.unexpected(awaitAt); }\n      return this.parseFor(node, init$1)\n    }\n    var refDestructuringErrors = new DestructuringErrors;\n    var init = this.parseExpression(true, refDestructuringErrors);\n    if (this.type === types._in || (this.options.ecmaVersion >= 6 && this.isContextual(\"of\"))) {\n      if (this.options.ecmaVersion >= 9) {\n        if (this.type === types._in) {\n          if (awaitAt > -1) { this.unexpected(awaitAt); }\n        } else { node.await = awaitAt > -1; }\n      }\n      this.toAssignable(init, false, refDestructuringErrors);\n      this.checkLVal(init);\n      return this.parseForIn(node, init)\n    } else {\n      this.checkExpressionErrors(refDestructuringErrors, true);\n    }\n    if (awaitAt > -1) { this.unexpected(awaitAt); }\n    return this.parseFor(node, init)\n  };\n\n  pp$1.parseFunctionStatement = function(node, isAsync, declarationPosition) {\n    this.next();\n    return this.parseFunction(node, FUNC_STATEMENT | (declarationPosition ? 0 : FUNC_HANGING_STATEMENT), false, isAsync)\n  };\n\n  pp$1.parseIfStatement = function(node) {\n    this.next();\n    node.test = this.parseParenExpression();\n    // allow function declarations in branches, but only in non-strict mode\n    node.consequent = this.parseStatement(\"if\");\n    node.alternate = this.eat(types._else) ? this.parseStatement(\"if\") : null;\n    return this.finishNode(node, \"IfStatement\")\n  };\n\n  pp$1.parseReturnStatement = function(node) {\n    if (!this.inFunction && !this.options.allowReturnOutsideFunction)\n      { this.raise(this.start, \"'return' outside of function\"); }\n    this.next();\n\n    // In `return` (and `break`/`continue`), the keywords with\n    // optional arguments, we eagerly look for a semicolon or the\n    // possibility to insert one.\n\n    if (this.eat(types.semi) || this.insertSemicolon()) { node.argument = null; }\n    else { node.argument = this.parseExpression(); this.semicolon(); }\n    return this.finishNode(node, \"ReturnStatement\")\n  };\n\n  pp$1.parseSwitchStatement = function(node) {\n    this.next();\n    node.discriminant = this.parseParenExpression();\n    node.cases = [];\n    this.expect(types.braceL);\n    this.labels.push(switchLabel);\n    this.enterScope(0);\n\n    // Statements under must be grouped (by label) in SwitchCase\n    // nodes. `cur` is used to keep the node that we are currently\n    // adding statements to.\n\n    var cur;\n    for (var sawDefault = false; this.type !== types.braceR;) {\n      if (this.type === types._case || this.type === types._default) {\n        var isCase = this.type === types._case;\n        if (cur) { this.finishNode(cur, \"SwitchCase\"); }\n        node.cases.push(cur = this.startNode());\n        cur.consequent = [];\n        this.next();\n        if (isCase) {\n          cur.test = this.parseExpression();\n        } else {\n          if (sawDefault) { this.raiseRecoverable(this.lastTokStart, \"Multiple default clauses\"); }\n          sawDefault = true;\n          cur.test = null;\n        }\n        this.expect(types.colon);\n      } else {\n        if (!cur) { this.unexpected(); }\n        cur.consequent.push(this.parseStatement(null));\n      }\n    }\n    this.exitScope();\n    if (cur) { this.finishNode(cur, \"SwitchCase\"); }\n    this.next(); // Closing brace\n    this.labels.pop();\n    return this.finishNode(node, \"SwitchStatement\")\n  };\n\n  pp$1.parseThrowStatement = function(node) {\n    this.next();\n    if (lineBreak.test(this.input.slice(this.lastTokEnd, this.start)))\n      { this.raise(this.lastTokEnd, \"Illegal newline after throw\"); }\n    node.argument = this.parseExpression();\n    this.semicolon();\n    return this.finishNode(node, \"ThrowStatement\")\n  };\n\n  // Reused empty array added for node fields that are always empty.\n\n  var empty = [];\n\n  pp$1.parseTryStatement = function(node) {\n    this.next();\n    node.block = this.parseBlock();\n    node.handler = null;\n    if (this.type === types._catch) {\n      var clause = this.startNode();\n      this.next();\n      if (this.eat(types.parenL)) {\n        clause.param = this.parseBindingAtom();\n        var simple = clause.param.type === \"Identifier\";\n        this.enterScope(simple ? SCOPE_SIMPLE_CATCH : 0);\n        this.checkLVal(clause.param, simple ? BIND_SIMPLE_CATCH : BIND_LEXICAL);\n        this.expect(types.parenR);\n      } else {\n        if (this.options.ecmaVersion < 10) { this.unexpected(); }\n        clause.param = null;\n        this.enterScope(0);\n      }\n      clause.body = this.parseBlock(false);\n      this.exitScope();\n      node.handler = this.finishNode(clause, \"CatchClause\");\n    }\n    node.finalizer = this.eat(types._finally) ? this.parseBlock() : null;\n    if (!node.handler && !node.finalizer)\n      { this.raise(node.start, \"Missing catch or finally clause\"); }\n    return this.finishNode(node, \"TryStatement\")\n  };\n\n  pp$1.parseVarStatement = function(node, kind) {\n    this.next();\n    this.parseVar(node, false, kind);\n    this.semicolon();\n    return this.finishNode(node, \"VariableDeclaration\")\n  };\n\n  pp$1.parseWhileStatement = function(node) {\n    this.next();\n    node.test = this.parseParenExpression();\n    this.labels.push(loopLabel);\n    node.body = this.parseStatement(\"while\");\n    this.labels.pop();\n    return this.finishNode(node, \"WhileStatement\")\n  };\n\n  pp$1.parseWithStatement = function(node) {\n    if (this.strict) { this.raise(this.start, \"'with' in strict mode\"); }\n    this.next();\n    node.object = this.parseParenExpression();\n    node.body = this.parseStatement(\"with\");\n    return this.finishNode(node, \"WithStatement\")\n  };\n\n  pp$1.parseEmptyStatement = function(node) {\n    this.next();\n    return this.finishNode(node, \"EmptyStatement\")\n  };\n\n  pp$1.parseLabeledStatement = function(node, maybeName, expr, context) {\n    for (var i$1 = 0, list = this.labels; i$1 < list.length; i$1 += 1)\n      {\n      var label = list[i$1];\n\n      if (label.name === maybeName)\n        { this.raise(expr.start, \"Label '\" + maybeName + \"' is already declared\");\n    } }\n    var kind = this.type.isLoop ? \"loop\" : this.type === types._switch ? \"switch\" : null;\n    for (var i = this.labels.length - 1; i >= 0; i--) {\n      var label$1 = this.labels[i];\n      if (label$1.statementStart === node.start) {\n        // Update information about previous labels on this node\n        label$1.statementStart = this.start;\n        label$1.kind = kind;\n      } else { break }\n    }\n    this.labels.push({name: maybeName, kind: kind, statementStart: this.start});\n    node.body = this.parseStatement(context ? context.indexOf(\"label\") === -1 ? context + \"label\" : context : \"label\");\n    this.labels.pop();\n    node.label = expr;\n    return this.finishNode(node, \"LabeledStatement\")\n  };\n\n  pp$1.parseExpressionStatement = function(node, expr) {\n    node.expression = expr;\n    this.semicolon();\n    return this.finishNode(node, \"ExpressionStatement\")\n  };\n\n  // Parse a semicolon-enclosed block of statements, handling `\"use\n  // strict\"` declarations when `allowStrict` is true (used for\n  // function bodies).\n\n  pp$1.parseBlock = function(createNewLexicalScope, node, exitStrict) {\n    if ( createNewLexicalScope === void 0 ) createNewLexicalScope = true;\n    if ( node === void 0 ) node = this.startNode();\n\n    node.body = [];\n    this.expect(types.braceL);\n    if (createNewLexicalScope) { this.enterScope(0); }\n    while (this.type !== types.braceR) {\n      var stmt = this.parseStatement(null);\n      node.body.push(stmt);\n    }\n    if (exitStrict) { this.strict = false; }\n    this.next();\n    if (createNewLexicalScope) { this.exitScope(); }\n    return this.finishNode(node, \"BlockStatement\")\n  };\n\n  // Parse a regular `for` loop. The disambiguation code in\n  // `parseStatement` will already have parsed the init statement or\n  // expression.\n\n  pp$1.parseFor = function(node, init) {\n    node.init = init;\n    this.expect(types.semi);\n    node.test = this.type === types.semi ? null : this.parseExpression();\n    this.expect(types.semi);\n    node.update = this.type === types.parenR ? null : this.parseExpression();\n    this.expect(types.parenR);\n    node.body = this.parseStatement(\"for\");\n    this.exitScope();\n    this.labels.pop();\n    return this.finishNode(node, \"ForStatement\")\n  };\n\n  // Parse a `for`/`in` and `for`/`of` loop, which are almost\n  // same from parser's perspective.\n\n  pp$1.parseForIn = function(node, init) {\n    var isForIn = this.type === types._in;\n    this.next();\n\n    if (\n      init.type === \"VariableDeclaration\" &&\n      init.declarations[0].init != null &&\n      (\n        !isForIn ||\n        this.options.ecmaVersion < 8 ||\n        this.strict ||\n        init.kind !== \"var\" ||\n        init.declarations[0].id.type !== \"Identifier\"\n      )\n    ) {\n      this.raise(\n        init.start,\n        ((isForIn ? \"for-in\" : \"for-of\") + \" loop variable declaration may not have an initializer\")\n      );\n    } else if (init.type === \"AssignmentPattern\") {\n      this.raise(init.start, \"Invalid left-hand side in for-loop\");\n    }\n    node.left = init;\n    node.right = isForIn ? this.parseExpression() : this.parseMaybeAssign();\n    this.expect(types.parenR);\n    node.body = this.parseStatement(\"for\");\n    this.exitScope();\n    this.labels.pop();\n    return this.finishNode(node, isForIn ? \"ForInStatement\" : \"ForOfStatement\")\n  };\n\n  // Parse a list of variable declarations.\n\n  pp$1.parseVar = function(node, isFor, kind) {\n    node.declarations = [];\n    node.kind = kind;\n    for (;;) {\n      var decl = this.startNode();\n      this.parseVarId(decl, kind);\n      if (this.eat(types.eq)) {\n        decl.init = this.parseMaybeAssign(isFor);\n      } else if (kind === \"const\" && !(this.type === types._in || (this.options.ecmaVersion >= 6 && this.isContextual(\"of\")))) {\n        this.unexpected();\n      } else if (decl.id.type !== \"Identifier\" && !(isFor && (this.type === types._in || this.isContextual(\"of\")))) {\n        this.raise(this.lastTokEnd, \"Complex binding patterns require an initialization value\");\n      } else {\n        decl.init = null;\n      }\n      node.declarations.push(this.finishNode(decl, \"VariableDeclarator\"));\n      if (!this.eat(types.comma)) { break }\n    }\n    return node\n  };\n\n  pp$1.parseVarId = function(decl, kind) {\n    decl.id = this.parseBindingAtom();\n    this.checkLVal(decl.id, kind === \"var\" ? BIND_VAR : BIND_LEXICAL, false);\n  };\n\n  var FUNC_STATEMENT = 1, FUNC_HANGING_STATEMENT = 2, FUNC_NULLABLE_ID = 4;\n\n  // Parse a function declaration or literal (depending on the\n  // `statement & FUNC_STATEMENT`).\n\n  // Remove `allowExpressionBody` for 7.0.0, as it is only called with false\n  pp$1.parseFunction = function(node, statement, allowExpressionBody, isAsync) {\n    this.initFunction(node);\n    if (this.options.ecmaVersion >= 9 || this.options.ecmaVersion >= 6 && !isAsync) {\n      if (this.type === types.star && (statement & FUNC_HANGING_STATEMENT))\n        { this.unexpected(); }\n      node.generator = this.eat(types.star);\n    }\n    if (this.options.ecmaVersion >= 8)\n      { node.async = !!isAsync; }\n\n    if (statement & FUNC_STATEMENT) {\n      node.id = (statement & FUNC_NULLABLE_ID) && this.type !== types.name ? null : this.parseIdent();\n      if (node.id && !(statement & FUNC_HANGING_STATEMENT))\n        // If it is a regular function declaration in sloppy mode, then it is\n        // subject to Annex B semantics (BIND_FUNCTION). Otherwise, the binding\n        // mode depends on properties of the current scope (see\n        // treatFunctionsAsVar).\n        { this.checkLVal(node.id, (this.strict || node.generator || node.async) ? this.treatFunctionsAsVar ? BIND_VAR : BIND_LEXICAL : BIND_FUNCTION); }\n    }\n\n    var oldYieldPos = this.yieldPos, oldAwaitPos = this.awaitPos, oldAwaitIdentPos = this.awaitIdentPos;\n    this.yieldPos = 0;\n    this.awaitPos = 0;\n    this.awaitIdentPos = 0;\n    this.enterScope(functionFlags(node.async, node.generator));\n\n    if (!(statement & FUNC_STATEMENT))\n      { node.id = this.type === types.name ? this.parseIdent() : null; }\n\n    this.parseFunctionParams(node);\n    this.parseFunctionBody(node, allowExpressionBody, false);\n\n    this.yieldPos = oldYieldPos;\n    this.awaitPos = oldAwaitPos;\n    this.awaitIdentPos = oldAwaitIdentPos;\n    return this.finishNode(node, (statement & FUNC_STATEMENT) ? \"FunctionDeclaration\" : \"FunctionExpression\")\n  };\n\n  pp$1.parseFunctionParams = function(node) {\n    this.expect(types.parenL);\n    node.params = this.parseBindingList(types.parenR, false, this.options.ecmaVersion >= 8);\n    this.checkYieldAwaitInDefaultParams();\n  };\n\n  // Parse a class declaration or literal (depending on the\n  // `isStatement` parameter).\n\n  pp$1.parseClass = function(node, isStatement) {\n    this.next();\n\n    // ecma-262 14.6 Class Definitions\n    // A class definition is always strict mode code.\n    var oldStrict = this.strict;\n    this.strict = true;\n\n    this.parseClassId(node, isStatement);\n    this.parseClassSuper(node);\n    var classBody = this.startNode();\n    var hadConstructor = false;\n    classBody.body = [];\n    this.expect(types.braceL);\n    while (this.type !== types.braceR) {\n      var element = this.parseClassElement(node.superClass !== null);\n      if (element) {\n        classBody.body.push(element);\n        if (element.type === \"MethodDefinition\" && element.kind === \"constructor\") {\n          if (hadConstructor) { this.raise(element.start, \"Duplicate constructor in the same class\"); }\n          hadConstructor = true;\n        }\n      }\n    }\n    this.strict = oldStrict;\n    this.next();\n    node.body = this.finishNode(classBody, \"ClassBody\");\n    return this.finishNode(node, isStatement ? \"ClassDeclaration\" : \"ClassExpression\")\n  };\n\n  pp$1.parseClassElement = function(constructorAllowsSuper) {\n    var this$1 = this;\n\n    if (this.eat(types.semi)) { return null }\n\n    var method = this.startNode();\n    var tryContextual = function (k, noLineBreak) {\n      if ( noLineBreak === void 0 ) noLineBreak = false;\n\n      var start = this$1.start, startLoc = this$1.startLoc;\n      if (!this$1.eatContextual(k)) { return false }\n      if (this$1.type !== types.parenL && (!noLineBreak || !this$1.canInsertSemicolon())) { return true }\n      if (method.key) { this$1.unexpected(); }\n      method.computed = false;\n      method.key = this$1.startNodeAt(start, startLoc);\n      method.key.name = k;\n      this$1.finishNode(method.key, \"Identifier\");\n      return false\n    };\n\n    method.kind = \"method\";\n    method.static = tryContextual(\"static\");\n    var isGenerator = this.eat(types.star);\n    var isAsync = false;\n    if (!isGenerator) {\n      if (this.options.ecmaVersion >= 8 && tryContextual(\"async\", true)) {\n        isAsync = true;\n        isGenerator = this.options.ecmaVersion >= 9 && this.eat(types.star);\n      } else if (tryContextual(\"get\")) {\n        method.kind = \"get\";\n      } else if (tryContextual(\"set\")) {\n        method.kind = \"set\";\n      }\n    }\n    if (!method.key) { this.parsePropertyName(method); }\n    var key = method.key;\n    var allowsDirectSuper = false;\n    if (!method.computed && !method.static && (key.type === \"Identifier\" && key.name === \"constructor\" ||\n        key.type === \"Literal\" && key.value === \"constructor\")) {\n      if (method.kind !== \"method\") { this.raise(key.start, \"Constructor can't have get/set modifier\"); }\n      if (isGenerator) { this.raise(key.start, \"Constructor can't be a generator\"); }\n      if (isAsync) { this.raise(key.start, \"Constructor can't be an async method\"); }\n      method.kind = \"constructor\";\n      allowsDirectSuper = constructorAllowsSuper;\n    } else if (method.static && key.type === \"Identifier\" && key.name === \"prototype\") {\n      this.raise(key.start, \"Classes may not have a static property named prototype\");\n    }\n    this.parseClassMethod(method, isGenerator, isAsync, allowsDirectSuper);\n    if (method.kind === \"get\" && method.value.params.length !== 0)\n      { this.raiseRecoverable(method.value.start, \"getter should have no params\"); }\n    if (method.kind === \"set\" && method.value.params.length !== 1)\n      { this.raiseRecoverable(method.value.start, \"setter should have exactly one param\"); }\n    if (method.kind === \"set\" && method.value.params[0].type === \"RestElement\")\n      { this.raiseRecoverable(method.value.params[0].start, \"Setter cannot use rest params\"); }\n    return method\n  };\n\n  pp$1.parseClassMethod = function(method, isGenerator, isAsync, allowsDirectSuper) {\n    method.value = this.parseMethod(isGenerator, isAsync, allowsDirectSuper);\n    return this.finishNode(method, \"MethodDefinition\")\n  };\n\n  pp$1.parseClassId = function(node, isStatement) {\n    if (this.type === types.name) {\n      node.id = this.parseIdent();\n      if (isStatement)\n        { this.checkLVal(node.id, BIND_LEXICAL, false); }\n    } else {\n      if (isStatement === true)\n        { this.unexpected(); }\n      node.id = null;\n    }\n  };\n\n  pp$1.parseClassSuper = function(node) {\n    node.superClass = this.eat(types._extends) ? this.parseExprSubscripts() : null;\n  };\n\n  // Parses module export declaration.\n\n  pp$1.parseExport = function(node, exports) {\n    this.next();\n    // export * from '...'\n    if (this.eat(types.star)) {\n      if (this.options.ecmaVersion >= 11) {\n        if (this.eatContextual(\"as\")) {\n          node.exported = this.parseIdent(true);\n          this.checkExport(exports, node.exported.name, this.lastTokStart);\n        } else {\n          node.exported = null;\n        }\n      }\n      this.expectContextual(\"from\");\n      if (this.type !== types.string) { this.unexpected(); }\n      node.source = this.parseExprAtom();\n      this.semicolon();\n      return this.finishNode(node, \"ExportAllDeclaration\")\n    }\n    if (this.eat(types._default)) { // export default ...\n      this.checkExport(exports, \"default\", this.lastTokStart);\n      var isAsync;\n      if (this.type === types._function || (isAsync = this.isAsyncFunction())) {\n        var fNode = this.startNode();\n        this.next();\n        if (isAsync) { this.next(); }\n        node.declaration = this.parseFunction(fNode, FUNC_STATEMENT | FUNC_NULLABLE_ID, false, isAsync);\n      } else if (this.type === types._class) {\n        var cNode = this.startNode();\n        node.declaration = this.parseClass(cNode, \"nullableID\");\n      } else {\n        node.declaration = this.parseMaybeAssign();\n        this.semicolon();\n      }\n      return this.finishNode(node, \"ExportDefaultDeclaration\")\n    }\n    // export var|const|let|function|class ...\n    if (this.shouldParseExportStatement()) {\n      node.declaration = this.parseStatement(null);\n      if (node.declaration.type === \"VariableDeclaration\")\n        { this.checkVariableExport(exports, node.declaration.declarations); }\n      else\n        { this.checkExport(exports, node.declaration.id.name, node.declaration.id.start); }\n      node.specifiers = [];\n      node.source = null;\n    } else { // export { x, y as z } [from '...']\n      node.declaration = null;\n      node.specifiers = this.parseExportSpecifiers(exports);\n      if (this.eatContextual(\"from\")) {\n        if (this.type !== types.string) { this.unexpected(); }\n        node.source = this.parseExprAtom();\n      } else {\n        for (var i = 0, list = node.specifiers; i < list.length; i += 1) {\n          // check for keywords used as local names\n          var spec = list[i];\n\n          this.checkUnreserved(spec.local);\n          // check if export is defined\n          this.checkLocalExport(spec.local);\n        }\n\n        node.source = null;\n      }\n      this.semicolon();\n    }\n    return this.finishNode(node, \"ExportNamedDeclaration\")\n  };\n\n  pp$1.checkExport = function(exports, name, pos) {\n    if (!exports) { return }\n    if (has(exports, name))\n      { this.raiseRecoverable(pos, \"Duplicate export '\" + name + \"'\"); }\n    exports[name] = true;\n  };\n\n  pp$1.checkPatternExport = function(exports, pat) {\n    var type = pat.type;\n    if (type === \"Identifier\")\n      { this.checkExport(exports, pat.name, pat.start); }\n    else if (type === \"ObjectPattern\")\n      { for (var i = 0, list = pat.properties; i < list.length; i += 1)\n        {\n          var prop = list[i];\n\n          this.checkPatternExport(exports, prop);\n        } }\n    else if (type === \"ArrayPattern\")\n      { for (var i$1 = 0, list$1 = pat.elements; i$1 < list$1.length; i$1 += 1) {\n        var elt = list$1[i$1];\n\n          if (elt) { this.checkPatternExport(exports, elt); }\n      } }\n    else if (type === \"Property\")\n      { this.checkPatternExport(exports, pat.value); }\n    else if (type === \"AssignmentPattern\")\n      { this.checkPatternExport(exports, pat.left); }\n    else if (type === \"RestElement\")\n      { this.checkPatternExport(exports, pat.argument); }\n    else if (type === \"ParenthesizedExpression\")\n      { this.checkPatternExport(exports, pat.expression); }\n  };\n\n  pp$1.checkVariableExport = function(exports, decls) {\n    if (!exports) { return }\n    for (var i = 0, list = decls; i < list.length; i += 1)\n      {\n      var decl = list[i];\n\n      this.checkPatternExport(exports, decl.id);\n    }\n  };\n\n  pp$1.shouldParseExportStatement = function() {\n    return this.type.keyword === \"var\" ||\n      this.type.keyword === \"const\" ||\n      this.type.keyword === \"class\" ||\n      this.type.keyword === \"function\" ||\n      this.isLet() ||\n      this.isAsyncFunction()\n  };\n\n  // Parses a comma-separated list of module exports.\n\n  pp$1.parseExportSpecifiers = function(exports) {\n    var nodes = [], first = true;\n    // export { x, y as z } [from '...']\n    this.expect(types.braceL);\n    while (!this.eat(types.braceR)) {\n      if (!first) {\n        this.expect(types.comma);\n        if (this.afterTrailingComma(types.braceR)) { break }\n      } else { first = false; }\n\n      var node = this.startNode();\n      node.local = this.parseIdent(true);\n      node.exported = this.eatContextual(\"as\") ? this.parseIdent(true) : node.local;\n      this.checkExport(exports, node.exported.name, node.exported.start);\n      nodes.push(this.finishNode(node, \"ExportSpecifier\"));\n    }\n    return nodes\n  };\n\n  // Parses import declaration.\n\n  pp$1.parseImport = function(node) {\n    this.next();\n    // import '...'\n    if (this.type === types.string) {\n      node.specifiers = empty;\n      node.source = this.parseExprAtom();\n    } else {\n      node.specifiers = this.parseImportSpecifiers();\n      this.expectContextual(\"from\");\n      node.source = this.type === types.string ? this.parseExprAtom() : this.unexpected();\n    }\n    this.semicolon();\n    return this.finishNode(node, \"ImportDeclaration\")\n  };\n\n  // Parses a comma-separated list of module imports.\n\n  pp$1.parseImportSpecifiers = function() {\n    var nodes = [], first = true;\n    if (this.type === types.name) {\n      // import defaultObj, { x, y as z } from '...'\n      var node = this.startNode();\n      node.local = this.parseIdent();\n      this.checkLVal(node.local, BIND_LEXICAL);\n      nodes.push(this.finishNode(node, \"ImportDefaultSpecifier\"));\n      if (!this.eat(types.comma)) { return nodes }\n    }\n    if (this.type === types.star) {\n      var node$1 = this.startNode();\n      this.next();\n      this.expectContextual(\"as\");\n      node$1.local = this.parseIdent();\n      this.checkLVal(node$1.local, BIND_LEXICAL);\n      nodes.push(this.finishNode(node$1, \"ImportNamespaceSpecifier\"));\n      return nodes\n    }\n    this.expect(types.braceL);\n    while (!this.eat(types.braceR)) {\n      if (!first) {\n        this.expect(types.comma);\n        if (this.afterTrailingComma(types.braceR)) { break }\n      } else { first = false; }\n\n      var node$2 = this.startNode();\n      node$2.imported = this.parseIdent(true);\n      if (this.eatContextual(\"as\")) {\n        node$2.local = this.parseIdent();\n      } else {\n        this.checkUnreserved(node$2.imported);\n        node$2.local = node$2.imported;\n      }\n      this.checkLVal(node$2.local, BIND_LEXICAL);\n      nodes.push(this.finishNode(node$2, \"ImportSpecifier\"));\n    }\n    return nodes\n  };\n\n  // Set `ExpressionStatement#directive` property for directive prologues.\n  pp$1.adaptDirectivePrologue = function(statements) {\n    for (var i = 0; i < statements.length && this.isDirectiveCandidate(statements[i]); ++i) {\n      statements[i].directive = statements[i].expression.raw.slice(1, -1);\n    }\n  };\n  pp$1.isDirectiveCandidate = function(statement) {\n    return (\n      statement.type === \"ExpressionStatement\" &&\n      statement.expression.type === \"Literal\" &&\n      typeof statement.expression.value === \"string\" &&\n      // Reject parenthesized strings.\n      (this.input[statement.start] === \"\\\"\" || this.input[statement.start] === \"'\")\n    )\n  };\n\n  var pp$2 = Parser.prototype;\n\n  // Convert existing expression atom to assignable pattern\n  // if possible.\n\n  pp$2.toAssignable = function(node, isBinding, refDestructuringErrors) {\n    if (this.options.ecmaVersion >= 6 && node) {\n      switch (node.type) {\n      case \"Identifier\":\n        if (this.inAsync && node.name === \"await\")\n          { this.raise(node.start, \"Cannot use 'await' as identifier inside an async function\"); }\n        break\n\n      case \"ObjectPattern\":\n      case \"ArrayPattern\":\n      case \"RestElement\":\n        break\n\n      case \"ObjectExpression\":\n        node.type = \"ObjectPattern\";\n        if (refDestructuringErrors) { this.checkPatternErrors(refDestructuringErrors, true); }\n        for (var i = 0, list = node.properties; i < list.length; i += 1) {\n          var prop = list[i];\n\n        this.toAssignable(prop, isBinding);\n          // Early error:\n          //   AssignmentRestProperty[Yield, Await] :\n          //     `...` DestructuringAssignmentTarget[Yield, Await]\n          //\n          //   It is a Syntax Error if |DestructuringAssignmentTarget| is an |ArrayLiteral| or an |ObjectLiteral|.\n          if (\n            prop.type === \"RestElement\" &&\n            (prop.argument.type === \"ArrayPattern\" || prop.argument.type === \"ObjectPattern\")\n          ) {\n            this.raise(prop.argument.start, \"Unexpected token\");\n          }\n        }\n        break\n\n      case \"Property\":\n        // AssignmentProperty has type === \"Property\"\n        if (node.kind !== \"init\") { this.raise(node.key.start, \"Object pattern can't contain getter or setter\"); }\n        this.toAssignable(node.value, isBinding);\n        break\n\n      case \"ArrayExpression\":\n        node.type = \"ArrayPattern\";\n        if (refDestructuringErrors) { this.checkPatternErrors(refDestructuringErrors, true); }\n        this.toAssignableList(node.elements, isBinding);\n        break\n\n      case \"SpreadElement\":\n        node.type = \"RestElement\";\n        this.toAssignable(node.argument, isBinding);\n        if (node.argument.type === \"AssignmentPattern\")\n          { this.raise(node.argument.start, \"Rest elements cannot have a default value\"); }\n        break\n\n      case \"AssignmentExpression\":\n        if (node.operator !== \"=\") { this.raise(node.left.end, \"Only '=' operator can be used for specifying default value.\"); }\n        node.type = \"AssignmentPattern\";\n        delete node.operator;\n        this.toAssignable(node.left, isBinding);\n        // falls through to AssignmentPattern\n\n      case \"AssignmentPattern\":\n        break\n\n      case \"ParenthesizedExpression\":\n        this.toAssignable(node.expression, isBinding, refDestructuringErrors);\n        break\n\n      case \"ChainExpression\":\n        this.raiseRecoverable(node.start, \"Optional chaining cannot appear in left-hand side\");\n        break\n\n      case \"MemberExpression\":\n        if (!isBinding) { break }\n\n      default:\n        this.raise(node.start, \"Assigning to rvalue\");\n      }\n    } else if (refDestructuringErrors) { this.checkPatternErrors(refDestructuringErrors, true); }\n    return node\n  };\n\n  // Convert list of expression atoms to binding list.\n\n  pp$2.toAssignableList = function(exprList, isBinding) {\n    var end = exprList.length;\n    for (var i = 0; i < end; i++) {\n      var elt = exprList[i];\n      if (elt) { this.toAssignable(elt, isBinding); }\n    }\n    if (end) {\n      var last = exprList[end - 1];\n      if (this.options.ecmaVersion === 6 && isBinding && last && last.type === \"RestElement\" && last.argument.type !== \"Identifier\")\n        { this.unexpected(last.argument.start); }\n    }\n    return exprList\n  };\n\n  // Parses spread element.\n\n  pp$2.parseSpread = function(refDestructuringErrors) {\n    var node = this.startNode();\n    this.next();\n    node.argument = this.parseMaybeAssign(false, refDestructuringErrors);\n    return this.finishNode(node, \"SpreadElement\")\n  };\n\n  pp$2.parseRestBinding = function() {\n    var node = this.startNode();\n    this.next();\n\n    // RestElement inside of a function parameter must be an identifier\n    if (this.options.ecmaVersion === 6 && this.type !== types.name)\n      { this.unexpected(); }\n\n    node.argument = this.parseBindingAtom();\n\n    return this.finishNode(node, \"RestElement\")\n  };\n\n  // Parses lvalue (assignable) atom.\n\n  pp$2.parseBindingAtom = function() {\n    if (this.options.ecmaVersion >= 6) {\n      switch (this.type) {\n      case types.bracketL:\n        var node = this.startNode();\n        this.next();\n        node.elements = this.parseBindingList(types.bracketR, true, true);\n        return this.finishNode(node, \"ArrayPattern\")\n\n      case types.braceL:\n        return this.parseObj(true)\n      }\n    }\n    return this.parseIdent()\n  };\n\n  pp$2.parseBindingList = function(close, allowEmpty, allowTrailingComma) {\n    var elts = [], first = true;\n    while (!this.eat(close)) {\n      if (first) { first = false; }\n      else { this.expect(types.comma); }\n      if (allowEmpty && this.type === types.comma) {\n        elts.push(null);\n      } else if (allowTrailingComma && this.afterTrailingComma(close)) {\n        break\n      } else if (this.type === types.ellipsis) {\n        var rest = this.parseRestBinding();\n        this.parseBindingListItem(rest);\n        elts.push(rest);\n        if (this.type === types.comma) { this.raise(this.start, \"Comma is not permitted after the rest element\"); }\n        this.expect(close);\n        break\n      } else {\n        var elem = this.parseMaybeDefault(this.start, this.startLoc);\n        this.parseBindingListItem(elem);\n        elts.push(elem);\n      }\n    }\n    return elts\n  };\n\n  pp$2.parseBindingListItem = function(param) {\n    return param\n  };\n\n  // Parses assignment pattern around given atom if possible.\n\n  pp$2.parseMaybeDefault = function(startPos, startLoc, left) {\n    left = left || this.parseBindingAtom();\n    if (this.options.ecmaVersion < 6 || !this.eat(types.eq)) { return left }\n    var node = this.startNodeAt(startPos, startLoc);\n    node.left = left;\n    node.right = this.parseMaybeAssign();\n    return this.finishNode(node, \"AssignmentPattern\")\n  };\n\n  // Verify that a node is an lval  something that can be assigned\n  // to.\n  // bindingType can be either:\n  // 'var' indicating that the lval creates a 'var' binding\n  // 'let' indicating that the lval creates a lexical ('let' or 'const') binding\n  // 'none' indicating that the binding should be checked for illegal identifiers, but not for duplicate references\n\n  pp$2.checkLVal = function(expr, bindingType, checkClashes) {\n    if ( bindingType === void 0 ) bindingType = BIND_NONE;\n\n    switch (expr.type) {\n    case \"Identifier\":\n      if (bindingType === BIND_LEXICAL && expr.name === \"let\")\n        { this.raiseRecoverable(expr.start, \"let is disallowed as a lexically bound name\"); }\n      if (this.strict && this.reservedWordsStrictBind.test(expr.name))\n        { this.raiseRecoverable(expr.start, (bindingType ? \"Binding \" : \"Assigning to \") + expr.name + \" in strict mode\"); }\n      if (checkClashes) {\n        if (has(checkClashes, expr.name))\n          { this.raiseRecoverable(expr.start, \"Argument name clash\"); }\n        checkClashes[expr.name] = true;\n      }\n      if (bindingType !== BIND_NONE && bindingType !== BIND_OUTSIDE) { this.declareName(expr.name, bindingType, expr.start); }\n      break\n\n    case \"ChainExpression\":\n      this.raiseRecoverable(expr.start, \"Optional chaining cannot appear in left-hand side\");\n      break\n\n    case \"MemberExpression\":\n      if (bindingType) { this.raiseRecoverable(expr.start, \"Binding member expression\"); }\n      break\n\n    case \"ObjectPattern\":\n      for (var i = 0, list = expr.properties; i < list.length; i += 1)\n        {\n      var prop = list[i];\n\n      this.checkLVal(prop, bindingType, checkClashes);\n    }\n      break\n\n    case \"Property\":\n      // AssignmentProperty has type === \"Property\"\n      this.checkLVal(expr.value, bindingType, checkClashes);\n      break\n\n    case \"ArrayPattern\":\n      for (var i$1 = 0, list$1 = expr.elements; i$1 < list$1.length; i$1 += 1) {\n        var elem = list$1[i$1];\n\n      if (elem) { this.checkLVal(elem, bindingType, checkClashes); }\n      }\n      break\n\n    case \"AssignmentPattern\":\n      this.checkLVal(expr.left, bindingType, checkClashes);\n      break\n\n    case \"RestElement\":\n      this.checkLVal(expr.argument, bindingType, checkClashes);\n      break\n\n    case \"ParenthesizedExpression\":\n      this.checkLVal(expr.expression, bindingType, checkClashes);\n      break\n\n    default:\n      this.raise(expr.start, (bindingType ? \"Binding\" : \"Assigning to\") + \" rvalue\");\n    }\n  };\n\n  // A recursive descent parser operates by defining functions for all\n\n  var pp$3 = Parser.prototype;\n\n  // Check if property name clashes with already added.\n  // Object/class getters and setters are not allowed to clash \n  // either with each other or with an init property  and in\n  // strict mode, init properties are also not allowed to be repeated.\n\n  pp$3.checkPropClash = function(prop, propHash, refDestructuringErrors) {\n    if (this.options.ecmaVersion >= 9 && prop.type === \"SpreadElement\")\n      { return }\n    if (this.options.ecmaVersion >= 6 && (prop.computed || prop.method || prop.shorthand))\n      { return }\n    var key = prop.key;\n    var name;\n    switch (key.type) {\n    case \"Identifier\": name = key.name; break\n    case \"Literal\": name = String(key.value); break\n    default: return\n    }\n    var kind = prop.kind;\n    if (this.options.ecmaVersion >= 6) {\n      if (name === \"__proto__\" && kind === \"init\") {\n        if (propHash.proto) {\n          if (refDestructuringErrors) {\n            if (refDestructuringErrors.doubleProto < 0)\n              { refDestructuringErrors.doubleProto = key.start; }\n            // Backwards-compat kludge. Can be removed in version 6.0\n          } else { this.raiseRecoverable(key.start, \"Redefinition of __proto__ property\"); }\n        }\n        propHash.proto = true;\n      }\n      return\n    }\n    name = \"$\" + name;\n    var other = propHash[name];\n    if (other) {\n      var redefinition;\n      if (kind === \"init\") {\n        redefinition = this.strict && other.init || other.get || other.set;\n      } else {\n        redefinition = other.init || other[kind];\n      }\n      if (redefinition)\n        { this.raiseRecoverable(key.start, \"Redefinition of property\"); }\n    } else {\n      other = propHash[name] = {\n        init: false,\n        get: false,\n        set: false\n      };\n    }\n    other[kind] = true;\n  };\n\n  // ### Expression parsing\n\n  // These nest, from the most general expression type at the top to\n  // 'atomic', nondivisible expression types at the bottom. Most of\n  // the functions will simply let the function(s) below them parse,\n  // and, *if* the syntactic construct they handle is present, wrap\n  // the AST node that the inner parser gave them in another node.\n\n  // Parse a full expression. The optional arguments are used to\n  // forbid the `in` operator (in for loops initalization expressions)\n  // and provide reference for storing '=' operator inside shorthand\n  // property assignment in contexts where both object expression\n  // and object pattern might appear (so it's possible to raise\n  // delayed syntax error at correct position).\n\n  pp$3.parseExpression = function(noIn, refDestructuringErrors) {\n    var startPos = this.start, startLoc = this.startLoc;\n    var expr = this.parseMaybeAssign(noIn, refDestructuringErrors);\n    if (this.type === types.comma) {\n      var node = this.startNodeAt(startPos, startLoc);\n      node.expressions = [expr];\n      while (this.eat(types.comma)) { node.expressions.push(this.parseMaybeAssign(noIn, refDestructuringErrors)); }\n      return this.finishNode(node, \"SequenceExpression\")\n    }\n    return expr\n  };\n\n  // Parse an assignment expression. This includes applications of\n  // operators like `+=`.\n\n  pp$3.parseMaybeAssign = function(noIn, refDestructuringErrors, afterLeftParse) {\n    if (this.isContextual(\"yield\")) {\n      if (this.inGenerator) { return this.parseYield(noIn) }\n      // The tokenizer will assume an expression is allowed after\n      // `yield`, but this isn't that kind of yield\n      else { this.exprAllowed = false; }\n    }\n\n    var ownDestructuringErrors = false, oldParenAssign = -1, oldTrailingComma = -1;\n    if (refDestructuringErrors) {\n      oldParenAssign = refDestructuringErrors.parenthesizedAssign;\n      oldTrailingComma = refDestructuringErrors.trailingComma;\n      refDestructuringErrors.parenthesizedAssign = refDestructuringErrors.trailingComma = -1;\n    } else {\n      refDestructuringErrors = new DestructuringErrors;\n      ownDestructuringErrors = true;\n    }\n\n    var startPos = this.start, startLoc = this.startLoc;\n    if (this.type === types.parenL || this.type === types.name)\n      { this.potentialArrowAt = this.start; }\n    var left = this.parseMaybeConditional(noIn, refDestructuringErrors);\n    if (afterLeftParse) { left = afterLeftParse.call(this, left, startPos, startLoc); }\n    if (this.type.isAssign) {\n      var node = this.startNodeAt(startPos, startLoc);\n      node.operator = this.value;\n      node.left = this.type === types.eq ? this.toAssignable(left, false, refDestructuringErrors) : left;\n      if (!ownDestructuringErrors) {\n        refDestructuringErrors.parenthesizedAssign = refDestructuringErrors.trailingComma = refDestructuringErrors.doubleProto = -1;\n      }\n      if (refDestructuringErrors.shorthandAssign >= node.left.start)\n        { refDestructuringErrors.shorthandAssign = -1; } // reset because shorthand default was used correctly\n      this.checkLVal(left);\n      this.next();\n      node.right = this.parseMaybeAssign(noIn);\n      return this.finishNode(node, \"AssignmentExpression\")\n    } else {\n      if (ownDestructuringErrors) { this.checkExpressionErrors(refDestructuringErrors, true); }\n    }\n    if (oldParenAssign > -1) { refDestructuringErrors.parenthesizedAssign = oldParenAssign; }\n    if (oldTrailingComma > -1) { refDestructuringErrors.trailingComma = oldTrailingComma; }\n    return left\n  };\n\n  // Parse a ternary conditional (`?:`) operator.\n\n  pp$3.parseMaybeConditional = function(noIn, refDestructuringErrors) {\n    var startPos = this.start, startLoc = this.startLoc;\n    var expr = this.parseExprOps(noIn, refDestructuringErrors);\n    if (this.checkExpressionErrors(refDestructuringErrors)) { return expr }\n    if (this.eat(types.question)) {\n      var node = this.startNodeAt(startPos, startLoc);\n      node.test = expr;\n      node.consequent = this.parseMaybeAssign();\n      this.expect(types.colon);\n      node.alternate = this.parseMaybeAssign(noIn);\n      return this.finishNode(node, \"ConditionalExpression\")\n    }\n    return expr\n  };\n\n  // Start the precedence parser.\n\n  pp$3.parseExprOps = function(noIn, refDestructuringErrors) {\n    var startPos = this.start, startLoc = this.startLoc;\n    var expr = this.parseMaybeUnary(refDestructuringErrors, false);\n    if (this.checkExpressionErrors(refDestructuringErrors)) { return expr }\n    return expr.start === startPos && expr.type === \"ArrowFunctionExpression\" ? expr : this.parseExprOp(expr, startPos, startLoc, -1, noIn)\n  };\n\n  // Parse binary operators with the operator precedence parsing\n  // algorithm. `left` is the left-hand side of the operator.\n  // `minPrec` provides context that allows the function to stop and\n  // defer further parser to one of its callers when it encounters an\n  // operator that has a lower precedence than the set it is parsing.\n\n  pp$3.parseExprOp = function(left, leftStartPos, leftStartLoc, minPrec, noIn) {\n    var prec = this.type.binop;\n    if (prec != null && (!noIn || this.type !== types._in)) {\n      if (prec > minPrec) {\n        var logical = this.type === types.logicalOR || this.type === types.logicalAND;\n        var coalesce = this.type === types.coalesce;\n        if (coalesce) {\n          // Handle the precedence of `tt.coalesce` as equal to the range of logical expressions.\n          // In other words, `node.right` shouldn't contain logical expressions in order to check the mixed error.\n          prec = types.logicalAND.binop;\n        }\n        var op = this.value;\n        this.next();\n        var startPos = this.start, startLoc = this.startLoc;\n        var right = this.parseExprOp(this.parseMaybeUnary(null, false), startPos, startLoc, prec, noIn);\n        var node = this.buildBinary(leftStartPos, leftStartLoc, left, right, op, logical || coalesce);\n        if ((logical && this.type === types.coalesce) || (coalesce && (this.type === types.logicalOR || this.type === types.logicalAND))) {\n          this.raiseRecoverable(this.start, \"Logical expressions and coalesce expressions cannot be mixed. Wrap either by parentheses\");\n        }\n        return this.parseExprOp(node, leftStartPos, leftStartLoc, minPrec, noIn)\n      }\n    }\n    return left\n  };\n\n  pp$3.buildBinary = function(startPos, startLoc, left, right, op, logical) {\n    var node = this.startNodeAt(startPos, startLoc);\n    node.left = left;\n    node.operator = op;\n    node.right = right;\n    return this.finishNode(node, logical ? \"LogicalExpression\" : \"BinaryExpression\")\n  };\n\n  // Parse unary operators, both prefix and postfix.\n\n  pp$3.parseMaybeUnary = function(refDestructuringErrors, sawUnary) {\n    var startPos = this.start, startLoc = this.startLoc, expr;\n    if (this.isContextual(\"await\") && (this.inAsync || (!this.inFunction && this.options.allowAwaitOutsideFunction))) {\n      expr = this.parseAwait();\n      sawUnary = true;\n    } else if (this.type.prefix) {\n      var node = this.startNode(), update = this.type === types.incDec;\n      node.operator = this.value;\n      node.prefix = true;\n      this.next();\n      node.argument = this.parseMaybeUnary(null, true);\n      this.checkExpressionErrors(refDestructuringErrors, true);\n      if (update) { this.checkLVal(node.argument); }\n      else if (this.strict && node.operator === \"delete\" &&\n               node.argument.type === \"Identifier\")\n        { this.raiseRecoverable(node.start, \"Deleting local variable in strict mode\"); }\n      else { sawUnary = true; }\n      expr = this.finishNode(node, update ? \"UpdateExpression\" : \"UnaryExpression\");\n    } else {\n      expr = this.parseExprSubscripts(refDestructuringErrors);\n      if (this.checkExpressionErrors(refDestructuringErrors)) { return expr }\n      while (this.type.postfix && !this.canInsertSemicolon()) {\n        var node$1 = this.startNodeAt(startPos, startLoc);\n        node$1.operator = this.value;\n        node$1.prefix = false;\n        node$1.argument = expr;\n        this.checkLVal(expr);\n        this.next();\n        expr = this.finishNode(node$1, \"UpdateExpression\");\n      }\n    }\n\n    if (!sawUnary && this.eat(types.starstar))\n      { return this.buildBinary(startPos, startLoc, expr, this.parseMaybeUnary(null, false), \"**\", false) }\n    else\n      { return expr }\n  };\n\n  // Parse call, dot, and `[]`-subscript expressions.\n\n  pp$3.parseExprSubscripts = function(refDestructuringErrors) {\n    var startPos = this.start, startLoc = this.startLoc;\n    var expr = this.parseExprAtom(refDestructuringErrors);\n    if (expr.type === \"ArrowFunctionExpression\" && this.input.slice(this.lastTokStart, this.lastTokEnd) !== \")\")\n      { return expr }\n    var result = this.parseSubscripts(expr, startPos, startLoc);\n    if (refDestructuringErrors && result.type === \"MemberExpression\") {\n      if (refDestructuringErrors.parenthesizedAssign >= result.start) { refDestructuringErrors.parenthesizedAssign = -1; }\n      if (refDestructuringErrors.parenthesizedBind >= result.start) { refDestructuringErrors.parenthesizedBind = -1; }\n    }\n    return result\n  };\n\n  pp$3.parseSubscripts = function(base, startPos, startLoc, noCalls) {\n    var maybeAsyncArrow = this.options.ecmaVersion >= 8 && base.type === \"Identifier\" && base.name === \"async\" &&\n        this.lastTokEnd === base.end && !this.canInsertSemicolon() && base.end - base.start === 5 &&\n        this.potentialArrowAt === base.start;\n    var optionalChained = false;\n\n    while (true) {\n      var element = this.parseSubscript(base, startPos, startLoc, noCalls, maybeAsyncArrow, optionalChained);\n\n      if (element.optional) { optionalChained = true; }\n      if (element === base || element.type === \"ArrowFunctionExpression\") {\n        if (optionalChained) {\n          var chainNode = this.startNodeAt(startPos, startLoc);\n          chainNode.expression = element;\n          element = this.finishNode(chainNode, \"ChainExpression\");\n        }\n        return element\n      }\n\n      base = element;\n    }\n  };\n\n  pp$3.parseSubscript = function(base, startPos, startLoc, noCalls, maybeAsyncArrow, optionalChained) {\n    var optionalSupported = this.options.ecmaVersion >= 11;\n    var optional = optionalSupported && this.eat(types.questionDot);\n    if (noCalls && optional) { this.raise(this.lastTokStart, \"Optional chaining cannot appear in the callee of new expressions\"); }\n\n    var computed = this.eat(types.bracketL);\n    if (computed || (optional && this.type !== types.parenL && this.type !== types.backQuote) || this.eat(types.dot)) {\n      var node = this.startNodeAt(startPos, startLoc);\n      node.object = base;\n      node.property = computed ? this.parseExpression() : this.parseIdent(this.options.allowReserved !== \"never\");\n      node.computed = !!computed;\n      if (computed) { this.expect(types.bracketR); }\n      if (optionalSupported) {\n        node.optional = optional;\n      }\n      base = this.finishNode(node, \"MemberExpression\");\n    } else if (!noCalls && this.eat(types.parenL)) {\n      var refDestructuringErrors = new DestructuringErrors, oldYieldPos = this.yieldPos, oldAwaitPos = this.awaitPos, oldAwaitIdentPos = this.awaitIdentPos;\n      this.yieldPos = 0;\n      this.awaitPos = 0;\n      this.awaitIdentPos = 0;\n      var exprList = this.parseExprList(types.parenR, this.options.ecmaVersion >= 8, false, refDestructuringErrors);\n      if (maybeAsyncArrow && !optional && !this.canInsertSemicolon() && this.eat(types.arrow)) {\n        this.checkPatternErrors(refDestructuringErrors, false);\n        this.checkYieldAwaitInDefaultParams();\n        if (this.awaitIdentPos > 0)\n          { this.raise(this.awaitIdentPos, \"Cannot use 'await' as identifier inside an async function\"); }\n        this.yieldPos = oldYieldPos;\n        this.awaitPos = oldAwaitPos;\n        this.awaitIdentPos = oldAwaitIdentPos;\n        return this.parseArrowExpression(this.startNodeAt(startPos, startLoc), exprList, true)\n      }\n      this.checkExpressionErrors(refDestructuringErrors, true);\n      this.yieldPos = oldYieldPos || this.yieldPos;\n      this.awaitPos = oldAwaitPos || this.awaitPos;\n      this.awaitIdentPos = oldAwaitIdentPos || this.awaitIdentPos;\n      var node$1 = this.startNodeAt(startPos, startLoc);\n      node$1.callee = base;\n      node$1.arguments = exprList;\n      if (optionalSupported) {\n        node$1.optional = optional;\n      }\n      base = this.finishNode(node$1, \"CallExpression\");\n    } else if (this.type === types.backQuote) {\n      if (optional || optionalChained) {\n        this.raise(this.start, \"Optional chaining cannot appear in the tag of tagged template expressions\");\n      }\n      var node$2 = this.startNodeAt(startPos, startLoc);\n      node$2.tag = base;\n      node$2.quasi = this.parseTemplate({isTagged: true});\n      base = this.finishNode(node$2, \"TaggedTemplateExpression\");\n    }\n    return base\n  };\n\n  // Parse an atomic expression  either a single token that is an\n  // expression, an expression started by a keyword like `function` or\n  // `new`, or an expression wrapped in punctuation like `()`, `[]`,\n  // or `{}`.\n\n  pp$3.parseExprAtom = function(refDestructuringErrors) {\n    // If a division operator appears in an expression position, the\n    // tokenizer got confused, and we force it to read a regexp instead.\n    if (this.type === types.slash) { this.readRegexp(); }\n\n    var node, canBeArrow = this.potentialArrowAt === this.start;\n    switch (this.type) {\n    case types._super:\n      if (!this.allowSuper)\n        { this.raise(this.start, \"'super' keyword outside a method\"); }\n      node = this.startNode();\n      this.next();\n      if (this.type === types.parenL && !this.allowDirectSuper)\n        { this.raise(node.start, \"super() call outside constructor of a subclass\"); }\n      // The `super` keyword can appear at below:\n      // SuperProperty:\n      //     super [ Expression ]\n      //     super . IdentifierName\n      // SuperCall:\n      //     super ( Arguments )\n      if (this.type !== types.dot && this.type !== types.bracketL && this.type !== types.parenL)\n        { this.unexpected(); }\n      return this.finishNode(node, \"Super\")\n\n    case types._this:\n      node = this.startNode();\n      this.next();\n      return this.finishNode(node, \"ThisExpression\")\n\n    case types.name:\n      var startPos = this.start, startLoc = this.startLoc, containsEsc = this.containsEsc;\n      var id = this.parseIdent(false);\n      if (this.options.ecmaVersion >= 8 && !containsEsc && id.name === \"async\" && !this.canInsertSemicolon() && this.eat(types._function))\n        { return this.parseFunction(this.startNodeAt(startPos, startLoc), 0, false, true) }\n      if (canBeArrow && !this.canInsertSemicolon()) {\n        if (this.eat(types.arrow))\n          { return this.parseArrowExpression(this.startNodeAt(startPos, startLoc), [id], false) }\n        if (this.options.ecmaVersion >= 8 && id.name === \"async\" && this.type === types.name && !containsEsc) {\n          id = this.parseIdent(false);\n          if (this.canInsertSemicolon() || !this.eat(types.arrow))\n            { this.unexpected(); }\n          return this.parseArrowExpression(this.startNodeAt(startPos, startLoc), [id], true)\n        }\n      }\n      return id\n\n    case types.regexp:\n      var value = this.value;\n      node = this.parseLiteral(value.value);\n      node.regex = {pattern: value.pattern, flags: value.flags};\n      return node\n\n    case types.num: case types.string:\n      return this.parseLiteral(this.value)\n\n    case types._null: case types._true: case types._false:\n      node = this.startNode();\n      node.value = this.type === types._null ? null : this.type === types._true;\n      node.raw = this.type.keyword;\n      this.next();\n      return this.finishNode(node, \"Literal\")\n\n    case types.parenL:\n      var start = this.start, expr = this.parseParenAndDistinguishExpression(canBeArrow);\n      if (refDestructuringErrors) {\n        if (refDestructuringErrors.parenthesizedAssign < 0 && !this.isSimpleAssignTarget(expr))\n          { refDestructuringErrors.parenthesizedAssign = start; }\n        if (refDestructuringErrors.parenthesizedBind < 0)\n          { refDestructuringErrors.parenthesizedBind = start; }\n      }\n      return expr\n\n    case types.bracketL:\n      node = this.startNode();\n      this.next();\n      node.elements = this.parseExprList(types.bracketR, true, true, refDestructuringErrors);\n      return this.finishNode(node, \"ArrayExpression\")\n\n    case types.braceL:\n      return this.parseObj(false, refDestructuringErrors)\n\n    case types._function:\n      node = this.startNode();\n      this.next();\n      return this.parseFunction(node, 0)\n\n    case types._class:\n      return this.parseClass(this.startNode(), false)\n\n    case types._new:\n      return this.parseNew()\n\n    case types.backQuote:\n      return this.parseTemplate()\n\n    case types._import:\n      if (this.options.ecmaVersion >= 11) {\n        return this.parseExprImport()\n      } else {\n        return this.unexpected()\n      }\n\n    default:\n      this.unexpected();\n    }\n  };\n\n  pp$3.parseExprImport = function() {\n    var node = this.startNode();\n\n    // Consume `import` as an identifier for `import.meta`.\n    // Because `this.parseIdent(true)` doesn't check escape sequences, it needs the check of `this.containsEsc`.\n    if (this.containsEsc) { this.raiseRecoverable(this.start, \"Escape sequence in keyword import\"); }\n    var meta = this.parseIdent(true);\n\n    switch (this.type) {\n    case types.parenL:\n      return this.parseDynamicImport(node)\n    case types.dot:\n      node.meta = meta;\n      return this.parseImportMeta(node)\n    default:\n      this.unexpected();\n    }\n  };\n\n  pp$3.parseDynamicImport = function(node) {\n    this.next(); // skip `(`\n\n    // Parse node.source.\n    node.source = this.parseMaybeAssign();\n\n    // Verify ending.\n    if (!this.eat(types.parenR)) {\n      var errorPos = this.start;\n      if (this.eat(types.comma) && this.eat(types.parenR)) {\n        this.raiseRecoverable(errorPos, \"Trailing comma is not allowed in import()\");\n      } else {\n        this.unexpected(errorPos);\n      }\n    }\n\n    return this.finishNode(node, \"ImportExpression\")\n  };\n\n  pp$3.parseImportMeta = function(node) {\n    this.next(); // skip `.`\n\n    var containsEsc = this.containsEsc;\n    node.property = this.parseIdent(true);\n\n    if (node.property.name !== \"meta\")\n      { this.raiseRecoverable(node.property.start, \"The only valid meta property for import is 'import.meta'\"); }\n    if (containsEsc)\n      { this.raiseRecoverable(node.start, \"'import.meta' must not contain escaped characters\"); }\n    if (this.options.sourceType !== \"module\")\n      { this.raiseRecoverable(node.start, \"Cannot use 'import.meta' outside a module\"); }\n\n    return this.finishNode(node, \"MetaProperty\")\n  };\n\n  pp$3.parseLiteral = function(value) {\n    var node = this.startNode();\n    node.value = value;\n    node.raw = this.input.slice(this.start, this.end);\n    if (node.raw.charCodeAt(node.raw.length - 1) === 110) { node.bigint = node.raw.slice(0, -1).replace(/_/g, \"\"); }\n    this.next();\n    return this.finishNode(node, \"Literal\")\n  };\n\n  pp$3.parseParenExpression = function() {\n    this.expect(types.parenL);\n    var val = this.parseExpression();\n    this.expect(types.parenR);\n    return val\n  };\n\n  pp$3.parseParenAndDistinguishExpression = function(canBeArrow) {\n    var startPos = this.start, startLoc = this.startLoc, val, allowTrailingComma = this.options.ecmaVersion >= 8;\n    if (this.options.ecmaVersion >= 6) {\n      this.next();\n\n      var innerStartPos = this.start, innerStartLoc = this.startLoc;\n      var exprList = [], first = true, lastIsComma = false;\n      var refDestructuringErrors = new DestructuringErrors, oldYieldPos = this.yieldPos, oldAwaitPos = this.awaitPos, spreadStart;\n      this.yieldPos = 0;\n      this.awaitPos = 0;\n      // Do not save awaitIdentPos to allow checking awaits nested in parameters\n      while (this.type !== types.parenR) {\n        first ? first = false : this.expect(types.comma);\n        if (allowTrailingComma && this.afterTrailingComma(types.parenR, true)) {\n          lastIsComma = true;\n          break\n        } else if (this.type === types.ellipsis) {\n          spreadStart = this.start;\n          exprList.push(this.parseParenItem(this.parseRestBinding()));\n          if (this.type === types.comma) { this.raise(this.start, \"Comma is not permitted after the rest element\"); }\n          break\n        } else {\n          exprList.push(this.parseMaybeAssign(false, refDestructuringErrors, this.parseParenItem));\n        }\n      }\n      var innerEndPos = this.start, innerEndLoc = this.startLoc;\n      this.expect(types.parenR);\n\n      if (canBeArrow && !this.canInsertSemicolon() && this.eat(types.arrow)) {\n        this.checkPatternErrors(refDestructuringErrors, false);\n        this.checkYieldAwaitInDefaultParams();\n        this.yieldPos = oldYieldPos;\n        this.awaitPos = oldAwaitPos;\n        return this.parseParenArrowList(startPos, startLoc, exprList)\n      }\n\n      if (!exprList.length || lastIsComma) { this.unexpected(this.lastTokStart); }\n      if (spreadStart) { this.unexpected(spreadStart); }\n      this.checkExpressionErrors(refDestructuringErrors, true);\n      this.yieldPos = oldYieldPos || this.yieldPos;\n      this.awaitPos = oldAwaitPos || this.awaitPos;\n\n      if (exprList.length > 1) {\n        val = this.startNodeAt(innerStartPos, innerStartLoc);\n        val.expressions = exprList;\n        this.finishNodeAt(val, \"SequenceExpression\", innerEndPos, innerEndLoc);\n      } else {\n        val = exprList[0];\n      }\n    } else {\n      val = this.parseParenExpression();\n    }\n\n    if (this.options.preserveParens) {\n      var par = this.startNodeAt(startPos, startLoc);\n      par.expression = val;\n      return this.finishNode(par, \"ParenthesizedExpression\")\n    } else {\n      return val\n    }\n  };\n\n  pp$3.parseParenItem = function(item) {\n    return item\n  };\n\n  pp$3.parseParenArrowList = function(startPos, startLoc, exprList) {\n    return this.parseArrowExpression(this.startNodeAt(startPos, startLoc), exprList)\n  };\n\n  // New's precedence is slightly tricky. It must allow its argument to\n  // be a `[]` or dot subscript expression, but not a call  at least,\n  // not without wrapping it in parentheses. Thus, it uses the noCalls\n  // argument to parseSubscripts to prevent it from consuming the\n  // argument list.\n\n  var empty$1 = [];\n\n  pp$3.parseNew = function() {\n    if (this.containsEsc) { this.raiseRecoverable(this.start, \"Escape sequence in keyword new\"); }\n    var node = this.startNode();\n    var meta = this.parseIdent(true);\n    if (this.options.ecmaVersion >= 6 && this.eat(types.dot)) {\n      node.meta = meta;\n      var containsEsc = this.containsEsc;\n      node.property = this.parseIdent(true);\n      if (node.property.name !== \"target\")\n        { this.raiseRecoverable(node.property.start, \"The only valid meta property for new is 'new.target'\"); }\n      if (containsEsc)\n        { this.raiseRecoverable(node.start, \"'new.target' must not contain escaped characters\"); }\n      if (!this.inNonArrowFunction())\n        { this.raiseRecoverable(node.start, \"'new.target' can only be used in functions\"); }\n      return this.finishNode(node, \"MetaProperty\")\n    }\n    var startPos = this.start, startLoc = this.startLoc, isImport = this.type === types._import;\n    node.callee = this.parseSubscripts(this.parseExprAtom(), startPos, startLoc, true);\n    if (isImport && node.callee.type === \"ImportExpression\") {\n      this.raise(startPos, \"Cannot use new with import()\");\n    }\n    if (this.eat(types.parenL)) { node.arguments = this.parseExprList(types.parenR, this.options.ecmaVersion >= 8, false); }\n    else { node.arguments = empty$1; }\n    return this.finishNode(node, \"NewExpression\")\n  };\n\n  // Parse template expression.\n\n  pp$3.parseTemplateElement = function(ref) {\n    var isTagged = ref.isTagged;\n\n    var elem = this.startNode();\n    if (this.type === types.invalidTemplate) {\n      if (!isTagged) {\n        this.raiseRecoverable(this.start, \"Bad escape sequence in untagged template literal\");\n      }\n      elem.value = {\n        raw: this.value,\n        cooked: null\n      };\n    } else {\n      elem.value = {\n        raw: this.input.slice(this.start, this.end).replace(/\\r\\n?/g, \"\\n\"),\n        cooked: this.value\n      };\n    }\n    this.next();\n    elem.tail = this.type === types.backQuote;\n    return this.finishNode(elem, \"TemplateElement\")\n  };\n\n  pp$3.parseTemplate = function(ref) {\n    if ( ref === void 0 ) ref = {};\n    var isTagged = ref.isTagged; if ( isTagged === void 0 ) isTagged = false;\n\n    var node = this.startNode();\n    this.next();\n    node.expressions = [];\n    var curElt = this.parseTemplateElement({isTagged: isTagged});\n    node.quasis = [curElt];\n    while (!curElt.tail) {\n      if (this.type === types.eof) { this.raise(this.pos, \"Unterminated template literal\"); }\n      this.expect(types.dollarBraceL);\n      node.expressions.push(this.parseExpression());\n      this.expect(types.braceR);\n      node.quasis.push(curElt = this.parseTemplateElement({isTagged: isTagged}));\n    }\n    this.next();\n    return this.finishNode(node, \"TemplateLiteral\")\n  };\n\n  pp$3.isAsyncProp = function(prop) {\n    return !prop.computed && prop.key.type === \"Identifier\" && prop.key.name === \"async\" &&\n      (this.type === types.name || this.type === types.num || this.type === types.string || this.type === types.bracketL || this.type.keyword || (this.options.ecmaVersion >= 9 && this.type === types.star)) &&\n      !lineBreak.test(this.input.slice(this.lastTokEnd, this.start))\n  };\n\n  // Parse an object literal or binding pattern.\n\n  pp$3.parseObj = function(isPattern, refDestructuringErrors) {\n    var node = this.startNode(), first = true, propHash = {};\n    node.properties = [];\n    this.next();\n    while (!this.eat(types.braceR)) {\n      if (!first) {\n        this.expect(types.comma);\n        if (this.options.ecmaVersion >= 5 && this.afterTrailingComma(types.braceR)) { break }\n      } else { first = false; }\n\n      var prop = this.parseProperty(isPattern, refDestructuringErrors);\n      if (!isPattern) { this.checkPropClash(prop, propHash, refDestructuringErrors); }\n      node.properties.push(prop);\n    }\n    return this.finishNode(node, isPattern ? \"ObjectPattern\" : \"ObjectExpression\")\n  };\n\n  pp$3.parseProperty = function(isPattern, refDestructuringErrors) {\n    var prop = this.startNode(), isGenerator, isAsync, startPos, startLoc;\n    if (this.options.ecmaVersion >= 9 && this.eat(types.ellipsis)) {\n      if (isPattern) {\n        prop.argument = this.parseIdent(false);\n        if (this.type === types.comma) {\n          this.raise(this.start, \"Comma is not permitted after the rest element\");\n        }\n        return this.finishNode(prop, \"RestElement\")\n      }\n      // To disallow parenthesized identifier via `this.toAssignable()`.\n      if (this.type === types.parenL && refDestructuringErrors) {\n        if (refDestructuringErrors.parenthesizedAssign < 0) {\n          refDestructuringErrors.parenthesizedAssign = this.start;\n        }\n        if (refDestructuringErrors.parenthesizedBind < 0) {\n          refDestructuringErrors.parenthesizedBind = this.start;\n        }\n      }\n      // Parse argument.\n      prop.argument = this.parseMaybeAssign(false, refDestructuringErrors);\n      // To disallow trailing comma via `this.toAssignable()`.\n      if (this.type === types.comma && refDestructuringErrors && refDestructuringErrors.trailingComma < 0) {\n        refDestructuringErrors.trailingComma = this.start;\n      }\n      // Finish\n      return this.finishNode(prop, \"SpreadElement\")\n    }\n    if (this.options.ecmaVersion >= 6) {\n      prop.method = false;\n      prop.shorthand = false;\n      if (isPattern || refDestructuringErrors) {\n        startPos = this.start;\n        startLoc = this.startLoc;\n      }\n      if (!isPattern)\n        { isGenerator = this.eat(types.star); }\n    }\n    var containsEsc = this.containsEsc;\n    this.parsePropertyName(prop);\n    if (!isPattern && !containsEsc && this.options.ecmaVersion >= 8 && !isGenerator && this.isAsyncProp(prop)) {\n      isAsync = true;\n      isGenerator = this.options.ecmaVersion >= 9 && this.eat(types.star);\n      this.parsePropertyName(prop, refDestructuringErrors);\n    } else {\n      isAsync = false;\n    }\n    this.parsePropertyValue(prop, isPattern, isGenerator, isAsync, startPos, startLoc, refDestructuringErrors, containsEsc);\n    return this.finishNode(prop, \"Property\")\n  };\n\n  pp$3.parsePropertyValue = function(prop, isPattern, isGenerator, isAsync, startPos, startLoc, refDestructuringErrors, containsEsc) {\n    if ((isGenerator || isAsync) && this.type === types.colon)\n      { this.unexpected(); }\n\n    if (this.eat(types.colon)) {\n      prop.value = isPattern ? this.parseMaybeDefault(this.start, this.startLoc) : this.parseMaybeAssign(false, refDestructuringErrors);\n      prop.kind = \"init\";\n    } else if (this.options.ecmaVersion >= 6 && this.type === types.parenL) {\n      if (isPattern) { this.unexpected(); }\n      prop.kind = \"init\";\n      prop.method = true;\n      prop.value = this.parseMethod(isGenerator, isAsync);\n    } else if (!isPattern && !containsEsc &&\n               this.options.ecmaVersion >= 5 && !prop.computed && prop.key.type === \"Identifier\" &&\n               (prop.key.name === \"get\" || prop.key.name === \"set\") &&\n               (this.type !== types.comma && this.type !== types.braceR && this.type !== types.eq)) {\n      if (isGenerator || isAsync) { this.unexpected(); }\n      prop.kind = prop.key.name;\n      this.parsePropertyName(prop);\n      prop.value = this.parseMethod(false);\n      var paramCount = prop.kind === \"get\" ? 0 : 1;\n      if (prop.value.params.length !== paramCount) {\n        var start = prop.value.start;\n        if (prop.kind === \"get\")\n          { this.raiseRecoverable(start, \"getter should have no params\"); }\n        else\n          { this.raiseRecoverable(start, \"setter should have exactly one param\"); }\n      } else {\n        if (prop.kind === \"set\" && prop.value.params[0].type === \"RestElement\")\n          { this.raiseRecoverable(prop.value.params[0].start, \"Setter cannot use rest params\"); }\n      }\n    } else if (this.options.ecmaVersion >= 6 && !prop.computed && prop.key.type === \"Identifier\") {\n      if (isGenerator || isAsync) { this.unexpected(); }\n      this.checkUnreserved(prop.key);\n      if (prop.key.name === \"await\" && !this.awaitIdentPos)\n        { this.awaitIdentPos = startPos; }\n      prop.kind = \"init\";\n      if (isPattern) {\n        prop.value = this.parseMaybeDefault(startPos, startLoc, prop.key);\n      } else if (this.type === types.eq && refDestructuringErrors) {\n        if (refDestructuringErrors.shorthandAssign < 0)\n          { refDestructuringErrors.shorthandAssign = this.start; }\n        prop.value = this.parseMaybeDefault(startPos, startLoc, prop.key);\n      } else {\n        prop.value = prop.key;\n      }\n      prop.shorthand = true;\n    } else { this.unexpected(); }\n  };\n\n  pp$3.parsePropertyName = function(prop) {\n    if (this.options.ecmaVersion >= 6) {\n      if (this.eat(types.bracketL)) {\n        prop.computed = true;\n        prop.key = this.parseMaybeAssign();\n        this.expect(types.bracketR);\n        return prop.key\n      } else {\n        prop.computed = false;\n      }\n    }\n    return prop.key = this.type === types.num || this.type === types.string ? this.parseExprAtom() : this.parseIdent(this.options.allowReserved !== \"never\")\n  };\n\n  // Initialize empty function node.\n\n  pp$3.initFunction = function(node) {\n    node.id = null;\n    if (this.options.ecmaVersion >= 6) { node.generator = node.expression = false; }\n    if (this.options.ecmaVersion >= 8) { node.async = false; }\n  };\n\n  // Parse object or class method.\n\n  pp$3.parseMethod = function(isGenerator, isAsync, allowDirectSuper) {\n    var node = this.startNode(), oldYieldPos = this.yieldPos, oldAwaitPos = this.awaitPos, oldAwaitIdentPos = this.awaitIdentPos;\n\n    this.initFunction(node);\n    if (this.options.ecmaVersion >= 6)\n      { node.generator = isGenerator; }\n    if (this.options.ecmaVersion >= 8)\n      { node.async = !!isAsync; }\n\n    this.yieldPos = 0;\n    this.awaitPos = 0;\n    this.awaitIdentPos = 0;\n    this.enterScope(functionFlags(isAsync, node.generator) | SCOPE_SUPER | (allowDirectSuper ? SCOPE_DIRECT_SUPER : 0));\n\n    this.expect(types.parenL);\n    node.params = this.parseBindingList(types.parenR, false, this.options.ecmaVersion >= 8);\n    this.checkYieldAwaitInDefaultParams();\n    this.parseFunctionBody(node, false, true);\n\n    this.yieldPos = oldYieldPos;\n    this.awaitPos = oldAwaitPos;\n    this.awaitIdentPos = oldAwaitIdentPos;\n    return this.finishNode(node, \"FunctionExpression\")\n  };\n\n  // Parse arrow function expression with given parameters.\n\n  pp$3.parseArrowExpression = function(node, params, isAsync) {\n    var oldYieldPos = this.yieldPos, oldAwaitPos = this.awaitPos, oldAwaitIdentPos = this.awaitIdentPos;\n\n    this.enterScope(functionFlags(isAsync, false) | SCOPE_ARROW);\n    this.initFunction(node);\n    if (this.options.ecmaVersion >= 8) { node.async = !!isAsync; }\n\n    this.yieldPos = 0;\n    this.awaitPos = 0;\n    this.awaitIdentPos = 0;\n\n    node.params = this.toAssignableList(params, true);\n    this.parseFunctionBody(node, true, false);\n\n    this.yieldPos = oldYieldPos;\n    this.awaitPos = oldAwaitPos;\n    this.awaitIdentPos = oldAwaitIdentPos;\n    return this.finishNode(node, \"ArrowFunctionExpression\")\n  };\n\n  // Parse function body and check parameters.\n\n  pp$3.parseFunctionBody = function(node, isArrowFunction, isMethod) {\n    var isExpression = isArrowFunction && this.type !== types.braceL;\n    var oldStrict = this.strict, useStrict = false;\n\n    if (isExpression) {\n      node.body = this.parseMaybeAssign();\n      node.expression = true;\n      this.checkParams(node, false);\n    } else {\n      var nonSimple = this.options.ecmaVersion >= 7 && !this.isSimpleParamList(node.params);\n      if (!oldStrict || nonSimple) {\n        useStrict = this.strictDirective(this.end);\n        // If this is a strict mode function, verify that argument names\n        // are not repeated, and it does not try to bind the words `eval`\n        // or `arguments`.\n        if (useStrict && nonSimple)\n          { this.raiseRecoverable(node.start, \"Illegal 'use strict' directive in function with non-simple parameter list\"); }\n      }\n      // Start a new scope with regard to labels and the `inFunction`\n      // flag (restore them to their old value afterwards).\n      var oldLabels = this.labels;\n      this.labels = [];\n      if (useStrict) { this.strict = true; }\n\n      // Add the params to varDeclaredNames to ensure that an error is thrown\n      // if a let/const declaration in the function clashes with one of the params.\n      this.checkParams(node, !oldStrict && !useStrict && !isArrowFunction && !isMethod && this.isSimpleParamList(node.params));\n      // Ensure the function name isn't a forbidden identifier in strict mode, e.g. 'eval'\n      if (this.strict && node.id) { this.checkLVal(node.id, BIND_OUTSIDE); }\n      node.body = this.parseBlock(false, undefined, useStrict && !oldStrict);\n      node.expression = false;\n      this.adaptDirectivePrologue(node.body.body);\n      this.labels = oldLabels;\n    }\n    this.exitScope();\n  };\n\n  pp$3.isSimpleParamList = function(params) {\n    for (var i = 0, list = params; i < list.length; i += 1)\n      {\n      var param = list[i];\n\n      if (param.type !== \"Identifier\") { return false\n    } }\n    return true\n  };\n\n  // Checks function params for various disallowed patterns such as using \"eval\"\n  // or \"arguments\" and duplicate parameters.\n\n  pp$3.checkParams = function(node, allowDuplicates) {\n    var nameHash = {};\n    for (var i = 0, list = node.params; i < list.length; i += 1)\n      {\n      var param = list[i];\n\n      this.checkLVal(param, BIND_VAR, allowDuplicates ? null : nameHash);\n    }\n  };\n\n  // Parses a comma-separated list of expressions, and returns them as\n  // an array. `close` is the token type that ends the list, and\n  // `allowEmpty` can be turned on to allow subsequent commas with\n  // nothing in between them to be parsed as `null` (which is needed\n  // for array literals).\n\n  pp$3.parseExprList = function(close, allowTrailingComma, allowEmpty, refDestructuringErrors) {\n    var elts = [], first = true;\n    while (!this.eat(close)) {\n      if (!first) {\n        this.expect(types.comma);\n        if (allowTrailingComma && this.afterTrailingComma(close)) { break }\n      } else { first = false; }\n\n      var elt = (void 0);\n      if (allowEmpty && this.type === types.comma)\n        { elt = null; }\n      else if (this.type === types.ellipsis) {\n        elt = this.parseSpread(refDestructuringErrors);\n        if (refDestructuringErrors && this.type === types.comma && refDestructuringErrors.trailingComma < 0)\n          { refDestructuringErrors.trailingComma = this.start; }\n      } else {\n        elt = this.parseMaybeAssign(false, refDestructuringErrors);\n      }\n      elts.push(elt);\n    }\n    return elts\n  };\n\n  pp$3.checkUnreserved = function(ref) {\n    var start = ref.start;\n    var end = ref.end;\n    var name = ref.name;\n\n    if (this.inGenerator && name === \"yield\")\n      { this.raiseRecoverable(start, \"Cannot use 'yield' as identifier inside a generator\"); }\n    if (this.inAsync && name === \"await\")\n      { this.raiseRecoverable(start, \"Cannot use 'await' as identifier inside an async function\"); }\n    if (this.keywords.test(name))\n      { this.raise(start, (\"Unexpected keyword '\" + name + \"'\")); }\n    if (this.options.ecmaVersion < 6 &&\n      this.input.slice(start, end).indexOf(\"\\\\\") !== -1) { return }\n    var re = this.strict ? this.reservedWordsStrict : this.reservedWords;\n    if (re.test(name)) {\n      if (!this.inAsync && name === \"await\")\n        { this.raiseRecoverable(start, \"Cannot use keyword 'await' outside an async function\"); }\n      this.raiseRecoverable(start, (\"The keyword '\" + name + \"' is reserved\"));\n    }\n  };\n\n  // Parse the next token as an identifier. If `liberal` is true (used\n  // when parsing properties), it will also convert keywords into\n  // identifiers.\n\n  pp$3.parseIdent = function(liberal, isBinding) {\n    var node = this.startNode();\n    if (this.type === types.name) {\n      node.name = this.value;\n    } else if (this.type.keyword) {\n      node.name = this.type.keyword;\n\n      // To fix https://github.com/acornjs/acorn/issues/575\n      // `class` and `function` keywords push new context into this.context.\n      // But there is no chance to pop the context if the keyword is consumed as an identifier such as a property name.\n      // If the previous token is a dot, this does not apply because the context-managing code already ignored the keyword\n      if ((node.name === \"class\" || node.name === \"function\") &&\n          (this.lastTokEnd !== this.lastTokStart + 1 || this.input.charCodeAt(this.lastTokStart) !== 46)) {\n        this.context.pop();\n      }\n    } else {\n      this.unexpected();\n    }\n    this.next(!!liberal);\n    this.finishNode(node, \"Identifier\");\n    if (!liberal) {\n      this.checkUnreserved(node);\n      if (node.name === \"await\" && !this.awaitIdentPos)\n        { this.awaitIdentPos = node.start; }\n    }\n    return node\n  };\n\n  // Parses yield expression inside generator.\n\n  pp$3.parseYield = function(noIn) {\n    if (!this.yieldPos) { this.yieldPos = this.start; }\n\n    var node = this.startNode();\n    this.next();\n    if (this.type === types.semi || this.canInsertSemicolon() || (this.type !== types.star && !this.type.startsExpr)) {\n      node.delegate = false;\n      node.argument = null;\n    } else {\n      node.delegate = this.eat(types.star);\n      node.argument = this.parseMaybeAssign(noIn);\n    }\n    return this.finishNode(node, \"YieldExpression\")\n  };\n\n  pp$3.parseAwait = function() {\n    if (!this.awaitPos) { this.awaitPos = this.start; }\n\n    var node = this.startNode();\n    this.next();\n    node.argument = this.parseMaybeUnary(null, false);\n    return this.finishNode(node, \"AwaitExpression\")\n  };\n\n  var pp$4 = Parser.prototype;\n\n  // This function is used to raise exceptions on parse errors. It\n  // takes an offset integer (into the current `input`) to indicate\n  // the location of the error, attaches the position to the end\n  // of the error message, and then raises a `SyntaxError` with that\n  // message.\n\n  pp$4.raise = function(pos, message) {\n    var loc = getLineInfo(this.input, pos);\n    message += \" (\" + loc.line + \":\" + loc.column + \")\";\n    var err = new SyntaxError(message);\n    err.pos = pos; err.loc = loc; err.raisedAt = this.pos;\n    throw err\n  };\n\n  pp$4.raiseRecoverable = pp$4.raise;\n\n  pp$4.curPosition = function() {\n    if (this.options.locations) {\n      return new Position(this.curLine, this.pos - this.lineStart)\n    }\n  };\n\n  var pp$5 = Parser.prototype;\n\n  var Scope = function Scope(flags) {\n    this.flags = flags;\n    // A list of var-declared names in the current lexical scope\n    this.var = [];\n    // A list of lexically-declared names in the current lexical scope\n    this.lexical = [];\n    // A list of lexically-declared FunctionDeclaration names in the current lexical scope\n    this.functions = [];\n  };\n\n  // The functions in this module keep track of declared variables in the current scope in order to detect duplicate variable names.\n\n  pp$5.enterScope = function(flags) {\n    this.scopeStack.push(new Scope(flags));\n  };\n\n  pp$5.exitScope = function() {\n    this.scopeStack.pop();\n  };\n\n  // The spec says:\n  // > At the top level of a function, or script, function declarations are\n  // > treated like var declarations rather than like lexical declarations.\n  pp$5.treatFunctionsAsVarInScope = function(scope) {\n    return (scope.flags & SCOPE_FUNCTION) || !this.inModule && (scope.flags & SCOPE_TOP)\n  };\n\n  pp$5.declareName = function(name, bindingType, pos) {\n    var redeclared = false;\n    if (bindingType === BIND_LEXICAL) {\n      var scope = this.currentScope();\n      redeclared = scope.lexical.indexOf(name) > -1 || scope.functions.indexOf(name) > -1 || scope.var.indexOf(name) > -1;\n      scope.lexical.push(name);\n      if (this.inModule && (scope.flags & SCOPE_TOP))\n        { delete this.undefinedExports[name]; }\n    } else if (bindingType === BIND_SIMPLE_CATCH) {\n      var scope$1 = this.currentScope();\n      scope$1.lexical.push(name);\n    } else if (bindingType === BIND_FUNCTION) {\n      var scope$2 = this.currentScope();\n      if (this.treatFunctionsAsVar)\n        { redeclared = scope$2.lexical.indexOf(name) > -1; }\n      else\n        { redeclared = scope$2.lexical.indexOf(name) > -1 || scope$2.var.indexOf(name) > -1; }\n      scope$2.functions.push(name);\n    } else {\n      for (var i = this.scopeStack.length - 1; i >= 0; --i) {\n        var scope$3 = this.scopeStack[i];\n        if (scope$3.lexical.indexOf(name) > -1 && !((scope$3.flags & SCOPE_SIMPLE_CATCH) && scope$3.lexical[0] === name) ||\n            !this.treatFunctionsAsVarInScope(scope$3) && scope$3.functions.indexOf(name) > -1) {\n          redeclared = true;\n          break\n        }\n        scope$3.var.push(name);\n        if (this.inModule && (scope$3.flags & SCOPE_TOP))\n          { delete this.undefinedExports[name]; }\n        if (scope$3.flags & SCOPE_VAR) { break }\n      }\n    }\n    if (redeclared) { this.raiseRecoverable(pos, (\"Identifier '\" + name + \"' has already been declared\")); }\n  };\n\n  pp$5.checkLocalExport = function(id) {\n    // scope.functions must be empty as Module code is always strict.\n    if (this.scopeStack[0].lexical.indexOf(id.name) === -1 &&\n        this.scopeStack[0].var.indexOf(id.name) === -1) {\n      this.undefinedExports[id.name] = id;\n    }\n  };\n\n  pp$5.currentScope = function() {\n    return this.scopeStack[this.scopeStack.length - 1]\n  };\n\n  pp$5.currentVarScope = function() {\n    for (var i = this.scopeStack.length - 1;; i--) {\n      var scope = this.scopeStack[i];\n      if (scope.flags & SCOPE_VAR) { return scope }\n    }\n  };\n\n  // Could be useful for `this`, `new.target`, `super()`, `super.property`, and `super[property]`.\n  pp$5.currentThisScope = function() {\n    for (var i = this.scopeStack.length - 1;; i--) {\n      var scope = this.scopeStack[i];\n      if (scope.flags & SCOPE_VAR && !(scope.flags & SCOPE_ARROW)) { return scope }\n    }\n  };\n\n  var Node = function Node(parser, pos, loc) {\n    this.type = \"\";\n    this.start = pos;\n    this.end = 0;\n    if (parser.options.locations)\n      { this.loc = new SourceLocation(parser, loc); }\n    if (parser.options.directSourceFile)\n      { this.sourceFile = parser.options.directSourceFile; }\n    if (parser.options.ranges)\n      { this.range = [pos, 0]; }\n  };\n\n  // Start an AST node, attaching a start offset.\n\n  var pp$6 = Parser.prototype;\n\n  pp$6.startNode = function() {\n    return new Node(this, this.start, this.startLoc)\n  };\n\n  pp$6.startNodeAt = function(pos, loc) {\n    return new Node(this, pos, loc)\n  };\n\n  // Finish an AST node, adding `type` and `end` properties.\n\n  function finishNodeAt(node, type, pos, loc) {\n    node.type = type;\n    node.end = pos;\n    if (this.options.locations)\n      { node.loc.end = loc; }\n    if (this.options.ranges)\n      { node.range[1] = pos; }\n    return node\n  }\n\n  pp$6.finishNode = function(node, type) {\n    return finishNodeAt.call(this, node, type, this.lastTokEnd, this.lastTokEndLoc)\n  };\n\n  // Finish node at given position\n\n  pp$6.finishNodeAt = function(node, type, pos, loc) {\n    return finishNodeAt.call(this, node, type, pos, loc)\n  };\n\n  // The algorithm used to determine whether a regexp can appear at a\n\n  var TokContext = function TokContext(token, isExpr, preserveSpace, override, generator) {\n    this.token = token;\n    this.isExpr = !!isExpr;\n    this.preserveSpace = !!preserveSpace;\n    this.override = override;\n    this.generator = !!generator;\n  };\n\n  var types$1 = {\n    b_stat: new TokContext(\"{\", false),\n    b_expr: new TokContext(\"{\", true),\n    b_tmpl: new TokContext(\"${\", false),\n    p_stat: new TokContext(\"(\", false),\n    p_expr: new TokContext(\"(\", true),\n    q_tmpl: new TokContext(\"`\", true, true, function (p) { return p.tryReadTemplateToken(); }),\n    f_stat: new TokContext(\"function\", false),\n    f_expr: new TokContext(\"function\", true),\n    f_expr_gen: new TokContext(\"function\", true, false, null, true),\n    f_gen: new TokContext(\"function\", false, false, null, true)\n  };\n\n  var pp$7 = Parser.prototype;\n\n  pp$7.initialContext = function() {\n    return [types$1.b_stat]\n  };\n\n  pp$7.braceIsBlock = function(prevType) {\n    var parent = this.curContext();\n    if (parent === types$1.f_expr || parent === types$1.f_stat)\n      { return true }\n    if (prevType === types.colon && (parent === types$1.b_stat || parent === types$1.b_expr))\n      { return !parent.isExpr }\n\n    // The check for `tt.name && exprAllowed` detects whether we are\n    // after a `yield` or `of` construct. See the `updateContext` for\n    // `tt.name`.\n    if (prevType === types._return || prevType === types.name && this.exprAllowed)\n      { return lineBreak.test(this.input.slice(this.lastTokEnd, this.start)) }\n    if (prevType === types._else || prevType === types.semi || prevType === types.eof || prevType === types.parenR || prevType === types.arrow)\n      { return true }\n    if (prevType === types.braceL)\n      { return parent === types$1.b_stat }\n    if (prevType === types._var || prevType === types._const || prevType === types.name)\n      { return false }\n    return !this.exprAllowed\n  };\n\n  pp$7.inGeneratorContext = function() {\n    for (var i = this.context.length - 1; i >= 1; i--) {\n      var context = this.context[i];\n      if (context.token === \"function\")\n        { return context.generator }\n    }\n    return false\n  };\n\n  pp$7.updateContext = function(prevType) {\n    var update, type = this.type;\n    if (type.keyword && prevType === types.dot)\n      { this.exprAllowed = false; }\n    else if (update = type.updateContext)\n      { update.call(this, prevType); }\n    else\n      { this.exprAllowed = type.beforeExpr; }\n  };\n\n  // Token-specific context update code\n\n  types.parenR.updateContext = types.braceR.updateContext = function() {\n    if (this.context.length === 1) {\n      this.exprAllowed = true;\n      return\n    }\n    var out = this.context.pop();\n    if (out === types$1.b_stat && this.curContext().token === \"function\") {\n      out = this.context.pop();\n    }\n    this.exprAllowed = !out.isExpr;\n  };\n\n  types.braceL.updateContext = function(prevType) {\n    this.context.push(this.braceIsBlock(prevType) ? types$1.b_stat : types$1.b_expr);\n    this.exprAllowed = true;\n  };\n\n  types.dollarBraceL.updateContext = function() {\n    this.context.push(types$1.b_tmpl);\n    this.exprAllowed = true;\n  };\n\n  types.parenL.updateContext = function(prevType) {\n    var statementParens = prevType === types._if || prevType === types._for || prevType === types._with || prevType === types._while;\n    this.context.push(statementParens ? types$1.p_stat : types$1.p_expr);\n    this.exprAllowed = true;\n  };\n\n  types.incDec.updateContext = function() {\n    // tokExprAllowed stays unchanged\n  };\n\n  types._function.updateContext = types._class.updateContext = function(prevType) {\n    if (prevType.beforeExpr && prevType !== types.semi && prevType !== types._else &&\n        !(prevType === types._return && lineBreak.test(this.input.slice(this.lastTokEnd, this.start))) &&\n        !((prevType === types.colon || prevType === types.braceL) && this.curContext() === types$1.b_stat))\n      { this.context.push(types$1.f_expr); }\n    else\n      { this.context.push(types$1.f_stat); }\n    this.exprAllowed = false;\n  };\n\n  types.backQuote.updateContext = function() {\n    if (this.curContext() === types$1.q_tmpl)\n      { this.context.pop(); }\n    else\n      { this.context.push(types$1.q_tmpl); }\n    this.exprAllowed = false;\n  };\n\n  types.star.updateContext = function(prevType) {\n    if (prevType === types._function) {\n      var index = this.context.length - 1;\n      if (this.context[index] === types$1.f_expr)\n        { this.context[index] = types$1.f_expr_gen; }\n      else\n        { this.context[index] = types$1.f_gen; }\n    }\n    this.exprAllowed = true;\n  };\n\n  types.name.updateContext = function(prevType) {\n    var allowed = false;\n    if (this.options.ecmaVersion >= 6 && prevType !== types.dot) {\n      if (this.value === \"of\" && !this.exprAllowed ||\n          this.value === \"yield\" && this.inGeneratorContext())\n        { allowed = true; }\n    }\n    this.exprAllowed = allowed;\n  };\n\n  // This file contains Unicode properties extracted from the ECMAScript\n  // specification. The lists are extracted like so:\n  // $$('#table-binary-unicode-properties > figure > table > tbody > tr > td:nth-child(1) code').map(el => el.innerText)\n\n  // #table-binary-unicode-properties\n  var ecma9BinaryProperties = \"ASCII ASCII_Hex_Digit AHex Alphabetic Alpha Any Assigned Bidi_Control Bidi_C Bidi_Mirrored Bidi_M Case_Ignorable CI Cased Changes_When_Casefolded CWCF Changes_When_Casemapped CWCM Changes_When_Lowercased CWL Changes_When_NFKC_Casefolded CWKCF Changes_When_Titlecased CWT Changes_When_Uppercased CWU Dash Default_Ignorable_Code_Point DI Deprecated Dep Diacritic Dia Emoji Emoji_Component Emoji_Modifier Emoji_Modifier_Base Emoji_Presentation Extender Ext Grapheme_Base Gr_Base Grapheme_Extend Gr_Ext Hex_Digit Hex IDS_Binary_Operator IDSB IDS_Trinary_Operator IDST ID_Continue IDC ID_Start IDS Ideographic Ideo Join_Control Join_C Logical_Order_Exception LOE Lowercase Lower Math Noncharacter_Code_Point NChar Pattern_Syntax Pat_Syn Pattern_White_Space Pat_WS Quotation_Mark QMark Radical Regional_Indicator RI Sentence_Terminal STerm Soft_Dotted SD Terminal_Punctuation Term Unified_Ideograph UIdeo Uppercase Upper Variation_Selector VS White_Space space XID_Continue XIDC XID_Start XIDS\";\n  var ecma10BinaryProperties = ecma9BinaryProperties + \" Extended_Pictographic\";\n  var ecma11BinaryProperties = ecma10BinaryProperties;\n  var unicodeBinaryProperties = {\n    9: ecma9BinaryProperties,\n    10: ecma10BinaryProperties,\n    11: ecma11BinaryProperties\n  };\n\n  // #table-unicode-general-category-values\n  var unicodeGeneralCategoryValues = \"Cased_Letter LC Close_Punctuation Pe Connector_Punctuation Pc Control Cc cntrl Currency_Symbol Sc Dash_Punctuation Pd Decimal_Number Nd digit Enclosing_Mark Me Final_Punctuation Pf Format Cf Initial_Punctuation Pi Letter L Letter_Number Nl Line_Separator Zl Lowercase_Letter Ll Mark M Combining_Mark Math_Symbol Sm Modifier_Letter Lm Modifier_Symbol Sk Nonspacing_Mark Mn Number N Open_Punctuation Ps Other C Other_Letter Lo Other_Number No Other_Punctuation Po Other_Symbol So Paragraph_Separator Zp Private_Use Co Punctuation P punct Separator Z Space_Separator Zs Spacing_Mark Mc Surrogate Cs Symbol S Titlecase_Letter Lt Unassigned Cn Uppercase_Letter Lu\";\n\n  // #table-unicode-script-values\n  var ecma9ScriptValues = \"Adlam Adlm Ahom Ahom Anatolian_Hieroglyphs Hluw Arabic Arab Armenian Armn Avestan Avst Balinese Bali Bamum Bamu Bassa_Vah Bass Batak Batk Bengali Beng Bhaiksuki Bhks Bopomofo Bopo Brahmi Brah Braille Brai Buginese Bugi Buhid Buhd Canadian_Aboriginal Cans Carian Cari Caucasian_Albanian Aghb Chakma Cakm Cham Cham Cherokee Cher Common Zyyy Coptic Copt Qaac Cuneiform Xsux Cypriot Cprt Cyrillic Cyrl Deseret Dsrt Devanagari Deva Duployan Dupl Egyptian_Hieroglyphs Egyp Elbasan Elba Ethiopic Ethi Georgian Geor Glagolitic Glag Gothic Goth Grantha Gran Greek Grek Gujarati Gujr Gurmukhi Guru Han Hani Hangul Hang Hanunoo Hano Hatran Hatr Hebrew Hebr Hiragana Hira Imperial_Aramaic Armi Inherited Zinh Qaai Inscriptional_Pahlavi Phli Inscriptional_Parthian Prti Javanese Java Kaithi Kthi Kannada Knda Katakana Kana Kayah_Li Kali Kharoshthi Khar Khmer Khmr Khojki Khoj Khudawadi Sind Lao Laoo Latin Latn Lepcha Lepc Limbu Limb Linear_A Lina Linear_B Linb Lisu Lisu Lycian Lyci Lydian Lydi Mahajani Mahj Malayalam Mlym Mandaic Mand Manichaean Mani Marchen Marc Masaram_Gondi Gonm Meetei_Mayek Mtei Mende_Kikakui Mend Meroitic_Cursive Merc Meroitic_Hieroglyphs Mero Miao Plrd Modi Modi Mongolian Mong Mro Mroo Multani Mult Myanmar Mymr Nabataean Nbat New_Tai_Lue Talu Newa Newa Nko Nkoo Nushu Nshu Ogham Ogam Ol_Chiki Olck Old_Hungarian Hung Old_Italic Ital Old_North_Arabian Narb Old_Permic Perm Old_Persian Xpeo Old_South_Arabian Sarb Old_Turkic Orkh Oriya Orya Osage Osge Osmanya Osma Pahawh_Hmong Hmng Palmyrene Palm Pau_Cin_Hau Pauc Phags_Pa Phag Phoenician Phnx Psalter_Pahlavi Phlp Rejang Rjng Runic Runr Samaritan Samr Saurashtra Saur Sharada Shrd Shavian Shaw Siddham Sidd SignWriting Sgnw Sinhala Sinh Sora_Sompeng Sora Soyombo Soyo Sundanese Sund Syloti_Nagri Sylo Syriac Syrc Tagalog Tglg Tagbanwa Tagb Tai_Le Tale Tai_Tham Lana Tai_Viet Tavt Takri Takr Tamil Taml Tangut Tang Telugu Telu Thaana Thaa Thai Thai Tibetan Tibt Tifinagh Tfng Tirhuta Tirh Ugaritic Ugar Vai Vaii Warang_Citi Wara Yi Yiii Zanabazar_Square Zanb\";\n  var ecma10ScriptValues = ecma9ScriptValues + \" Dogra Dogr Gunjala_Gondi Gong Hanifi_Rohingya Rohg Makasar Maka Medefaidrin Medf Old_Sogdian Sogo Sogdian Sogd\";\n  var ecma11ScriptValues = ecma10ScriptValues + \" Elymaic Elym Nandinagari Nand Nyiakeng_Puachue_Hmong Hmnp Wancho Wcho\";\n  var unicodeScriptValues = {\n    9: ecma9ScriptValues,\n    10: ecma10ScriptValues,\n    11: ecma11ScriptValues\n  };\n\n  var data = {};\n  function buildUnicodeData(ecmaVersion) {\n    var d = data[ecmaVersion] = {\n      binary: wordsRegexp(unicodeBinaryProperties[ecmaVersion] + \" \" + unicodeGeneralCategoryValues),\n      nonBinary: {\n        General_Category: wordsRegexp(unicodeGeneralCategoryValues),\n        Script: wordsRegexp(unicodeScriptValues[ecmaVersion])\n      }\n    };\n    d.nonBinary.Script_Extensions = d.nonBinary.Script;\n\n    d.nonBinary.gc = d.nonBinary.General_Category;\n    d.nonBinary.sc = d.nonBinary.Script;\n    d.nonBinary.scx = d.nonBinary.Script_Extensions;\n  }\n  buildUnicodeData(9);\n  buildUnicodeData(10);\n  buildUnicodeData(11);\n\n  var pp$8 = Parser.prototype;\n\n  var RegExpValidationState = function RegExpValidationState(parser) {\n    this.parser = parser;\n    this.validFlags = \"gim\" + (parser.options.ecmaVersion >= 6 ? \"uy\" : \"\") + (parser.options.ecmaVersion >= 9 ? \"s\" : \"\");\n    this.unicodeProperties = data[parser.options.ecmaVersion >= 11 ? 11 : parser.options.ecmaVersion];\n    this.source = \"\";\n    this.flags = \"\";\n    this.start = 0;\n    this.switchU = false;\n    this.switchN = false;\n    this.pos = 0;\n    this.lastIntValue = 0;\n    this.lastStringValue = \"\";\n    this.lastAssertionIsQuantifiable = false;\n    this.numCapturingParens = 0;\n    this.maxBackReference = 0;\n    this.groupNames = [];\n    this.backReferenceNames = [];\n  };\n\n  RegExpValidationState.prototype.reset = function reset (start, pattern, flags) {\n    var unicode = flags.indexOf(\"u\") !== -1;\n    this.start = start | 0;\n    this.source = pattern + \"\";\n    this.flags = flags;\n    this.switchU = unicode && this.parser.options.ecmaVersion >= 6;\n    this.switchN = unicode && this.parser.options.ecmaVersion >= 9;\n  };\n\n  RegExpValidationState.prototype.raise = function raise (message) {\n    this.parser.raiseRecoverable(this.start, (\"Invalid regular expression: /\" + (this.source) + \"/: \" + message));\n  };\n\n  // If u flag is given, this returns the code point at the index (it combines a surrogate pair).\n  // Otherwise, this returns the code unit of the index (can be a part of a surrogate pair).\n  RegExpValidationState.prototype.at = function at (i, forceU) {\n      if ( forceU === void 0 ) forceU = false;\n\n    var s = this.source;\n    var l = s.length;\n    if (i >= l) {\n      return -1\n    }\n    var c = s.charCodeAt(i);\n    if (!(forceU || this.switchU) || c <= 0xD7FF || c >= 0xE000 || i + 1 >= l) {\n      return c\n    }\n    var next = s.charCodeAt(i + 1);\n    return next >= 0xDC00 && next <= 0xDFFF ? (c << 10) + next - 0x35FDC00 : c\n  };\n\n  RegExpValidationState.prototype.nextIndex = function nextIndex (i, forceU) {\n      if ( forceU === void 0 ) forceU = false;\n\n    var s = this.source;\n    var l = s.length;\n    if (i >= l) {\n      return l\n    }\n    var c = s.charCodeAt(i), next;\n    if (!(forceU || this.switchU) || c <= 0xD7FF || c >= 0xE000 || i + 1 >= l ||\n        (next = s.charCodeAt(i + 1)) < 0xDC00 || next > 0xDFFF) {\n      return i + 1\n    }\n    return i + 2\n  };\n\n  RegExpValidationState.prototype.current = function current (forceU) {\n      if ( forceU === void 0 ) forceU = false;\n\n    return this.at(this.pos, forceU)\n  };\n\n  RegExpValidationState.prototype.lookahead = function lookahead (forceU) {\n      if ( forceU === void 0 ) forceU = false;\n\n    return this.at(this.nextIndex(this.pos, forceU), forceU)\n  };\n\n  RegExpValidationState.prototype.advance = function advance (forceU) {\n      if ( forceU === void 0 ) forceU = false;\n\n    this.pos = this.nextIndex(this.pos, forceU);\n  };\n\n  RegExpValidationState.prototype.eat = function eat (ch, forceU) {\n      if ( forceU === void 0 ) forceU = false;\n\n    if (this.current(forceU) === ch) {\n      this.advance(forceU);\n      return true\n    }\n    return false\n  };\n\n  function codePointToString(ch) {\n    if (ch <= 0xFFFF) { return String.fromCharCode(ch) }\n    ch -= 0x10000;\n    return String.fromCharCode((ch >> 10) + 0xD800, (ch & 0x03FF) + 0xDC00)\n  }\n\n  /**\n   * Validate the flags part of a given RegExpLiteral.\n   *\n   * @param {RegExpValidationState} state The state to validate RegExp.\n   * @returns {void}\n   */\n  pp$8.validateRegExpFlags = function(state) {\n    var validFlags = state.validFlags;\n    var flags = state.flags;\n\n    for (var i = 0; i < flags.length; i++) {\n      var flag = flags.charAt(i);\n      if (validFlags.indexOf(flag) === -1) {\n        this.raise(state.start, \"Invalid regular expression flag\");\n      }\n      if (flags.indexOf(flag, i + 1) > -1) {\n        this.raise(state.start, \"Duplicate regular expression flag\");\n      }\n    }\n  };\n\n  /**\n   * Validate the pattern part of a given RegExpLiteral.\n   *\n   * @param {RegExpValidationState} state The state to validate RegExp.\n   * @returns {void}\n   */\n  pp$8.validateRegExpPattern = function(state) {\n    this.regexp_pattern(state);\n\n    // The goal symbol for the parse is |Pattern[~U, ~N]|. If the result of\n    // parsing contains a |GroupName|, reparse with the goal symbol\n    // |Pattern[~U, +N]| and use this result instead. Throw a *SyntaxError*\n    // exception if _P_ did not conform to the grammar, if any elements of _P_\n    // were not matched by the parse, or if any Early Error conditions exist.\n    if (!state.switchN && this.options.ecmaVersion >= 9 && state.groupNames.length > 0) {\n      state.switchN = true;\n      this.regexp_pattern(state);\n    }\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-Pattern\n  pp$8.regexp_pattern = function(state) {\n    state.pos = 0;\n    state.lastIntValue = 0;\n    state.lastStringValue = \"\";\n    state.lastAssertionIsQuantifiable = false;\n    state.numCapturingParens = 0;\n    state.maxBackReference = 0;\n    state.groupNames.length = 0;\n    state.backReferenceNames.length = 0;\n\n    this.regexp_disjunction(state);\n\n    if (state.pos !== state.source.length) {\n      // Make the same messages as V8.\n      if (state.eat(0x29 /* ) */)) {\n        state.raise(\"Unmatched ')'\");\n      }\n      if (state.eat(0x5D /* ] */) || state.eat(0x7D /* } */)) {\n        state.raise(\"Lone quantifier brackets\");\n      }\n    }\n    if (state.maxBackReference > state.numCapturingParens) {\n      state.raise(\"Invalid escape\");\n    }\n    for (var i = 0, list = state.backReferenceNames; i < list.length; i += 1) {\n      var name = list[i];\n\n      if (state.groupNames.indexOf(name) === -1) {\n        state.raise(\"Invalid named capture referenced\");\n      }\n    }\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-Disjunction\n  pp$8.regexp_disjunction = function(state) {\n    this.regexp_alternative(state);\n    while (state.eat(0x7C /* | */)) {\n      this.regexp_alternative(state);\n    }\n\n    // Make the same message as V8.\n    if (this.regexp_eatQuantifier(state, true)) {\n      state.raise(\"Nothing to repeat\");\n    }\n    if (state.eat(0x7B /* { */)) {\n      state.raise(\"Lone quantifier brackets\");\n    }\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-Alternative\n  pp$8.regexp_alternative = function(state) {\n    while (state.pos < state.source.length && this.regexp_eatTerm(state))\n      { }\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-Term\n  pp$8.regexp_eatTerm = function(state) {\n    if (this.regexp_eatAssertion(state)) {\n      // Handle `QuantifiableAssertion Quantifier` alternative.\n      // `state.lastAssertionIsQuantifiable` is true if the last eaten Assertion\n      // is a QuantifiableAssertion.\n      if (state.lastAssertionIsQuantifiable && this.regexp_eatQuantifier(state)) {\n        // Make the same message as V8.\n        if (state.switchU) {\n          state.raise(\"Invalid quantifier\");\n        }\n      }\n      return true\n    }\n\n    if (state.switchU ? this.regexp_eatAtom(state) : this.regexp_eatExtendedAtom(state)) {\n      this.regexp_eatQuantifier(state);\n      return true\n    }\n\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-Assertion\n  pp$8.regexp_eatAssertion = function(state) {\n    var start = state.pos;\n    state.lastAssertionIsQuantifiable = false;\n\n    // ^, $\n    if (state.eat(0x5E /* ^ */) || state.eat(0x24 /* $ */)) {\n      return true\n    }\n\n    // \\b \\B\n    if (state.eat(0x5C /* \\ */)) {\n      if (state.eat(0x42 /* B */) || state.eat(0x62 /* b */)) {\n        return true\n      }\n      state.pos = start;\n    }\n\n    // Lookahead / Lookbehind\n    if (state.eat(0x28 /* ( */) && state.eat(0x3F /* ? */)) {\n      var lookbehind = false;\n      if (this.options.ecmaVersion >= 9) {\n        lookbehind = state.eat(0x3C /* < */);\n      }\n      if (state.eat(0x3D /* = */) || state.eat(0x21 /* ! */)) {\n        this.regexp_disjunction(state);\n        if (!state.eat(0x29 /* ) */)) {\n          state.raise(\"Unterminated group\");\n        }\n        state.lastAssertionIsQuantifiable = !lookbehind;\n        return true\n      }\n    }\n\n    state.pos = start;\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-Quantifier\n  pp$8.regexp_eatQuantifier = function(state, noError) {\n    if ( noError === void 0 ) noError = false;\n\n    if (this.regexp_eatQuantifierPrefix(state, noError)) {\n      state.eat(0x3F /* ? */);\n      return true\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-QuantifierPrefix\n  pp$8.regexp_eatQuantifierPrefix = function(state, noError) {\n    return (\n      state.eat(0x2A /* * */) ||\n      state.eat(0x2B /* + */) ||\n      state.eat(0x3F /* ? */) ||\n      this.regexp_eatBracedQuantifier(state, noError)\n    )\n  };\n  pp$8.regexp_eatBracedQuantifier = function(state, noError) {\n    var start = state.pos;\n    if (state.eat(0x7B /* { */)) {\n      var min = 0, max = -1;\n      if (this.regexp_eatDecimalDigits(state)) {\n        min = state.lastIntValue;\n        if (state.eat(0x2C /* , */) && this.regexp_eatDecimalDigits(state)) {\n          max = state.lastIntValue;\n        }\n        if (state.eat(0x7D /* } */)) {\n          // SyntaxError in https://www.ecma-international.org/ecma-262/8.0/#sec-term\n          if (max !== -1 && max < min && !noError) {\n            state.raise(\"numbers out of order in {} quantifier\");\n          }\n          return true\n        }\n      }\n      if (state.switchU && !noError) {\n        state.raise(\"Incomplete quantifier\");\n      }\n      state.pos = start;\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-Atom\n  pp$8.regexp_eatAtom = function(state) {\n    return (\n      this.regexp_eatPatternCharacters(state) ||\n      state.eat(0x2E /* . */) ||\n      this.regexp_eatReverseSolidusAtomEscape(state) ||\n      this.regexp_eatCharacterClass(state) ||\n      this.regexp_eatUncapturingGroup(state) ||\n      this.regexp_eatCapturingGroup(state)\n    )\n  };\n  pp$8.regexp_eatReverseSolidusAtomEscape = function(state) {\n    var start = state.pos;\n    if (state.eat(0x5C /* \\ */)) {\n      if (this.regexp_eatAtomEscape(state)) {\n        return true\n      }\n      state.pos = start;\n    }\n    return false\n  };\n  pp$8.regexp_eatUncapturingGroup = function(state) {\n    var start = state.pos;\n    if (state.eat(0x28 /* ( */)) {\n      if (state.eat(0x3F /* ? */) && state.eat(0x3A /* : */)) {\n        this.regexp_disjunction(state);\n        if (state.eat(0x29 /* ) */)) {\n          return true\n        }\n        state.raise(\"Unterminated group\");\n      }\n      state.pos = start;\n    }\n    return false\n  };\n  pp$8.regexp_eatCapturingGroup = function(state) {\n    if (state.eat(0x28 /* ( */)) {\n      if (this.options.ecmaVersion >= 9) {\n        this.regexp_groupSpecifier(state);\n      } else if (state.current() === 0x3F /* ? */) {\n        state.raise(\"Invalid group\");\n      }\n      this.regexp_disjunction(state);\n      if (state.eat(0x29 /* ) */)) {\n        state.numCapturingParens += 1;\n        return true\n      }\n      state.raise(\"Unterminated group\");\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-ExtendedAtom\n  pp$8.regexp_eatExtendedAtom = function(state) {\n    return (\n      state.eat(0x2E /* . */) ||\n      this.regexp_eatReverseSolidusAtomEscape(state) ||\n      this.regexp_eatCharacterClass(state) ||\n      this.regexp_eatUncapturingGroup(state) ||\n      this.regexp_eatCapturingGroup(state) ||\n      this.regexp_eatInvalidBracedQuantifier(state) ||\n      this.regexp_eatExtendedPatternCharacter(state)\n    )\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-InvalidBracedQuantifier\n  pp$8.regexp_eatInvalidBracedQuantifier = function(state) {\n    if (this.regexp_eatBracedQuantifier(state, true)) {\n      state.raise(\"Nothing to repeat\");\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-SyntaxCharacter\n  pp$8.regexp_eatSyntaxCharacter = function(state) {\n    var ch = state.current();\n    if (isSyntaxCharacter(ch)) {\n      state.lastIntValue = ch;\n      state.advance();\n      return true\n    }\n    return false\n  };\n  function isSyntaxCharacter(ch) {\n    return (\n      ch === 0x24 /* $ */ ||\n      ch >= 0x28 /* ( */ && ch <= 0x2B /* + */ ||\n      ch === 0x2E /* . */ ||\n      ch === 0x3F /* ? */ ||\n      ch >= 0x5B /* [ */ && ch <= 0x5E /* ^ */ ||\n      ch >= 0x7B /* { */ && ch <= 0x7D /* } */\n    )\n  }\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-PatternCharacter\n  // But eat eager.\n  pp$8.regexp_eatPatternCharacters = function(state) {\n    var start = state.pos;\n    var ch = 0;\n    while ((ch = state.current()) !== -1 && !isSyntaxCharacter(ch)) {\n      state.advance();\n    }\n    return state.pos !== start\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-ExtendedPatternCharacter\n  pp$8.regexp_eatExtendedPatternCharacter = function(state) {\n    var ch = state.current();\n    if (\n      ch !== -1 &&\n      ch !== 0x24 /* $ */ &&\n      !(ch >= 0x28 /* ( */ && ch <= 0x2B /* + */) &&\n      ch !== 0x2E /* . */ &&\n      ch !== 0x3F /* ? */ &&\n      ch !== 0x5B /* [ */ &&\n      ch !== 0x5E /* ^ */ &&\n      ch !== 0x7C /* | */\n    ) {\n      state.advance();\n      return true\n    }\n    return false\n  };\n\n  // GroupSpecifier ::\n  //   [empty]\n  //   `?` GroupName\n  pp$8.regexp_groupSpecifier = function(state) {\n    if (state.eat(0x3F /* ? */)) {\n      if (this.regexp_eatGroupName(state)) {\n        if (state.groupNames.indexOf(state.lastStringValue) !== -1) {\n          state.raise(\"Duplicate capture group name\");\n        }\n        state.groupNames.push(state.lastStringValue);\n        return\n      }\n      state.raise(\"Invalid group\");\n    }\n  };\n\n  // GroupName ::\n  //   `<` RegExpIdentifierName `>`\n  // Note: this updates `state.lastStringValue` property with the eaten name.\n  pp$8.regexp_eatGroupName = function(state) {\n    state.lastStringValue = \"\";\n    if (state.eat(0x3C /* < */)) {\n      if (this.regexp_eatRegExpIdentifierName(state) && state.eat(0x3E /* > */)) {\n        return true\n      }\n      state.raise(\"Invalid capture group name\");\n    }\n    return false\n  };\n\n  // RegExpIdentifierName ::\n  //   RegExpIdentifierStart\n  //   RegExpIdentifierName RegExpIdentifierPart\n  // Note: this updates `state.lastStringValue` property with the eaten name.\n  pp$8.regexp_eatRegExpIdentifierName = function(state) {\n    state.lastStringValue = \"\";\n    if (this.regexp_eatRegExpIdentifierStart(state)) {\n      state.lastStringValue += codePointToString(state.lastIntValue);\n      while (this.regexp_eatRegExpIdentifierPart(state)) {\n        state.lastStringValue += codePointToString(state.lastIntValue);\n      }\n      return true\n    }\n    return false\n  };\n\n  // RegExpIdentifierStart ::\n  //   UnicodeIDStart\n  //   `$`\n  //   `_`\n  //   `\\` RegExpUnicodeEscapeSequence[+U]\n  pp$8.regexp_eatRegExpIdentifierStart = function(state) {\n    var start = state.pos;\n    var forceU = this.options.ecmaVersion >= 11;\n    var ch = state.current(forceU);\n    state.advance(forceU);\n\n    if (ch === 0x5C /* \\ */ && this.regexp_eatRegExpUnicodeEscapeSequence(state, forceU)) {\n      ch = state.lastIntValue;\n    }\n    if (isRegExpIdentifierStart(ch)) {\n      state.lastIntValue = ch;\n      return true\n    }\n\n    state.pos = start;\n    return false\n  };\n  function isRegExpIdentifierStart(ch) {\n    return isIdentifierStart(ch, true) || ch === 0x24 /* $ */ || ch === 0x5F /* _ */\n  }\n\n  // RegExpIdentifierPart ::\n  //   UnicodeIDContinue\n  //   `$`\n  //   `_`\n  //   `\\` RegExpUnicodeEscapeSequence[+U]\n  //   <ZWNJ>\n  //   <ZWJ>\n  pp$8.regexp_eatRegExpIdentifierPart = function(state) {\n    var start = state.pos;\n    var forceU = this.options.ecmaVersion >= 11;\n    var ch = state.current(forceU);\n    state.advance(forceU);\n\n    if (ch === 0x5C /* \\ */ && this.regexp_eatRegExpUnicodeEscapeSequence(state, forceU)) {\n      ch = state.lastIntValue;\n    }\n    if (isRegExpIdentifierPart(ch)) {\n      state.lastIntValue = ch;\n      return true\n    }\n\n    state.pos = start;\n    return false\n  };\n  function isRegExpIdentifierPart(ch) {\n    return isIdentifierChar(ch, true) || ch === 0x24 /* $ */ || ch === 0x5F /* _ */ || ch === 0x200C /* <ZWNJ> */ || ch === 0x200D /* <ZWJ> */\n  }\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-AtomEscape\n  pp$8.regexp_eatAtomEscape = function(state) {\n    if (\n      this.regexp_eatBackReference(state) ||\n      this.regexp_eatCharacterClassEscape(state) ||\n      this.regexp_eatCharacterEscape(state) ||\n      (state.switchN && this.regexp_eatKGroupName(state))\n    ) {\n      return true\n    }\n    if (state.switchU) {\n      // Make the same message as V8.\n      if (state.current() === 0x63 /* c */) {\n        state.raise(\"Invalid unicode escape\");\n      }\n      state.raise(\"Invalid escape\");\n    }\n    return false\n  };\n  pp$8.regexp_eatBackReference = function(state) {\n    var start = state.pos;\n    if (this.regexp_eatDecimalEscape(state)) {\n      var n = state.lastIntValue;\n      if (state.switchU) {\n        // For SyntaxError in https://www.ecma-international.org/ecma-262/8.0/#sec-atomescape\n        if (n > state.maxBackReference) {\n          state.maxBackReference = n;\n        }\n        return true\n      }\n      if (n <= state.numCapturingParens) {\n        return true\n      }\n      state.pos = start;\n    }\n    return false\n  };\n  pp$8.regexp_eatKGroupName = function(state) {\n    if (state.eat(0x6B /* k */)) {\n      if (this.regexp_eatGroupName(state)) {\n        state.backReferenceNames.push(state.lastStringValue);\n        return true\n      }\n      state.raise(\"Invalid named reference\");\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-CharacterEscape\n  pp$8.regexp_eatCharacterEscape = function(state) {\n    return (\n      this.regexp_eatControlEscape(state) ||\n      this.regexp_eatCControlLetter(state) ||\n      this.regexp_eatZero(state) ||\n      this.regexp_eatHexEscapeSequence(state) ||\n      this.regexp_eatRegExpUnicodeEscapeSequence(state, false) ||\n      (!state.switchU && this.regexp_eatLegacyOctalEscapeSequence(state)) ||\n      this.regexp_eatIdentityEscape(state)\n    )\n  };\n  pp$8.regexp_eatCControlLetter = function(state) {\n    var start = state.pos;\n    if (state.eat(0x63 /* c */)) {\n      if (this.regexp_eatControlLetter(state)) {\n        return true\n      }\n      state.pos = start;\n    }\n    return false\n  };\n  pp$8.regexp_eatZero = function(state) {\n    if (state.current() === 0x30 /* 0 */ && !isDecimalDigit(state.lookahead())) {\n      state.lastIntValue = 0;\n      state.advance();\n      return true\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-ControlEscape\n  pp$8.regexp_eatControlEscape = function(state) {\n    var ch = state.current();\n    if (ch === 0x74 /* t */) {\n      state.lastIntValue = 0x09; /* \\t */\n      state.advance();\n      return true\n    }\n    if (ch === 0x6E /* n */) {\n      state.lastIntValue = 0x0A; /* \\n */\n      state.advance();\n      return true\n    }\n    if (ch === 0x76 /* v */) {\n      state.lastIntValue = 0x0B; /* \\v */\n      state.advance();\n      return true\n    }\n    if (ch === 0x66 /* f */) {\n      state.lastIntValue = 0x0C; /* \\f */\n      state.advance();\n      return true\n    }\n    if (ch === 0x72 /* r */) {\n      state.lastIntValue = 0x0D; /* \\r */\n      state.advance();\n      return true\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-ControlLetter\n  pp$8.regexp_eatControlLetter = function(state) {\n    var ch = state.current();\n    if (isControlLetter(ch)) {\n      state.lastIntValue = ch % 0x20;\n      state.advance();\n      return true\n    }\n    return false\n  };\n  function isControlLetter(ch) {\n    return (\n      (ch >= 0x41 /* A */ && ch <= 0x5A /* Z */) ||\n      (ch >= 0x61 /* a */ && ch <= 0x7A /* z */)\n    )\n  }\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-RegExpUnicodeEscapeSequence\n  pp$8.regexp_eatRegExpUnicodeEscapeSequence = function(state, forceU) {\n    if ( forceU === void 0 ) forceU = false;\n\n    var start = state.pos;\n    var switchU = forceU || state.switchU;\n\n    if (state.eat(0x75 /* u */)) {\n      if (this.regexp_eatFixedHexDigits(state, 4)) {\n        var lead = state.lastIntValue;\n        if (switchU && lead >= 0xD800 && lead <= 0xDBFF) {\n          var leadSurrogateEnd = state.pos;\n          if (state.eat(0x5C /* \\ */) && state.eat(0x75 /* u */) && this.regexp_eatFixedHexDigits(state, 4)) {\n            var trail = state.lastIntValue;\n            if (trail >= 0xDC00 && trail <= 0xDFFF) {\n              state.lastIntValue = (lead - 0xD800) * 0x400 + (trail - 0xDC00) + 0x10000;\n              return true\n            }\n          }\n          state.pos = leadSurrogateEnd;\n          state.lastIntValue = lead;\n        }\n        return true\n      }\n      if (\n        switchU &&\n        state.eat(0x7B /* { */) &&\n        this.regexp_eatHexDigits(state) &&\n        state.eat(0x7D /* } */) &&\n        isValidUnicode(state.lastIntValue)\n      ) {\n        return true\n      }\n      if (switchU) {\n        state.raise(\"Invalid unicode escape\");\n      }\n      state.pos = start;\n    }\n\n    return false\n  };\n  function isValidUnicode(ch) {\n    return ch >= 0 && ch <= 0x10FFFF\n  }\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-IdentityEscape\n  pp$8.regexp_eatIdentityEscape = function(state) {\n    if (state.switchU) {\n      if (this.regexp_eatSyntaxCharacter(state)) {\n        return true\n      }\n      if (state.eat(0x2F /* / */)) {\n        state.lastIntValue = 0x2F; /* / */\n        return true\n      }\n      return false\n    }\n\n    var ch = state.current();\n    if (ch !== 0x63 /* c */ && (!state.switchN || ch !== 0x6B /* k */)) {\n      state.lastIntValue = ch;\n      state.advance();\n      return true\n    }\n\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-DecimalEscape\n  pp$8.regexp_eatDecimalEscape = function(state) {\n    state.lastIntValue = 0;\n    var ch = state.current();\n    if (ch >= 0x31 /* 1 */ && ch <= 0x39 /* 9 */) {\n      do {\n        state.lastIntValue = 10 * state.lastIntValue + (ch - 0x30 /* 0 */);\n        state.advance();\n      } while ((ch = state.current()) >= 0x30 /* 0 */ && ch <= 0x39 /* 9 */)\n      return true\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-CharacterClassEscape\n  pp$8.regexp_eatCharacterClassEscape = function(state) {\n    var ch = state.current();\n\n    if (isCharacterClassEscape(ch)) {\n      state.lastIntValue = -1;\n      state.advance();\n      return true\n    }\n\n    if (\n      state.switchU &&\n      this.options.ecmaVersion >= 9 &&\n      (ch === 0x50 /* P */ || ch === 0x70 /* p */)\n    ) {\n      state.lastIntValue = -1;\n      state.advance();\n      if (\n        state.eat(0x7B /* { */) &&\n        this.regexp_eatUnicodePropertyValueExpression(state) &&\n        state.eat(0x7D /* } */)\n      ) {\n        return true\n      }\n      state.raise(\"Invalid property name\");\n    }\n\n    return false\n  };\n  function isCharacterClassEscape(ch) {\n    return (\n      ch === 0x64 /* d */ ||\n      ch === 0x44 /* D */ ||\n      ch === 0x73 /* s */ ||\n      ch === 0x53 /* S */ ||\n      ch === 0x77 /* w */ ||\n      ch === 0x57 /* W */\n    )\n  }\n\n  // UnicodePropertyValueExpression ::\n  //   UnicodePropertyName `=` UnicodePropertyValue\n  //   LoneUnicodePropertyNameOrValue\n  pp$8.regexp_eatUnicodePropertyValueExpression = function(state) {\n    var start = state.pos;\n\n    // UnicodePropertyName `=` UnicodePropertyValue\n    if (this.regexp_eatUnicodePropertyName(state) && state.eat(0x3D /* = */)) {\n      var name = state.lastStringValue;\n      if (this.regexp_eatUnicodePropertyValue(state)) {\n        var value = state.lastStringValue;\n        this.regexp_validateUnicodePropertyNameAndValue(state, name, value);\n        return true\n      }\n    }\n    state.pos = start;\n\n    // LoneUnicodePropertyNameOrValue\n    if (this.regexp_eatLoneUnicodePropertyNameOrValue(state)) {\n      var nameOrValue = state.lastStringValue;\n      this.regexp_validateUnicodePropertyNameOrValue(state, nameOrValue);\n      return true\n    }\n    return false\n  };\n  pp$8.regexp_validateUnicodePropertyNameAndValue = function(state, name, value) {\n    if (!has(state.unicodeProperties.nonBinary, name))\n      { state.raise(\"Invalid property name\"); }\n    if (!state.unicodeProperties.nonBinary[name].test(value))\n      { state.raise(\"Invalid property value\"); }\n  };\n  pp$8.regexp_validateUnicodePropertyNameOrValue = function(state, nameOrValue) {\n    if (!state.unicodeProperties.binary.test(nameOrValue))\n      { state.raise(\"Invalid property name\"); }\n  };\n\n  // UnicodePropertyName ::\n  //   UnicodePropertyNameCharacters\n  pp$8.regexp_eatUnicodePropertyName = function(state) {\n    var ch = 0;\n    state.lastStringValue = \"\";\n    while (isUnicodePropertyNameCharacter(ch = state.current())) {\n      state.lastStringValue += codePointToString(ch);\n      state.advance();\n    }\n    return state.lastStringValue !== \"\"\n  };\n  function isUnicodePropertyNameCharacter(ch) {\n    return isControlLetter(ch) || ch === 0x5F /* _ */\n  }\n\n  // UnicodePropertyValue ::\n  //   UnicodePropertyValueCharacters\n  pp$8.regexp_eatUnicodePropertyValue = function(state) {\n    var ch = 0;\n    state.lastStringValue = \"\";\n    while (isUnicodePropertyValueCharacter(ch = state.current())) {\n      state.lastStringValue += codePointToString(ch);\n      state.advance();\n    }\n    return state.lastStringValue !== \"\"\n  };\n  function isUnicodePropertyValueCharacter(ch) {\n    return isUnicodePropertyNameCharacter(ch) || isDecimalDigit(ch)\n  }\n\n  // LoneUnicodePropertyNameOrValue ::\n  //   UnicodePropertyValueCharacters\n  pp$8.regexp_eatLoneUnicodePropertyNameOrValue = function(state) {\n    return this.regexp_eatUnicodePropertyValue(state)\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-CharacterClass\n  pp$8.regexp_eatCharacterClass = function(state) {\n    if (state.eat(0x5B /* [ */)) {\n      state.eat(0x5E /* ^ */);\n      this.regexp_classRanges(state);\n      if (state.eat(0x5D /* ] */)) {\n        return true\n      }\n      // Unreachable since it threw \"unterminated regular expression\" error before.\n      state.raise(\"Unterminated character class\");\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-ClassRanges\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-NonemptyClassRanges\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-NonemptyClassRangesNoDash\n  pp$8.regexp_classRanges = function(state) {\n    while (this.regexp_eatClassAtom(state)) {\n      var left = state.lastIntValue;\n      if (state.eat(0x2D /* - */) && this.regexp_eatClassAtom(state)) {\n        var right = state.lastIntValue;\n        if (state.switchU && (left === -1 || right === -1)) {\n          state.raise(\"Invalid character class\");\n        }\n        if (left !== -1 && right !== -1 && left > right) {\n          state.raise(\"Range out of order in character class\");\n        }\n      }\n    }\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-ClassAtom\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-ClassAtomNoDash\n  pp$8.regexp_eatClassAtom = function(state) {\n    var start = state.pos;\n\n    if (state.eat(0x5C /* \\ */)) {\n      if (this.regexp_eatClassEscape(state)) {\n        return true\n      }\n      if (state.switchU) {\n        // Make the same message as V8.\n        var ch$1 = state.current();\n        if (ch$1 === 0x63 /* c */ || isOctalDigit(ch$1)) {\n          state.raise(\"Invalid class escape\");\n        }\n        state.raise(\"Invalid escape\");\n      }\n      state.pos = start;\n    }\n\n    var ch = state.current();\n    if (ch !== 0x5D /* ] */) {\n      state.lastIntValue = ch;\n      state.advance();\n      return true\n    }\n\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-ClassEscape\n  pp$8.regexp_eatClassEscape = function(state) {\n    var start = state.pos;\n\n    if (state.eat(0x62 /* b */)) {\n      state.lastIntValue = 0x08; /* <BS> */\n      return true\n    }\n\n    if (state.switchU && state.eat(0x2D /* - */)) {\n      state.lastIntValue = 0x2D; /* - */\n      return true\n    }\n\n    if (!state.switchU && state.eat(0x63 /* c */)) {\n      if (this.regexp_eatClassControlLetter(state)) {\n        return true\n      }\n      state.pos = start;\n    }\n\n    return (\n      this.regexp_eatCharacterClassEscape(state) ||\n      this.regexp_eatCharacterEscape(state)\n    )\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-ClassControlLetter\n  pp$8.regexp_eatClassControlLetter = function(state) {\n    var ch = state.current();\n    if (isDecimalDigit(ch) || ch === 0x5F /* _ */) {\n      state.lastIntValue = ch % 0x20;\n      state.advance();\n      return true\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-HexEscapeSequence\n  pp$8.regexp_eatHexEscapeSequence = function(state) {\n    var start = state.pos;\n    if (state.eat(0x78 /* x */)) {\n      if (this.regexp_eatFixedHexDigits(state, 2)) {\n        return true\n      }\n      if (state.switchU) {\n        state.raise(\"Invalid escape\");\n      }\n      state.pos = start;\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-DecimalDigits\n  pp$8.regexp_eatDecimalDigits = function(state) {\n    var start = state.pos;\n    var ch = 0;\n    state.lastIntValue = 0;\n    while (isDecimalDigit(ch = state.current())) {\n      state.lastIntValue = 10 * state.lastIntValue + (ch - 0x30 /* 0 */);\n      state.advance();\n    }\n    return state.pos !== start\n  };\n  function isDecimalDigit(ch) {\n    return ch >= 0x30 /* 0 */ && ch <= 0x39 /* 9 */\n  }\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-HexDigits\n  pp$8.regexp_eatHexDigits = function(state) {\n    var start = state.pos;\n    var ch = 0;\n    state.lastIntValue = 0;\n    while (isHexDigit(ch = state.current())) {\n      state.lastIntValue = 16 * state.lastIntValue + hexToInt(ch);\n      state.advance();\n    }\n    return state.pos !== start\n  };\n  function isHexDigit(ch) {\n    return (\n      (ch >= 0x30 /* 0 */ && ch <= 0x39 /* 9 */) ||\n      (ch >= 0x41 /* A */ && ch <= 0x46 /* F */) ||\n      (ch >= 0x61 /* a */ && ch <= 0x66 /* f */)\n    )\n  }\n  function hexToInt(ch) {\n    if (ch >= 0x41 /* A */ && ch <= 0x46 /* F */) {\n      return 10 + (ch - 0x41 /* A */)\n    }\n    if (ch >= 0x61 /* a */ && ch <= 0x66 /* f */) {\n      return 10 + (ch - 0x61 /* a */)\n    }\n    return ch - 0x30 /* 0 */\n  }\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-annexB-LegacyOctalEscapeSequence\n  // Allows only 0-377(octal) i.e. 0-255(decimal).\n  pp$8.regexp_eatLegacyOctalEscapeSequence = function(state) {\n    if (this.regexp_eatOctalDigit(state)) {\n      var n1 = state.lastIntValue;\n      if (this.regexp_eatOctalDigit(state)) {\n        var n2 = state.lastIntValue;\n        if (n1 <= 3 && this.regexp_eatOctalDigit(state)) {\n          state.lastIntValue = n1 * 64 + n2 * 8 + state.lastIntValue;\n        } else {\n          state.lastIntValue = n1 * 8 + n2;\n        }\n      } else {\n        state.lastIntValue = n1;\n      }\n      return true\n    }\n    return false\n  };\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-OctalDigit\n  pp$8.regexp_eatOctalDigit = function(state) {\n    var ch = state.current();\n    if (isOctalDigit(ch)) {\n      state.lastIntValue = ch - 0x30; /* 0 */\n      state.advance();\n      return true\n    }\n    state.lastIntValue = 0;\n    return false\n  };\n  function isOctalDigit(ch) {\n    return ch >= 0x30 /* 0 */ && ch <= 0x37 /* 7 */\n  }\n\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-Hex4Digits\n  // https://www.ecma-international.org/ecma-262/8.0/#prod-HexDigit\n  // And HexDigit HexDigit in https://www.ecma-international.org/ecma-262/8.0/#prod-HexEscapeSequence\n  pp$8.regexp_eatFixedHexDigits = function(state, length) {\n    var start = state.pos;\n    state.lastIntValue = 0;\n    for (var i = 0; i < length; ++i) {\n      var ch = state.current();\n      if (!isHexDigit(ch)) {\n        state.pos = start;\n        return false\n      }\n      state.lastIntValue = 16 * state.lastIntValue + hexToInt(ch);\n      state.advance();\n    }\n    return true\n  };\n\n  // Object type used to represent tokens. Note that normally, tokens\n  // simply exist as properties on the parser object. This is only\n  // used for the onToken callback and the external tokenizer.\n\n  var Token = function Token(p) {\n    this.type = p.type;\n    this.value = p.value;\n    this.start = p.start;\n    this.end = p.end;\n    if (p.options.locations)\n      { this.loc = new SourceLocation(p, p.startLoc, p.endLoc); }\n    if (p.options.ranges)\n      { this.range = [p.start, p.end]; }\n  };\n\n  // ## Tokenizer\n\n  var pp$9 = Parser.prototype;\n\n  // Move to the next token\n\n  pp$9.next = function(ignoreEscapeSequenceInKeyword) {\n    if (!ignoreEscapeSequenceInKeyword && this.type.keyword && this.containsEsc)\n      { this.raiseRecoverable(this.start, \"Escape sequence in keyword \" + this.type.keyword); }\n    if (this.options.onToken)\n      { this.options.onToken(new Token(this)); }\n\n    this.lastTokEnd = this.end;\n    this.lastTokStart = this.start;\n    this.lastTokEndLoc = this.endLoc;\n    this.lastTokStartLoc = this.startLoc;\n    this.nextToken();\n  };\n\n  pp$9.getToken = function() {\n    this.next();\n    return new Token(this)\n  };\n\n  // If we're in an ES6 environment, make parsers iterable\n  if (typeof Symbol !== \"undefined\")\n    { pp$9[Symbol.iterator] = function() {\n      var this$1 = this;\n\n      return {\n        next: function () {\n          var token = this$1.getToken();\n          return {\n            done: token.type === types.eof,\n            value: token\n          }\n        }\n      }\n    }; }\n\n  // Toggle strict mode. Re-reads the next number or string to please\n  // pedantic tests (`\"use strict\"; 010;` should fail).\n\n  pp$9.curContext = function() {\n    return this.context[this.context.length - 1]\n  };\n\n  // Read a single token, updating the parser object's token-related\n  // properties.\n\n  pp$9.nextToken = function() {\n    var curContext = this.curContext();\n    if (!curContext || !curContext.preserveSpace) { this.skipSpace(); }\n\n    this.start = this.pos;\n    if (this.options.locations) { this.startLoc = this.curPosition(); }\n    if (this.pos >= this.input.length) { return this.finishToken(types.eof) }\n\n    if (curContext.override) { return curContext.override(this) }\n    else { this.readToken(this.fullCharCodeAtPos()); }\n  };\n\n  pp$9.readToken = function(code) {\n    // Identifier or keyword. '\\uXXXX' sequences are allowed in\n    // identifiers, so '\\' also dispatches to that.\n    if (isIdentifierStart(code, this.options.ecmaVersion >= 6) || code === 92 /* '\\' */)\n      { return this.readWord() }\n\n    return this.getTokenFromCode(code)\n  };\n\n  pp$9.fullCharCodeAtPos = function() {\n    var code = this.input.charCodeAt(this.pos);\n    if (code <= 0xd7ff || code >= 0xe000) { return code }\n    var next = this.input.charCodeAt(this.pos + 1);\n    return (code << 10) + next - 0x35fdc00\n  };\n\n  pp$9.skipBlockComment = function() {\n    var startLoc = this.options.onComment && this.curPosition();\n    var start = this.pos, end = this.input.indexOf(\"*/\", this.pos += 2);\n    if (end === -1) { this.raise(this.pos - 2, \"Unterminated comment\"); }\n    this.pos = end + 2;\n    if (this.options.locations) {\n      lineBreakG.lastIndex = start;\n      var match;\n      while ((match = lineBreakG.exec(this.input)) && match.index < this.pos) {\n        ++this.curLine;\n        this.lineStart = match.index + match[0].length;\n      }\n    }\n    if (this.options.onComment)\n      { this.options.onComment(true, this.input.slice(start + 2, end), start, this.pos,\n                             startLoc, this.curPosition()); }\n  };\n\n  pp$9.skipLineComment = function(startSkip) {\n    var start = this.pos;\n    var startLoc = this.options.onComment && this.curPosition();\n    var ch = this.input.charCodeAt(this.pos += startSkip);\n    while (this.pos < this.input.length && !isNewLine(ch)) {\n      ch = this.input.charCodeAt(++this.pos);\n    }\n    if (this.options.onComment)\n      { this.options.onComment(false, this.input.slice(start + startSkip, this.pos), start, this.pos,\n                             startLoc, this.curPosition()); }\n  };\n\n  // Called at the start of the parse and after every token. Skips\n  // whitespace and comments, and.\n\n  pp$9.skipSpace = function() {\n    loop: while (this.pos < this.input.length) {\n      var ch = this.input.charCodeAt(this.pos);\n      switch (ch) {\n      case 32: case 160: // ' '\n        ++this.pos;\n        break\n      case 13:\n        if (this.input.charCodeAt(this.pos + 1) === 10) {\n          ++this.pos;\n        }\n      case 10: case 8232: case 8233:\n        ++this.pos;\n        if (this.options.locations) {\n          ++this.curLine;\n          this.lineStart = this.pos;\n        }\n        break\n      case 47: // '/'\n        switch (this.input.charCodeAt(this.pos + 1)) {\n        case 42: // '*'\n          this.skipBlockComment();\n          break\n        case 47:\n          this.skipLineComment(2);\n          break\n        default:\n          break loop\n        }\n        break\n      default:\n        if (ch > 8 && ch < 14 || ch >= 5760 && nonASCIIwhitespace.test(String.fromCharCode(ch))) {\n          ++this.pos;\n        } else {\n          break loop\n        }\n      }\n    }\n  };\n\n  // Called at the end of every token. Sets `end`, `val`, and\n  // maintains `context` and `exprAllowed`, and skips the space after\n  // the token, so that the next one's `start` will point at the\n  // right position.\n\n  pp$9.finishToken = function(type, val) {\n    this.end = this.pos;\n    if (this.options.locations) { this.endLoc = this.curPosition(); }\n    var prevType = this.type;\n    this.type = type;\n    this.value = val;\n\n    this.updateContext(prevType);\n  };\n\n  // ### Token reading\n\n  // This is the function that is called to fetch the next token. It\n  // is somewhat obscure, because it works in character codes rather\n  // than characters, and because operator parsing has been inlined\n  // into it.\n  //\n  // All in the name of speed.\n  //\n  pp$9.readToken_dot = function() {\n    var next = this.input.charCodeAt(this.pos + 1);\n    if (next >= 48 && next <= 57) { return this.readNumber(true) }\n    var next2 = this.input.charCodeAt(this.pos + 2);\n    if (this.options.ecmaVersion >= 6 && next === 46 && next2 === 46) { // 46 = dot '.'\n      this.pos += 3;\n      return this.finishToken(types.ellipsis)\n    } else {\n      ++this.pos;\n      return this.finishToken(types.dot)\n    }\n  };\n\n  pp$9.readToken_slash = function() { // '/'\n    var next = this.input.charCodeAt(this.pos + 1);\n    if (this.exprAllowed) { ++this.pos; return this.readRegexp() }\n    if (next === 61) { return this.finishOp(types.assign, 2) }\n    return this.finishOp(types.slash, 1)\n  };\n\n  pp$9.readToken_mult_modulo_exp = function(code) { // '%*'\n    var next = this.input.charCodeAt(this.pos + 1);\n    var size = 1;\n    var tokentype = code === 42 ? types.star : types.modulo;\n\n    // exponentiation operator ** and **=\n    if (this.options.ecmaVersion >= 7 && code === 42 && next === 42) {\n      ++size;\n      tokentype = types.starstar;\n      next = this.input.charCodeAt(this.pos + 2);\n    }\n\n    if (next === 61) { return this.finishOp(types.assign, size + 1) }\n    return this.finishOp(tokentype, size)\n  };\n\n  pp$9.readToken_pipe_amp = function(code) { // '|&'\n    var next = this.input.charCodeAt(this.pos + 1);\n    if (next === code) {\n      if (this.options.ecmaVersion >= 12) {\n        var next2 = this.input.charCodeAt(this.pos + 2);\n        if (next2 === 61) { return this.finishOp(types.assign, 3) }\n      }\n      return this.finishOp(code === 124 ? types.logicalOR : types.logicalAND, 2)\n    }\n    if (next === 61) { return this.finishOp(types.assign, 2) }\n    return this.finishOp(code === 124 ? types.bitwiseOR : types.bitwiseAND, 1)\n  };\n\n  pp$9.readToken_caret = function() { // '^'\n    var next = this.input.charCodeAt(this.pos + 1);\n    if (next === 61) { return this.finishOp(types.assign, 2) }\n    return this.finishOp(types.bitwiseXOR, 1)\n  };\n\n  pp$9.readToken_plus_min = function(code) { // '+-'\n    var next = this.input.charCodeAt(this.pos + 1);\n    if (next === code) {\n      if (next === 45 && !this.inModule && this.input.charCodeAt(this.pos + 2) === 62 &&\n          (this.lastTokEnd === 0 || lineBreak.test(this.input.slice(this.lastTokEnd, this.pos)))) {\n        // A `-->` line comment\n        this.skipLineComment(3);\n        this.skipSpace();\n        return this.nextToken()\n      }\n      return this.finishOp(types.incDec, 2)\n    }\n    if (next === 61) { return this.finishOp(types.assign, 2) }\n    return this.finishOp(types.plusMin, 1)\n  };\n\n  pp$9.readToken_lt_gt = function(code) { // '<>'\n    var next = this.input.charCodeAt(this.pos + 1);\n    var size = 1;\n    if (next === code) {\n      size = code === 62 && this.input.charCodeAt(this.pos + 2) === 62 ? 3 : 2;\n      if (this.input.charCodeAt(this.pos + size) === 61) { return this.finishOp(types.assign, size + 1) }\n      return this.finishOp(types.bitShift, size)\n    }\n    if (next === 33 && code === 60 && !this.inModule && this.input.charCodeAt(this.pos + 2) === 45 &&\n        this.input.charCodeAt(this.pos + 3) === 45) {\n      // `<!--`, an XML-style comment that should be interpreted as a line comment\n      this.skipLineComment(4);\n      this.skipSpace();\n      return this.nextToken()\n    }\n    if (next === 61) { size = 2; }\n    return this.finishOp(types.relational, size)\n  };\n\n  pp$9.readToken_eq_excl = function(code) { // '=!'\n    var next = this.input.charCodeAt(this.pos + 1);\n    if (next === 61) { return this.finishOp(types.equality, this.input.charCodeAt(this.pos + 2) === 61 ? 3 : 2) }\n    if (code === 61 && next === 62 && this.options.ecmaVersion >= 6) { // '=>'\n      this.pos += 2;\n      return this.finishToken(types.arrow)\n    }\n    return this.finishOp(code === 61 ? types.eq : types.prefix, 1)\n  };\n\n  pp$9.readToken_question = function() { // '?'\n    var ecmaVersion = this.options.ecmaVersion;\n    if (ecmaVersion >= 11) {\n      var next = this.input.charCodeAt(this.pos + 1);\n      if (next === 46) {\n        var next2 = this.input.charCodeAt(this.pos + 2);\n        if (next2 < 48 || next2 > 57) { return this.finishOp(types.questionDot, 2) }\n      }\n      if (next === 63) {\n        if (ecmaVersion >= 12) {\n          var next2$1 = this.input.charCodeAt(this.pos + 2);\n          if (next2$1 === 61) { return this.finishOp(types.assign, 3) }\n        }\n        return this.finishOp(types.coalesce, 2)\n      }\n    }\n    return this.finishOp(types.question, 1)\n  };\n\n  pp$9.getTokenFromCode = function(code) {\n    switch (code) {\n    // The interpretation of a dot depends on whether it is followed\n    // by a digit or another two dots.\n    case 46: // '.'\n      return this.readToken_dot()\n\n    // Punctuation tokens.\n    case 40: ++this.pos; return this.finishToken(types.parenL)\n    case 41: ++this.pos; return this.finishToken(types.parenR)\n    case 59: ++this.pos; return this.finishToken(types.semi)\n    case 44: ++this.pos; return this.finishToken(types.comma)\n    case 91: ++this.pos; return this.finishToken(types.bracketL)\n    case 93: ++this.pos; return this.finishToken(types.bracketR)\n    case 123: ++this.pos; return this.finishToken(types.braceL)\n    case 125: ++this.pos; return this.finishToken(types.braceR)\n    case 58: ++this.pos; return this.finishToken(types.colon)\n\n    case 96: // '`'\n      if (this.options.ecmaVersion < 6) { break }\n      ++this.pos;\n      return this.finishToken(types.backQuote)\n\n    case 48: // '0'\n      var next = this.input.charCodeAt(this.pos + 1);\n      if (next === 120 || next === 88) { return this.readRadixNumber(16) } // '0x', '0X' - hex number\n      if (this.options.ecmaVersion >= 6) {\n        if (next === 111 || next === 79) { return this.readRadixNumber(8) } // '0o', '0O' - octal number\n        if (next === 98 || next === 66) { return this.readRadixNumber(2) } // '0b', '0B' - binary number\n      }\n\n    // Anything else beginning with a digit is an integer, octal\n    // number, or float.\n    case 49: case 50: case 51: case 52: case 53: case 54: case 55: case 56: case 57: // 1-9\n      return this.readNumber(false)\n\n    // Quotes produce strings.\n    case 34: case 39: // '\"', \"'\"\n      return this.readString(code)\n\n    // Operators are parsed inline in tiny state machines. '=' (61) is\n    // often referred to. `finishOp` simply skips the amount of\n    // characters it is given as second argument, and returns a token\n    // of the type given by its first argument.\n\n    case 47: // '/'\n      return this.readToken_slash()\n\n    case 37: case 42: // '%*'\n      return this.readToken_mult_modulo_exp(code)\n\n    case 124: case 38: // '|&'\n      return this.readToken_pipe_amp(code)\n\n    case 94: // '^'\n      return this.readToken_caret()\n\n    case 43: case 45: // '+-'\n      return this.readToken_plus_min(code)\n\n    case 60: case 62: // '<>'\n      return this.readToken_lt_gt(code)\n\n    case 61: case 33: // '=!'\n      return this.readToken_eq_excl(code)\n\n    case 63: // '?'\n      return this.readToken_question()\n\n    case 126: // '~'\n      return this.finishOp(types.prefix, 1)\n    }\n\n    this.raise(this.pos, \"Unexpected character '\" + codePointToString$1(code) + \"'\");\n  };\n\n  pp$9.finishOp = function(type, size) {\n    var str = this.input.slice(this.pos, this.pos + size);\n    this.pos += size;\n    return this.finishToken(type, str)\n  };\n\n  pp$9.readRegexp = function() {\n    var escaped, inClass, start = this.pos;\n    for (;;) {\n      if (this.pos >= this.input.length) { this.raise(start, \"Unterminated regular expression\"); }\n      var ch = this.input.charAt(this.pos);\n      if (lineBreak.test(ch)) { this.raise(start, \"Unterminated regular expression\"); }\n      if (!escaped) {\n        if (ch === \"[\") { inClass = true; }\n        else if (ch === \"]\" && inClass) { inClass = false; }\n        else if (ch === \"/\" && !inClass) { break }\n        escaped = ch === \"\\\\\";\n      } else { escaped = false; }\n      ++this.pos;\n    }\n    var pattern = this.input.slice(start, this.pos);\n    ++this.pos;\n    var flagsStart = this.pos;\n    var flags = this.readWord1();\n    if (this.containsEsc) { this.unexpected(flagsStart); }\n\n    // Validate pattern\n    var state = this.regexpState || (this.regexpState = new RegExpValidationState(this));\n    state.reset(start, pattern, flags);\n    this.validateRegExpFlags(state);\n    this.validateRegExpPattern(state);\n\n    // Create Literal#value property value.\n    var value = null;\n    try {\n      value = new RegExp(pattern, flags);\n    } catch (e) {\n      // ESTree requires null if it failed to instantiate RegExp object.\n      // https://github.com/estree/estree/blob/a27003adf4fd7bfad44de9cef372a2eacd527b1c/es5.md#regexpliteral\n    }\n\n    return this.finishToken(types.regexp, {pattern: pattern, flags: flags, value: value})\n  };\n\n  // Read an integer in the given radix. Return null if zero digits\n  // were read, the integer value otherwise. When `len` is given, this\n  // will return `null` unless the integer has exactly `len` digits.\n\n  pp$9.readInt = function(radix, len, maybeLegacyOctalNumericLiteral) {\n    // `len` is used for character escape sequences. In that case, disallow separators.\n    var allowSeparators = this.options.ecmaVersion >= 12 && len === undefined;\n\n    // `maybeLegacyOctalNumericLiteral` is true if it doesn't have prefix (0x,0o,0b)\n    // and isn't fraction part nor exponent part. In that case, if the first digit\n    // is zero then disallow separators.\n    var isLegacyOctalNumericLiteral = maybeLegacyOctalNumericLiteral && this.input.charCodeAt(this.pos) === 48;\n\n    var start = this.pos, total = 0, lastCode = 0;\n    for (var i = 0, e = len == null ? Infinity : len; i < e; ++i, ++this.pos) {\n      var code = this.input.charCodeAt(this.pos), val = (void 0);\n\n      if (allowSeparators && code === 95) {\n        if (isLegacyOctalNumericLiteral) { this.raiseRecoverable(this.pos, \"Numeric separator is not allowed in legacy octal numeric literals\"); }\n        if (lastCode === 95) { this.raiseRecoverable(this.pos, \"Numeric separator must be exactly one underscore\"); }\n        if (i === 0) { this.raiseRecoverable(this.pos, \"Numeric separator is not allowed at the first of digits\"); }\n        lastCode = code;\n        continue\n      }\n\n      if (code >= 97) { val = code - 97 + 10; } // a\n      else if (code >= 65) { val = code - 65 + 10; } // A\n      else if (code >= 48 && code <= 57) { val = code - 48; } // 0-9\n      else { val = Infinity; }\n      if (val >= radix) { break }\n      lastCode = code;\n      total = total * radix + val;\n    }\n\n    if (allowSeparators && lastCode === 95) { this.raiseRecoverable(this.pos - 1, \"Numeric separator is not allowed at the last of digits\"); }\n    if (this.pos === start || len != null && this.pos - start !== len) { return null }\n\n    return total\n  };\n\n  function stringToNumber(str, isLegacyOctalNumericLiteral) {\n    if (isLegacyOctalNumericLiteral) {\n      return parseInt(str, 8)\n    }\n\n    // `parseFloat(value)` stops parsing at the first numeric separator then returns a wrong value.\n    return parseFloat(str.replace(/_/g, \"\"))\n  }\n\n  function stringToBigInt(str) {\n    if (typeof BigInt !== \"function\") {\n      return null\n    }\n\n    // `BigInt(value)` throws syntax error if the string contains numeric separators.\n    return BigInt(str.replace(/_/g, \"\"))\n  }\n\n  pp$9.readRadixNumber = function(radix) {\n    var start = this.pos;\n    this.pos += 2; // 0x\n    var val = this.readInt(radix);\n    if (val == null) { this.raise(this.start + 2, \"Expected number in radix \" + radix); }\n    if (this.options.ecmaVersion >= 11 && this.input.charCodeAt(this.pos) === 110) {\n      val = stringToBigInt(this.input.slice(start, this.pos));\n      ++this.pos;\n    } else if (isIdentifierStart(this.fullCharCodeAtPos())) { this.raise(this.pos, \"Identifier directly after number\"); }\n    return this.finishToken(types.num, val)\n  };\n\n  // Read an integer, octal integer, or floating-point number.\n\n  pp$9.readNumber = function(startsWithDot) {\n    var start = this.pos;\n    if (!startsWithDot && this.readInt(10, undefined, true) === null) { this.raise(start, \"Invalid number\"); }\n    var octal = this.pos - start >= 2 && this.input.charCodeAt(start) === 48;\n    if (octal && this.strict) { this.raise(start, \"Invalid number\"); }\n    var next = this.input.charCodeAt(this.pos);\n    if (!octal && !startsWithDot && this.options.ecmaVersion >= 11 && next === 110) {\n      var val$1 = stringToBigInt(this.input.slice(start, this.pos));\n      ++this.pos;\n      if (isIdentifierStart(this.fullCharCodeAtPos())) { this.raise(this.pos, \"Identifier directly after number\"); }\n      return this.finishToken(types.num, val$1)\n    }\n    if (octal && /[89]/.test(this.input.slice(start, this.pos))) { octal = false; }\n    if (next === 46 && !octal) { // '.'\n      ++this.pos;\n      this.readInt(10);\n      next = this.input.charCodeAt(this.pos);\n    }\n    if ((next === 69 || next === 101) && !octal) { // 'eE'\n      next = this.input.charCodeAt(++this.pos);\n      if (next === 43 || next === 45) { ++this.pos; } // '+-'\n      if (this.readInt(10) === null) { this.raise(start, \"Invalid number\"); }\n    }\n    if (isIdentifierStart(this.fullCharCodeAtPos())) { this.raise(this.pos, \"Identifier directly after number\"); }\n\n    var val = stringToNumber(this.input.slice(start, this.pos), octal);\n    return this.finishToken(types.num, val)\n  };\n\n  // Read a string value, interpreting backslash-escapes.\n\n  pp$9.readCodePoint = function() {\n    var ch = this.input.charCodeAt(this.pos), code;\n\n    if (ch === 123) { // '{'\n      if (this.options.ecmaVersion < 6) { this.unexpected(); }\n      var codePos = ++this.pos;\n      code = this.readHexChar(this.input.indexOf(\"}\", this.pos) - this.pos);\n      ++this.pos;\n      if (code > 0x10FFFF) { this.invalidStringToken(codePos, \"Code point out of bounds\"); }\n    } else {\n      code = this.readHexChar(4);\n    }\n    return code\n  };\n\n  function codePointToString$1(code) {\n    // UTF-16 Decoding\n    if (code <= 0xFFFF) { return String.fromCharCode(code) }\n    code -= 0x10000;\n    return String.fromCharCode((code >> 10) + 0xD800, (code & 1023) + 0xDC00)\n  }\n\n  pp$9.readString = function(quote) {\n    var out = \"\", chunkStart = ++this.pos;\n    for (;;) {\n      if (this.pos >= this.input.length) { this.raise(this.start, \"Unterminated string constant\"); }\n      var ch = this.input.charCodeAt(this.pos);\n      if (ch === quote) { break }\n      if (ch === 92) { // '\\'\n        out += this.input.slice(chunkStart, this.pos);\n        out += this.readEscapedChar(false);\n        chunkStart = this.pos;\n      } else {\n        if (isNewLine(ch, this.options.ecmaVersion >= 10)) { this.raise(this.start, \"Unterminated string constant\"); }\n        ++this.pos;\n      }\n    }\n    out += this.input.slice(chunkStart, this.pos++);\n    return this.finishToken(types.string, out)\n  };\n\n  // Reads template string tokens.\n\n  var INVALID_TEMPLATE_ESCAPE_ERROR = {};\n\n  pp$9.tryReadTemplateToken = function() {\n    this.inTemplateElement = true;\n    try {\n      this.readTmplToken();\n    } catch (err) {\n      if (err === INVALID_TEMPLATE_ESCAPE_ERROR) {\n        this.readInvalidTemplateToken();\n      } else {\n        throw err\n      }\n    }\n\n    this.inTemplateElement = false;\n  };\n\n  pp$9.invalidStringToken = function(position, message) {\n    if (this.inTemplateElement && this.options.ecmaVersion >= 9) {\n      throw INVALID_TEMPLATE_ESCAPE_ERROR\n    } else {\n      this.raise(position, message);\n    }\n  };\n\n  pp$9.readTmplToken = function() {\n    var out = \"\", chunkStart = this.pos;\n    for (;;) {\n      if (this.pos >= this.input.length) { this.raise(this.start, \"Unterminated template\"); }\n      var ch = this.input.charCodeAt(this.pos);\n      if (ch === 96 || ch === 36 && this.input.charCodeAt(this.pos + 1) === 123) { // '`', '${'\n        if (this.pos === this.start && (this.type === types.template || this.type === types.invalidTemplate)) {\n          if (ch === 36) {\n            this.pos += 2;\n            return this.finishToken(types.dollarBraceL)\n          } else {\n            ++this.pos;\n            return this.finishToken(types.backQuote)\n          }\n        }\n        out += this.input.slice(chunkStart, this.pos);\n        return this.finishToken(types.template, out)\n      }\n      if (ch === 92) { // '\\'\n        out += this.input.slice(chunkStart, this.pos);\n        out += this.readEscapedChar(true);\n        chunkStart = this.pos;\n      } else if (isNewLine(ch)) {\n        out += this.input.slice(chunkStart, this.pos);\n        ++this.pos;\n        switch (ch) {\n        case 13:\n          if (this.input.charCodeAt(this.pos) === 10) { ++this.pos; }\n        case 10:\n          out += \"\\n\";\n          break\n        default:\n          out += String.fromCharCode(ch);\n          break\n        }\n        if (this.options.locations) {\n          ++this.curLine;\n          this.lineStart = this.pos;\n        }\n        chunkStart = this.pos;\n      } else {\n        ++this.pos;\n      }\n    }\n  };\n\n  // Reads a template token to search for the end, without validating any escape sequences\n  pp$9.readInvalidTemplateToken = function() {\n    for (; this.pos < this.input.length; this.pos++) {\n      switch (this.input[this.pos]) {\n      case \"\\\\\":\n        ++this.pos;\n        break\n\n      case \"$\":\n        if (this.input[this.pos + 1] !== \"{\") {\n          break\n        }\n      // falls through\n\n      case \"`\":\n        return this.finishToken(types.invalidTemplate, this.input.slice(this.start, this.pos))\n\n      // no default\n      }\n    }\n    this.raise(this.start, \"Unterminated template\");\n  };\n\n  // Used to read escaped characters\n\n  pp$9.readEscapedChar = function(inTemplate) {\n    var ch = this.input.charCodeAt(++this.pos);\n    ++this.pos;\n    switch (ch) {\n    case 110: return \"\\n\" // 'n' -> '\\n'\n    case 114: return \"\\r\" // 'r' -> '\\r'\n    case 120: return String.fromCharCode(this.readHexChar(2)) // 'x'\n    case 117: return codePointToString$1(this.readCodePoint()) // 'u'\n    case 116: return \"\\t\" // 't' -> '\\t'\n    case 98: return \"\\b\" // 'b' -> '\\b'\n    case 118: return \"\\u000b\" // 'v' -> '\\u000b'\n    case 102: return \"\\f\" // 'f' -> '\\f'\n    case 13: if (this.input.charCodeAt(this.pos) === 10) { ++this.pos; } // '\\r\\n'\n    case 10: // ' \\n'\n      if (this.options.locations) { this.lineStart = this.pos; ++this.curLine; }\n      return \"\"\n    case 56:\n    case 57:\n      if (inTemplate) {\n        var codePos = this.pos - 1;\n\n        this.invalidStringToken(\n          codePos,\n          \"Invalid escape sequence in template string\"\n        );\n\n        return null\n      }\n    default:\n      if (ch >= 48 && ch <= 55) {\n        var octalStr = this.input.substr(this.pos - 1, 3).match(/^[0-7]+/)[0];\n        var octal = parseInt(octalStr, 8);\n        if (octal > 255) {\n          octalStr = octalStr.slice(0, -1);\n          octal = parseInt(octalStr, 8);\n        }\n        this.pos += octalStr.length - 1;\n        ch = this.input.charCodeAt(this.pos);\n        if ((octalStr !== \"0\" || ch === 56 || ch === 57) && (this.strict || inTemplate)) {\n          this.invalidStringToken(\n            this.pos - 1 - octalStr.length,\n            inTemplate\n              ? \"Octal literal in template string\"\n              : \"Octal literal in strict mode\"\n          );\n        }\n        return String.fromCharCode(octal)\n      }\n      if (isNewLine(ch)) {\n        // Unicode new line characters after \\ get removed from output in both\n        // template literals and strings\n        return \"\"\n      }\n      return String.fromCharCode(ch)\n    }\n  };\n\n  // Used to read character escape sequences ('\\x', '\\u', '\\U').\n\n  pp$9.readHexChar = function(len) {\n    var codePos = this.pos;\n    var n = this.readInt(16, len);\n    if (n === null) { this.invalidStringToken(codePos, \"Bad character escape sequence\"); }\n    return n\n  };\n\n  // Read an identifier, and return it as a string. Sets `this.containsEsc`\n  // to whether the word contained a '\\u' escape.\n  //\n  // Incrementally adds only escaped chars, adding other chunks as-is\n  // as a micro-optimization.\n\n  pp$9.readWord1 = function() {\n    this.containsEsc = false;\n    var word = \"\", first = true, chunkStart = this.pos;\n    var astral = this.options.ecmaVersion >= 6;\n    while (this.pos < this.input.length) {\n      var ch = this.fullCharCodeAtPos();\n      if (isIdentifierChar(ch, astral)) {\n        this.pos += ch <= 0xffff ? 1 : 2;\n      } else if (ch === 92) { // \"\\\"\n        this.containsEsc = true;\n        word += this.input.slice(chunkStart, this.pos);\n        var escStart = this.pos;\n        if (this.input.charCodeAt(++this.pos) !== 117) // \"u\"\n          { this.invalidStringToken(this.pos, \"Expecting Unicode escape sequence \\\\uXXXX\"); }\n        ++this.pos;\n        var esc = this.readCodePoint();\n        if (!(first ? isIdentifierStart : isIdentifierChar)(esc, astral))\n          { this.invalidStringToken(escStart, \"Invalid Unicode escape\"); }\n        word += codePointToString$1(esc);\n        chunkStart = this.pos;\n      } else {\n        break\n      }\n      first = false;\n    }\n    return word + this.input.slice(chunkStart, this.pos)\n  };\n\n  // Read an identifier or keyword token. Will check for reserved\n  // words when necessary.\n\n  pp$9.readWord = function() {\n    var word = this.readWord1();\n    var type = types.name;\n    if (this.keywords.test(word)) {\n      type = keywords$1[word];\n    }\n    return this.finishToken(type, word)\n  };\n\n  // Acorn is a tiny, fast JavaScript parser written in JavaScript.\n\n  var version = \"7.4.1\";\n\n  Parser.acorn = {\n    Parser: Parser,\n    version: version,\n    defaultOptions: defaultOptions,\n    Position: Position,\n    SourceLocation: SourceLocation,\n    getLineInfo: getLineInfo,\n    Node: Node,\n    TokenType: TokenType,\n    tokTypes: types,\n    keywordTypes: keywords$1,\n    TokContext: TokContext,\n    tokContexts: types$1,\n    isIdentifierChar: isIdentifierChar,\n    isIdentifierStart: isIdentifierStart,\n    Token: Token,\n    isNewLine: isNewLine,\n    lineBreak: lineBreak,\n    lineBreakG: lineBreakG,\n    nonASCIIwhitespace: nonASCIIwhitespace\n  };\n\n  // The main exported interface (under `self.acorn` when in the\n  // browser) is a `parse` function that takes a code string and\n  // returns an abstract syntax tree as specified by [Mozilla parser\n  // API][api].\n  //\n  // [api]: https://developer.mozilla.org/en-US/docs/SpiderMonkey/Parser_API\n\n  function parse(input, options) {\n    return Parser.parse(input, options)\n  }\n\n  // This function tries to parse a single expression at a given\n  // offset in a string. Useful for parsing mixed-language formats\n  // that embed JavaScript expressions.\n\n  function parseExpressionAt(input, pos, options) {\n    return Parser.parseExpressionAt(input, pos, options)\n  }\n\n  // Acorn is organized as a tokenizer and a recursive-descent parser.\n  // The `tokenizer` export provides an interface to the tokenizer.\n\n  function tokenizer(input, options) {\n    return Parser.tokenizer(input, options)\n  }\n\n  exports.Node = Node;\n  exports.Parser = Parser;\n  exports.Position = Position;\n  exports.SourceLocation = SourceLocation;\n  exports.TokContext = TokContext;\n  exports.Token = Token;\n  exports.TokenType = TokenType;\n  exports.defaultOptions = defaultOptions;\n  exports.getLineInfo = getLineInfo;\n  exports.isIdentifierChar = isIdentifierChar;\n  exports.isIdentifierStart = isIdentifierStart;\n  exports.isNewLine = isNewLine;\n  exports.keywordTypes = keywords$1;\n  exports.lineBreak = lineBreak;\n  exports.lineBreakG = lineBreakG;\n  exports.nonASCIIwhitespace = nonASCIIwhitespace;\n  exports.parse = parse;\n  exports.parseExpressionAt = parseExpressionAt;\n  exports.tokContexts = types$1;\n  exports.tokTypes = types;\n  exports.tokenizer = tokenizer;\n  exports.version = version;\n\n  Object.defineProperty(exports, '__esModule', { value: true });\n\n})));\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/acorn/dist/acorn.js',
          'importMap': {},
          'packageName': 'acorn',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/acorn/dist/acorn.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/browser-pack/index.js': {
        'builtin': [
          'fs.readFileSync',
          'path.join',
          'path.relative',
        ],
        'globals': {
          '__dirname': 'read',
          'process.cwd': 'read',
        },
        'moduleRecord': {
          'content': "var JSONStream = require('JSONStream');\nvar defined = require('defined');\nvar through = require('through2');\nvar umd = require('umd');\nvar Buffer = require('safe-buffer').Buffer;\n\nvar fs = require('fs');\nvar path = require('path');\n\nvar combineSourceMap = require('combine-source-map');\n\nvar defaultPreludePath = path.join(__dirname, '_prelude.js');\nvar defaultPrelude = fs.readFileSync(defaultPreludePath, 'utf8');\n\nfunction newlinesIn(src) {\n  if (!src) return 0;\n  var newlines = src.match(/\\n/g);\n\n  return newlines ? newlines.length : 0;\n}\n\nmodule.exports = function (opts) {\n    if (!opts) opts = {};\n    var parser = opts.raw ? through.obj() : JSONStream.parse([ true ]);\n    var stream = through.obj(\n        function (buf, enc, next) { parser.write(buf); next() },\n        function () { parser.end() }\n    );\n    parser.pipe(through.obj(write, end));\n    stream.standaloneModule = opts.standaloneModule;\n    stream.hasExports = opts.hasExports;\n    \n    var first = true;\n    var entries = [];\n    var basedir = defined(opts.basedir, process.cwd());\n    var prelude = opts.prelude || defaultPrelude;\n    var preludePath = opts.preludePath ||\n        path.relative(basedir, defaultPreludePath).replace(/\\\\/g, '/');\n    \n    var lineno = 1 + newlinesIn(prelude);\n    var sourcemap;\n    \n    return stream;\n    \n    function write (row, enc, next) {\n        if (first && opts.standalone) {\n            var pre = umd.prelude(opts.standalone).trim();\n            stream.push(Buffer.from(pre + 'return ', 'utf8'));\n        }\n        else if (first && stream.hasExports) {\n            var pre = opts.externalRequireName || 'require';\n            stream.push(Buffer.from(pre + '=', 'utf8'));\n        }\n        if (first) stream.push(Buffer.from(prelude + '({', 'utf8'));\n        \n        if (row.sourceFile && !row.nomap) {\n            if (!sourcemap) {\n                sourcemap = combineSourceMap.create(null, opts.sourceRoot);\n                sourcemap.addFile(\n                    { sourceFile: preludePath, source: prelude },\n                    { line: 0 }\n                );\n            }\n            sourcemap.addFile(\n                { sourceFile: row.sourceFile, source: row.source },\n                { line: lineno }\n            );\n        }\n        \n        var wrappedSource = [\n            (first ? '' : ','),\n            JSON.stringify(row.id),\n            ':[',\n            'function(require,module,exports){\\n',\n            combineSourceMap.removeComments(row.source),\n            '\\n},',\n            '{' + Object.keys(row.deps || {}).sort().map(function (key) {\n                return JSON.stringify(key) + ':'\n                    + JSON.stringify(row.deps[key])\n                ;\n            }).join(',') + '}',\n            ']'\n        ].join('');\n\n        stream.push(Buffer.from(wrappedSource, 'utf8'));\n        lineno += newlinesIn(wrappedSource);\n        \n        first = false;\n        if (row.entry && row.order !== undefined) {\n            entries[row.order] = row.id;\n        }\n        else if (row.entry) entries.push(row.id);\n        next();\n    }\n    \n    function end () {\n        if (first) stream.push(Buffer.from(prelude + '({', 'utf8'));\n        entries = entries.filter(function (x) { return x !== undefined });\n        \n        stream.push(\n            Buffer.from('},{},' + JSON.stringify(entries) + ')', 'utf8')\n        );\n\n        if (opts.standalone && !first) {\n            stream.push(Buffer.from(\n                '(' + JSON.stringify(stream.standaloneModule) + ')'\n                    + umd.postlude(opts.standalone),\n                'utf8'\n            ));\n        }\n        \n        if (sourcemap) {\n            var comment = sourcemap.comment();\n            if (opts.sourceMapPrefix) {\n                comment = comment.replace(\n                    /^\\/\\/#/, function () { return opts.sourceMapPrefix }\n                )\n            }\n            stream.push(Buffer.from('\\n' + comment + '\\n', 'utf8'));\n        }\n        if (!sourcemap && !opts.standalone) {\n            stream.push(Buffer.from(';\\n', 'utf8'));\n        }\n\n        stream.push(null);\n    }\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/browser-pack/index.js',
          'importMap': {
            'JSONStream': '/home/xyz/Development/webtorrent/node_modules/JSONStream/index.js',
            'combine-source-map': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/index.js',
            'defined': '/home/xyz/Development/webtorrent/node_modules/defined/index.js',
            'fs': 'fs',
            'path': 'path',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/safe-buffer/index.js',
            'through2': '/home/xyz/Development/webtorrent/node_modules/through2/through2.js',
            'umd': '/home/xyz/Development/webtorrent/node_modules/umd/index.js',
          },
          'packageName': 'browser-pack',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/browser-pack/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/browser-resolve/index.js': {
        'builtin': [
          'fs.readFile',
          'fs.readFileSync',
          'path.join.apply',
          'path',
          'path.resolve',
          'path.normalize',
          'path.join',
          'path.extname',
          'path.dirname',
        ],
        'globals': {
          '__dirname': 'read',
          'process.platform': 'read',
        },
        'moduleRecord': {
          'content': "// builtin\nvar fs = require('fs');\nvar path = require('path');\n\n// vendor\nvar resv = require('resolve');\n\n// given a path, create an array of node_module paths for it\n// borrowed from substack/resolve\nfunction nodeModulesPaths (start, cb) {\n    var splitRe = process.platform === 'win32' ? /[\\/\\\\]/ : /\\/+/;\n    var parts = start.split(splitRe);\n\n    var dirs = [];\n    for (var i = parts.length - 1; i >= 0; i--) {\n        if (parts[i] === 'node_modules') continue;\n        var dir = path.join.apply(\n            path, parts.slice(0, i + 1).concat(['node_modules'])\n        );\n        if (!parts[0].match(/([A-Za-z]:)/)) {\n            dir = '/' + dir;\n        }\n        dirs.push(dir);\n    }\n    return dirs;\n}\n\nfunction find_shims_in_package(pkgJson, cur_path, shims, browser) {\n    try {\n        var info = JSON.parse(pkgJson);\n    }\n    catch (err) {\n        err.message = pkgJson + ' : ' + err.message\n        throw err;\n    }\n\n    var replacements = getReplacements(info, browser);\n\n    // no replacements, skip shims\n    if (!replacements) {\n        return;\n    }\n\n    // if browser mapping is a string\n    // then it just replaces the main entry point\n    if (typeof replacements === 'string') {\n        var key = path.resolve(cur_path, info.main || 'index.js');\n        shims[key] = path.resolve(cur_path, replacements);\n        return;\n    }\n\n    // http://nodejs.org/api/modules.html#modules_loading_from_node_modules_folders\n    Object.keys(replacements).forEach(function(key) {\n        var val;\n        if (replacements[key] === false) {\n            val = path.normalize(__dirname + '/empty.js');\n        }\n        else {\n            val = replacements[key];\n            // if target is a relative path, then resolve\n            // otherwise we assume target is a module\n            if (val[0] === '.') {\n                val = path.resolve(cur_path, val);\n            }\n        }\n\n        if (key[0] === '/' || key[0] === '.') {\n            // if begins with / ../ or ./ then we must resolve to a full path\n            key = path.resolve(cur_path, key);\n        }\n        shims[key] = val;\n    });\n\n    [ '.js', '.json' ].forEach(function (ext) {\n        Object.keys(shims).forEach(function (key) {\n            if (!shims[key + ext]) {\n                shims[key + ext] = shims[key];\n            }\n        });\n    });\n}\n\n// paths is mutated\n// load shims from first package.json file found\nfunction load_shims(paths, browser, cb) {\n    // identify if our file should be replaced per the browser field\n    // original filename|id -> replacement\n    var shims = Object.create(null);\n\n    (function next() {\n        var cur_path = paths.shift();\n        if (!cur_path) {\n            return cb(null, shims);\n        }\n\n        var pkg_path = path.join(cur_path, 'package.json');\n\n        fs.readFile(pkg_path, 'utf8', function(err, data) {\n            if (err) {\n                // ignore paths we can't open\n                // avoids an exists check\n                if (err.code === 'ENOENT') {\n                    return next();\n                }\n\n                return cb(err);\n            }\n            try {\n                find_shims_in_package(data, cur_path, shims, browser);\n                return cb(null, shims);\n            }\n            catch (err) {\n                return cb(err);\n            }\n        });\n    })();\n};\n\n// paths is mutated\n// synchronously load shims from first package.json file found\nfunction load_shims_sync(paths, browser) {\n    // identify if our file should be replaced per the browser field\n    // original filename|id -> replacement\n    var shims = Object.create(null);\n    var cur_path;\n\n    while (cur_path = paths.shift()) {\n        var pkg_path = path.join(cur_path, 'package.json');\n\n        try {\n            var data = fs.readFileSync(pkg_path, 'utf8');\n            find_shims_in_package(data, cur_path, shims, browser);\n            return shims;\n        }\n        catch (err) {\n            // ignore paths we can't open\n            // avoids an exists check\n            if (err.code === 'ENOENT') {\n                continue;\n            }\n\n            throw err;\n        }\n    }\n    return shims;\n}\n\nfunction build_resolve_opts(opts, base) {\n    var packageFilter = opts.packageFilter;\n    var browser = normalizeBrowserFieldName(opts.browser)\n\n    opts.basedir = base;\n    opts.packageFilter = function (info, pkgdir) {\n        if (packageFilter) info = packageFilter(info, pkgdir);\n\n        var replacements = getReplacements(info, browser);\n\n        // no browser field, keep info unchanged\n        if (!replacements) {\n            return info;\n        }\n\n        info[browser] = replacements;\n\n        // replace main\n        if (typeof replacements === 'string') {\n            info.main = replacements;\n            return info;\n        }\n\n        var replace_main = replacements[info.main || './index.js'] ||\n            replacements['./' + info.main || './index.js'];\n\n        info.main = replace_main || info.main;\n        return info;\n    };\n\n    var pathFilter = opts.pathFilter;\n    opts.pathFilter = function(info, resvPath, relativePath) {\n        if (relativePath[0] != '.') {\n            relativePath = './' + relativePath;\n        }\n        var mappedPath;\n        if (pathFilter) {\n            mappedPath = pathFilter.apply(this, arguments);\n        }\n        if (mappedPath) {\n            return mappedPath;\n        }\n\n        var replacements = info[browser];\n        if (!replacements) {\n            return;\n        }\n\n        mappedPath = replacements[relativePath];\n        if (!mappedPath && path.extname(relativePath) === '') {\n            mappedPath = replacements[relativePath + '.js'];\n            if (!mappedPath) {\n                mappedPath = replacements[relativePath + '.json'];\n            }\n        }\n        return mappedPath;\n    };\n\n    return opts;\n}\n\nfunction resolve(id, opts, cb) {\n\n    // opts.filename\n    // opts.paths\n    // opts.modules\n    // opts.packageFilter\n\n    opts = opts || {};\n    opts.filename = opts.filename || '';\n\n    var base = path.dirname(opts.filename);\n\n    if (opts.basedir) {\n        base = opts.basedir;\n    }\n\n    var paths = nodeModulesPaths(base);\n\n    if (opts.paths) {\n        paths.push.apply(paths, opts.paths);\n    }\n\n    paths = paths.map(function(p) {\n        return path.dirname(p);\n    });\n\n    // we must always load shims because the browser field could shim out a module\n    load_shims(paths, opts.browser, function(err, shims) {\n        if (err) {\n            return cb(err);\n        }\n\n        var resid = path.resolve(opts.basedir || path.dirname(opts.filename), id);\n        if (shims[id] || shims[resid]) {\n            var xid = shims[id] ? id : resid;\n            // if the shim was is an absolute path, it was fully resolved\n            if (shims[xid][0] === '/') {\n                return resv(shims[xid], build_resolve_opts(opts, base), function(err, full, pkg) {\n                    cb(null, full, pkg);\n                });\n            }\n\n            // module -> alt-module shims\n            id = shims[xid];\n        }\n\n        var modules = opts.modules || Object.create(null);\n        var shim_path = modules[id];\n        if (shim_path) {\n            return cb(null, shim_path);\n        }\n\n        // our browser field resolver\n        // if browser field is an object tho?\n        var full = resv(id, build_resolve_opts(opts, base), function(err, full, pkg) {\n            if (err) {\n                return cb(err);\n            }\n\n            var resolved = (shims) ? shims[full] || full : full;\n            cb(null, resolved, pkg);\n        });\n    });\n};\n\nresolve.sync = function (id, opts) {\n\n    // opts.filename\n    // opts.paths\n    // opts.modules\n    // opts.packageFilter\n\n    opts = opts || {};\n    opts.filename = opts.filename || '';\n\n    var base = path.dirname(opts.filename);\n\n    if (opts.basedir) {\n        base = opts.basedir;\n    }\n\n    var paths = nodeModulesPaths(base);\n\n    if (opts.paths) {\n        paths.push.apply(paths, opts.paths);\n    }\n\n    paths = paths.map(function(p) {\n        return path.dirname(p);\n    });\n\n    // we must always load shims because the browser field could shim out a module\n    var shims = load_shims_sync(paths, opts.browser);\n    var resid = path.resolve(opts.basedir || path.dirname(opts.filename), id);\n\n    if (shims[id] || shims[resid]) {\n        var xid = shims[id] ? id : resid;\n        // if the shim was is an absolute path, it was fully resolved\n        if (shims[xid][0] === '/') {\n            return resv.sync(shims[xid], build_resolve_opts(opts, base));\n        }\n\n        // module -> alt-module shims\n        id = shims[xid];\n    }\n\n    var modules = opts.modules || Object.create(null);\n    var shim_path = modules[id];\n    if (shim_path) {\n        return shim_path;\n    }\n\n    // our browser field resolver\n    // if browser field is an object tho?\n    var full = resv.sync(id, build_resolve_opts(opts, base));\n\n    return (shims) ? shims[full] || full : full;\n};\n\nfunction normalizeBrowserFieldName(browser) {\n    return browser || 'browser';\n}\n\nfunction getReplacements(info, browser) {\n    browser = normalizeBrowserFieldName(browser);\n    var replacements = info[browser] || info.browser;\n\n    // support legacy browserify field for easier migration from legacy\n    // many packages used this field historically\n    if (typeof info.browserify === 'string' && !replacements) {\n        replacements = info.browserify;\n    }\n\n    return replacements;\n}\n\nmodule.exports = resolve;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/browser-resolve/index.js',
          'importMap': {
            'fs': 'fs',
            'path': 'path',
            'resolve': '/home/xyz/Development/webtorrent/node_modules/resolve/index.js',
          },
          'packageName': 'browser-resolve',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/browser-resolve/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/browserify-package-json/index.js': {
        'builtin': [
          'stream.PassThrough',
          'stream.Transform',
        ],
        'moduleRecord': {
          'content': "'use strict'\nconst stream = require('stream')\n\nconst isPackageJSONRegExp = /\\b(?:package.json)$/\nconst isPackageJSON = (filename) => isPackageJSONRegExp.test(filename)\n\nconst arrify = (x) => Array.isArray(x) ? x : [x]\n\nmodule.exports = function (filename, options) {\n  if (!isPackageJSON(filename)) return new stream.PassThrough()\n\n  let data = ''\n  return new stream.Transform({\n    transform (chunk, encoding, callback) {\n      data += chunk.toString('utf8')\n      callback(null)\n    },\n\n    flush (callback) {\n      data = JSON.parse(data)\n\n      let keys = Object.keys(data).filter((key) => !key.startsWith('_'))\n      if (options && options.only !== undefined) keys = arrify(options.only)\n\n      const result = {}\n      for (let key of keys) result[key] = data[key]\n      this.push(JSON.stringify(result, null, 2))\n\n      callback(null)\n    }\n  })\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/browserify-package-json/index.js',
          'importMap': {
            'stream': 'stream',
          },
          'packageName': 'browserify-package-json',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/browserify-package-json/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/browserify/index.js': {
        'builtin': [
          'path.join',
          'path.dirname',
          'path.resolve',
          'path.relative',
          'path.sep',
          'events.EventEmitter',
          'fs.realpath',
        ],
        'globals': {
          '__dirname': 'read',
          'process.cwd': 'read',
          'process.nextTick': 'read',
          'process.platform': 'read',
        },
        'moduleRecord': {
          'content': "var path = require('path');\nvar mdeps = require('module-deps');\nvar depsSort = require('deps-sort');\nvar bpack = require('browser-pack');\nvar insertGlobals = require('insert-module-globals');\nvar syntaxError = require('syntax-error');\n\nvar builtins = require('./lib/builtins.js');\n\nvar splicer = require('labeled-stream-splicer');\nvar through = require('through2');\nvar concat = require('concat-stream');\n\nvar inherits = require('inherits');\nvar EventEmitter = require('events').EventEmitter;\nvar xtend = require('xtend');\nvar isArray = Array.isArray;\nvar defined = require('defined');\nvar has = require('has');\nvar sanitize = require('htmlescape').sanitize;\nvar shasum = require('shasum-object');\n\nvar bresolve = require('browser-resolve');\nvar resolve = require('resolve');\n\nvar readonly = require('read-only-stream');\n\nmodule.exports = Browserify;\ninherits(Browserify, EventEmitter);\n\nvar fs = require('fs');\nvar path = require('path');\nvar cachedPathRelative = require('cached-path-relative');\n\nvar paths = {\n    empty: path.join(__dirname, 'lib/_empty.js')\n};\n\nfunction Browserify (files, opts) {\n    var self = this;\n    if (!(this instanceof Browserify)) return new Browserify(files, opts);\n    if (!opts) opts = {};\n    \n    if (typeof files === 'string' || isArray(files) || isStream(files)) {\n        opts = xtend(opts, { entries: [].concat(opts.entries || [], files) });\n    }\n    else opts = xtend(files, opts);\n\n    if (opts.node) {\n        opts.bare = true;\n        opts.browserField = false;\n    }\n    if (opts.bare) {\n        opts.builtins = false;\n        opts.commondir = false;\n        if (opts.insertGlobalVars === undefined) {\n            opts.insertGlobalVars = {}\n            Object.keys(insertGlobals.vars).forEach(function (name) {\n                if (name !== '__dirname' && name !== '__filename') {\n                    opts.insertGlobalVars[name] = undefined;\n                }\n            })\n        }\n    }\n    \n    self._options = opts;\n    if (opts.noparse) opts.noParse = opts.noparse;\n    \n    if (opts.basedir !== undefined && typeof opts.basedir !== 'string') {\n        throw new Error('opts.basedir must be either undefined or a string.');\n    }\n\n    opts.dedupe = opts.dedupe === false ? false : true;\n\n    self._external = [];\n    self._exclude = [];\n    self._ignore = [];\n    self._expose = {};\n    self._hashes = {};\n    self._pending = 0;\n    self._transformOrder = 0;\n    self._transformPending = 0;\n    self._transforms = [];\n    self._entryOrder = 0;\n    self._ticked = false;\n\n    var browserField = opts.browserField\n    self._bresolve = browserField === false\n        ? function (id, opts, cb) {\n            if (!opts.basedir) opts.basedir = path.dirname(opts.filename)\n            resolve(id, opts, cb)\n        }\n        : typeof browserField === 'string'\n            ? function (id, opts, cb) {\n                opts.browser = browserField\n                bresolve(id, opts, cb)\n            }\n            : bresolve\n    ;\n    self._syntaxCache = {};\n\n    var ignoreTransform = [].concat(opts.ignoreTransform).filter(Boolean);\n    self._filterTransform = function (tr) {\n        if (isArray(tr)) {\n            return ignoreTransform.indexOf(tr[0]) === -1;\n        }\n        return ignoreTransform.indexOf(tr) === -1;\n    };\n\n    self.pipeline = self._createPipeline(opts);\n    \n    [].concat(opts.transform).filter(Boolean).filter(self._filterTransform)\n    .forEach(function (tr) {\n        self.transform(tr);\n    });\n    \n    [].concat(opts.entries).filter(Boolean).forEach(function (file) {\n        self.add(file, { basedir: opts.basedir });\n    });\n    \n    [].concat(opts.require).filter(Boolean).forEach(function (file) {\n        self.require(file, { basedir: opts.basedir });\n    });\n    \n    [].concat(opts.plugin).filter(Boolean).forEach(function (p) {\n        self.plugin(p, { basedir: opts.basedir });\n    });\n}\n\nBrowserify.prototype.require = function (file, opts) {\n    var self = this;\n    if (isArray(file)) {\n        file.forEach(function (x) {\n            if (typeof x === 'object') {\n                self.require(x.file, xtend(opts, x));\n            }\n            else self.require(x, opts);\n        });\n        return this;\n    }\n    \n    if (!opts) opts = {};\n    var basedir = defined(opts.basedir, self._options.basedir, process.cwd());\n    var expose = opts.expose;\n    if (file === expose && /^[\\.]/.test(expose)) {\n        expose = '/' + relativePath(basedir, expose);\n    }\n    if (expose === undefined && this._options.exposeAll) {\n        expose = true;\n    }\n    if (expose === true) {\n        expose = '/' + relativePath(basedir, file);\n    }\n    \n    if (isStream(file)) {\n        self._pending ++;\n        var order = self._entryOrder ++;\n        file.pipe(concat(function (buf) {\n            var filename = opts.file || file.file || path.join(\n                basedir,\n                '_stream_' + order + '.js'\n            );\n            var id = file.id || expose || filename;\n            if (expose || opts.entry === false) {\n                self._expose[id] = filename;\n            }\n            if (!opts.entry && self._options.exports === undefined) {\n                self._bpack.hasExports = true;\n            }\n            var rec = {\n                source: buf.toString('utf8'),\n                entry: defined(opts.entry, false),\n                file: filename,\n                id: id\n            };\n            if (rec.entry) rec.order = order;\n            if (rec.transform === false) rec.transform = false;\n            self.pipeline.write(rec);\n            \n            if (-- self._pending === 0) self.emit('_ready');\n        }));\n        return this;\n    }\n    \n    var row;\n    if (typeof file === 'object') {\n        row = xtend(file, opts);\n    }\n    else if (!opts.entry && isExternalModule(file)) {\n        // external module or builtin\n        row = xtend(opts, { id: expose || file, file: file });\n    }\n    else {\n        row = xtend(opts, { file: path.resolve(basedir, file) });\n    }\n    \n    if (!row.id) {\n        row.id = expose || row.file;\n    }\n    if (expose || !row.entry) {\n        // Make this available to mdeps so that it can assign the value when it\n        // resolves the pathname.\n        row.expose = row.id;\n    }\n    \n    if (opts.external) return self.external(file, opts);\n    if (row.entry === undefined) row.entry = false;\n    \n    if (!row.entry && self._options.exports === undefined) {\n        self._bpack.hasExports = true;\n    }\n    \n    if (row.entry) row.order = self._entryOrder ++;\n    \n    if (opts.transform === false) row.transform = false;\n    self.pipeline.write(row);\n    return self;\n};\n\nBrowserify.prototype.add = function (file, opts) {\n    var self = this;\n    if (!opts) opts = {};\n    if (isArray(file)) {\n        file.forEach(function (x) { self.add(x, opts) });\n        return this;\n    }\n    return this.require(file, xtend({ entry: true, expose: false }, opts));\n};\n\nBrowserify.prototype.external = function (file, opts) {\n    var self = this;\n    if (isArray(file)) {\n        file.forEach(function (f) {\n            if (typeof f === 'object') {\n                self.external(f, xtend(opts, f));\n            }\n            else self.external(f, opts)\n        });\n        return this;\n    }\n    if (file && typeof file === 'object' && typeof file.bundle === 'function') {\n        var b = file;\n        self._pending ++;\n\n        var bdeps = {};\n        var blabels = {};\n\n        b.on('label', function (prev, id) {\n            self._external.push(id);\n\n            if (prev !== id) {\n                blabels[prev] = id;\n                self._external.push(prev);\n            }\n        });\n\n        b.pipeline.get('deps').push(through.obj(function (row, enc, next) {\n            bdeps = xtend(bdeps, row.deps);\n            this.push(row);\n            next();\n        }));\n\n        self.on('dep', function (row) {\n            Object.keys(row.deps).forEach(function (key) {\n                var prev = bdeps[key];\n                if (prev) {\n                    var id = blabels[prev];\n                    if (id) {\n                        row.indexDeps[key] = id;\n                    }\n                }\n            });\n        });\n\n        b.pipeline.get('label').once('end', function () {\n            if (-- self._pending === 0) self.emit('_ready');\n        });\n        return this;\n    }\n    \n    if (!opts) opts = {};\n    var basedir = defined(opts.basedir, process.cwd());\n    this._external.push(file);\n    this._external.push('/' + relativePath(basedir, file));\n    return this;\n};\n\nBrowserify.prototype.exclude = function (file, opts) {\n    if (!opts) opts = {};\n    if (isArray(file)) {\n        var self = this;\n        file.forEach(function(file) {\n            self.exclude(file, opts);\n        });\n        return this;\n    }\n    var basedir = defined(opts.basedir, process.cwd());\n    this._exclude.push(file);\n    this._exclude.push('/' + relativePath(basedir, file));\n    return this;\n};\n\nBrowserify.prototype.ignore = function (file, opts) {\n    if (!opts) opts = {};\n    if (isArray(file)) {\n        var self = this;\n        file.forEach(function(file) {\n            self.ignore(file, opts);\n        });\n        return this;\n    }\n    var basedir = defined(opts.basedir, process.cwd());\n\n    // Handle relative paths\n    if (file[0] === '.') {\n        this._ignore.push(path.resolve(basedir, file));\n    }\n    else {\n        this._ignore.push(file);\n    }\n    return this;\n};\n\nBrowserify.prototype.transform = function (tr, opts) {\n    var self = this;\n    if (typeof opts === 'function' || typeof opts === 'string') {\n        tr = [ opts, tr ];\n    }\n    if (isArray(tr)) {\n        opts = tr[1];\n        tr = tr[0];\n    }\n    \n    //if the bundler is ignoring this transform\n    if (typeof tr === 'string' && !self._filterTransform(tr)) {\n        return this;\n    }\n\n    function resolved () {\n      self._transforms[order] = rec;\n      -- self._pending;\n      if (-- self._transformPending === 0) {\n          self._transforms.forEach(function (transform) {\n            self.pipeline.write(transform);\n          });\n\n          if (self._pending === 0) {\n            self.emit('_ready');\n          }\n      }\n    }\n    \n    if (!opts) opts = {};\n    opts._flags = '_flags' in opts ? opts._flags : self._options;\n    \n    var basedir = defined(opts.basedir, this._options.basedir, process.cwd());\n    var order = self._transformOrder ++;\n    self._pending ++;\n    self._transformPending ++;\n\n    var rec = {\n        transform: tr,\n        options: opts,\n        global: opts.global\n    };\n\n    if (typeof tr === 'string') {\n        var topts = {\n            basedir: basedir,\n            paths: (self._options.paths || []).map(function (p) {\n                return path.resolve(basedir, p);\n            })\n        };\n        resolve(tr, topts, function (err, res) {\n            if (err) return self.emit('error', err);\n            rec.transform = res;\n            resolved();\n        });\n    }\n    else process.nextTick(resolved);\n    return this;\n};\n\nBrowserify.prototype.plugin = function (p, opts) {\n    if (isArray(p)) {\n        opts = p[1];\n        p = p[0];\n    }\n    if (!opts) opts = {};\n    var basedir = defined(opts.basedir, this._options.basedir, process.cwd());\n    if (typeof p === 'function') {\n        p(this, opts);\n    }\n    else {\n        var pfile = resolve.sync(String(p), { basedir: basedir })\n        var f = require(pfile);\n        if (typeof f !== 'function') {\n            throw new Error('plugin ' + p + ' should export a function');\n        }\n        f(this, opts);\n    }\n    return this;\n};\n\nBrowserify.prototype._createPipeline = function (opts) {\n    var self = this;\n    if (!opts) opts = {};\n    this._mdeps = this._createDeps(opts);\n    this._mdeps.on('file', function (file, id) {\n        pipeline.emit('file', file, id);\n        self.emit('file', file, id);\n    });\n    this._mdeps.on('package', function (pkg) {\n        pipeline.emit('package', pkg);\n        self.emit('package', pkg);\n    });\n    this._mdeps.on('transform', function (tr, file) {\n        pipeline.emit('transform', tr, file);\n        self.emit('transform', tr, file);\n    });\n    \n    var dopts = {\n        index: !opts.fullPaths && !opts.exposeAll,\n        dedupe: opts.dedupe,\n        expose: this._expose\n    };\n    this._bpack = bpack(xtend(opts, { raw: true }));\n    \n    var pipeline = splicer.obj([\n        'record', [ this._recorder() ],\n        'deps', [ this._mdeps ],\n        'json', [ this._json() ],\n        'unbom', [ this._unbom() ],\n        'unshebang', [ this._unshebang() ],\n        'syntax', [ this._syntax() ],\n        'sort', [ depsSort(dopts) ],\n        'dedupe', [ this._dedupe() ],\n        'label', [ this._label(opts) ],\n        'emit-deps', [ this._emitDeps() ],\n        'debug', [ this._debug(opts) ],\n        'pack', [ this._bpack ],\n        'wrap', []\n    ]);\n    if (opts.exposeAll) {\n        var basedir = defined(opts.basedir, process.cwd());\n        pipeline.get('deps').push(through.obj(function (row, enc, next) {\n            if (self._external.indexOf(row.id) >= 0) return next();\n            if (self._external.indexOf(row.file) >= 0) return next();\n            \n            if (isAbsolutePath(row.id)) {\n                row.id = '/' + relativePath(basedir, row.file);\n            }\n            Object.keys(row.deps || {}).forEach(function (key) {\n                row.deps[key] = '/' + relativePath(basedir, row.deps[key]);\n            });\n            this.push(row);\n            next();\n        }));\n    }\n    return pipeline;\n};\n\nBrowserify.prototype._createDeps = function (opts) {\n    var self = this;\n    var mopts = xtend(opts);\n    var basedir = defined(opts.basedir, process.cwd());\n\n    // Let mdeps populate these values since it will be resolving file paths\n    // anyway.\n    mopts.expose = this._expose;\n    mopts.extensions = [ '.js', '.json' ].concat(mopts.extensions || []);\n    self._extensions = mopts.extensions;\n\n    mopts.transform = [];\n    mopts.transformKey = defined(opts.transformKey, [ 'browserify', 'transform' ]);\n    mopts.postFilter = function (id, file, pkg) {\n        if (opts.postFilter && !opts.postFilter(id, file, pkg)) return false;\n        if (self._external.indexOf(file) >= 0) return false;\n        if (self._exclude.indexOf(file) >= 0) return false;\n\n        //filter transforms on module dependencies\n        if (pkg && pkg.browserify && pkg.browserify.transform) {\n            //In edge cases it may be a string\n            pkg.browserify.transform = [].concat(pkg.browserify.transform)\n                    .filter(Boolean)\n                    .filter(self._filterTransform);\n        }\n        return true;\n    };\n    mopts.filter = function (id) {\n        if (opts.filter && !opts.filter(id)) return false;\n        if (self._external.indexOf(id) >= 0) return false;\n        if (self._exclude.indexOf(id) >= 0) return false;\n        if (opts.bundleExternal === false && isExternalModule(id)) {\n            return false;\n        }\n        return true;\n    };\n    mopts.resolve = function (id, parent, cb) {\n        if (self._ignore.indexOf(id) >= 0) return cb(null, paths.empty, {});\n        \n        self._bresolve(id, parent, function (err, file, pkg) {\n            if (file && self._ignore.indexOf(file) >= 0) {\n                return cb(null, paths.empty, {});\n            }\n            if (file && self._ignore.length) {\n                var nm = file.replace(/\\\\/g, '/').split('/node_modules/')[1];\n                if (nm) {\n                    nm = nm.split('/')[0];\n                    if (self._ignore.indexOf(nm) >= 0) {\n                        return cb(null, paths.empty, {});\n                    }\n                }\n            }\n            \n            if (file) {\n                var ex = '/' + relativePath(basedir, file);\n                if (self._external.indexOf(ex) >= 0) {\n                    return cb(null, ex);\n                }\n                if (self._exclude.indexOf(ex) >= 0) {\n                    return cb(null, ex);\n                }\n                if (self._ignore.indexOf(ex) >= 0) {\n                    return cb(null, paths.empty, {});\n                }\n            }\n            if (err) cb(err, file, pkg)\n            else if (file) {\n                if (opts.preserveSymlinks && parent.id !== self._mdeps.top.id) {\n                    return cb(err, path.resolve(file), pkg, file)\n                }\n\n                fs.realpath(file, function (err, res) {\n                    cb(err, res, pkg, file);\n                });\n            } else cb(err, null, pkg)\n        });\n    };\n    \n    if (opts.builtins === false) {\n        mopts.modules = {};\n        self._exclude.push.apply(self._exclude, Object.keys(builtins));\n    }\n    else if (opts.builtins && isArray(opts.builtins)) {\n        mopts.modules = {};\n        opts.builtins.forEach(function (key) {\n            mopts.modules[key] = builtins[key];\n        });\n    }\n    else if (opts.builtins && typeof opts.builtins === 'object') {\n        mopts.modules = opts.builtins;\n    }\n    else mopts.modules = xtend(builtins);\n    \n    Object.keys(builtins).forEach(function (key) {\n        if (!has(mopts.modules, key)) self._exclude.push(key);\n    });\n    \n    mopts.globalTransform = [];\n    if (!this._bundled) {\n        this.once('bundle', function () {\n            self.pipeline.write({\n                transform: globalTr,\n                global: true,\n                options: {}\n            });\n        });\n    }\n    \n    var no = [].concat(opts.noParse).filter(Boolean);\n    var absno = no.filter(function(x) {\n        return typeof x === 'string';\n    }).map(function (x) {\n        return path.resolve(basedir, x);\n    });\n    \n    function globalTr (file) {\n        if (opts.detectGlobals === false) return through();\n        \n        if (opts.noParse === true) return through();\n        if (no.indexOf(file) >= 0) return through();\n        if (absno.indexOf(file) >= 0) return through();\n        \n        var parts = file.replace(/\\\\/g, '/').split('/node_modules/');\n        for (var i = 0; i < no.length; i++) {\n            if (typeof no[i] === 'function' && no[i](file)) {\n                return through();\n            }\n            else if (no[i] === parts[parts.length-1].split('/')[0]) {\n                return through();\n            }\n            else if (no[i] === parts[parts.length-1]) {\n                return through();\n            }\n        }\n\n        if (opts.commondir === false && opts.builtins === false) {\n          opts.insertGlobalVars = xtend({\n            __dirname: function(file, basedir) {\n              var dir = path.dirname(path.relative(basedir, file));\n              return 'require(\"path\").join(__dirname,' + dir.split(path.sep).map(JSON.stringify).join(',') + ')';\n            },\n            __filename: function(file, basedir) {\n              var filename = path.relative(basedir, file);\n              return 'require(\"path\").join(__dirname,' + filename.split(path.sep).map(JSON.stringify).join(',') + ')';\n            }\n          }, opts.insertGlobalVars);\n        }\n        \n        var vars = xtend({\n            process: function () { return \"require('_process')\" },\n        }, opts.insertGlobalVars);\n        \n        if (opts.bundleExternal === false) {\n            vars.process = undefined;\n            vars.buffer = undefined;\n        }\n\n        return insertGlobals(file, xtend(opts, {\n            debug: opts.debug,\n            always: opts.insertGlobals,\n            basedir: opts.commondir === false && isArray(opts.builtins)\n                ? '/'\n                : opts.basedir || process.cwd()\n            ,\n            vars: vars\n        }));\n    }\n    return mdeps(mopts);\n};\n\nBrowserify.prototype._recorder = function (opts) {\n    var self = this;\n    var ended = false;\n    this._recorded = [];\n    \n    if (!this._ticked) {\n        process.nextTick(function () {\n            self._ticked = true;\n            self._recorded.forEach(function (row) {\n                stream.push(row);\n            });\n            if (ended) stream.push(null);\n        });\n    }\n    \n    var stream = through.obj(write, end);\n    return stream;\n    \n    function write (row, enc, next) {\n        self._recorded.push(row);\n        if (self._ticked) this.push(row);\n        next();\n    }\n    function end () {\n        ended = true;\n        if (self._ticked) this.push(null);\n    }\n};\n\nBrowserify.prototype._json = function () {\n    return through.obj(function (row, enc, next) {\n        if (/\\.json$/.test(row.file)) {\n            var sanitizedString = sanitize(row.source);\n            try {\n                // check json validity\n                JSON.parse(sanitizedString);\n                row.source = 'module.exports=' + sanitizedString;\n            } catch (err) {\n                err.message = 'While parsing ' + (row.file || row.id) + ': ' + err.message\n                this.emit('error', err);\n                return;\n            }\n        }\n        this.push(row);\n        next();\n    });\n};\n\nBrowserify.prototype._unbom = function () {\n    return through.obj(function (row, enc, next) {\n        if (/^\\ufeff/.test(row.source)) {\n            row.source = row.source.replace(/^\\ufeff/, '');\n        }\n        this.push(row);\n        next();\n    });\n};\n\nBrowserify.prototype._unshebang = function () {\n    return through.obj(function (row, enc, next) {\n        if (/^#!/.test(row.source)) {\n            row.source = row.source.replace(/^#![^\\n]*\\n/, '');\n        }\n        this.push(row);\n        next();\n    });\n};\n\nBrowserify.prototype._syntax = function () {\n    var self = this;\n    return through.obj(function (row, enc, next) {\n        var h = shasum(row.source);\n        if (typeof self._syntaxCache[h] === 'undefined') {\n            var err = syntaxError(row.source, row.file || row.id);\n            if (err) return this.emit('error', err);\n            self._syntaxCache[h] = true;\n        }\n        this.push(row);\n        next();\n    });\n};\n\nBrowserify.prototype._dedupe = function () {\n    return through.obj(function (row, enc, next) {\n        if (!row.dedupeIndex && row.dedupe) {\n            row.source = 'arguments[4]['\n                + JSON.stringify(row.dedupe)\n                + '][0].apply(exports,arguments)'\n            ;\n            row.nomap = true;\n        }\n        else if (row.dedupeIndex) {\n            row.source = 'arguments[4]['\n                + JSON.stringify(row.dedupeIndex)\n                + '][0].apply(exports,arguments)'\n            ;\n            row.nomap = true;\n        }\n        if (row.dedupeIndex && row.indexDeps) {\n            row.indexDeps.dup = row.dedupeIndex;\n        }\n        this.push(row);\n        next();\n    });\n};\n\nBrowserify.prototype._label = function (opts) {\n    var self = this;\n    var basedir = defined(opts.basedir, process.cwd());\n    \n    return through.obj(function (row, enc, next) {\n        var prev = row.id;\n\n        if (self._external.indexOf(row.id) >= 0) return next();\n        if (self._external.indexOf('/' + relativePath(basedir, row.id)) >= 0) {\n            return next();\n        }\n        if (self._external.indexOf(row.file) >= 0) return next();\n        \n        if (row.index) row.id = row.index;\n        \n        self.emit('label', prev, row.id);\n        if (row.indexDeps) row.deps = row.indexDeps || {};\n        \n        Object.keys(row.deps).forEach(function (key) {\n            if (self._expose[key]) {\n                row.deps[key] = key;\n                return;\n            }\n\n            var afile = path.resolve(path.dirname(row.file), key);\n            var rfile = '/' + relativePath(basedir, afile);\n            if (self._external.indexOf(rfile) >= 0) {\n                row.deps[key] = rfile;\n            }\n            if (self._external.indexOf(afile) >= 0) {\n                row.deps[key] = rfile;\n            }\n            if (self._external.indexOf(key) >= 0) {\n                row.deps[key] = key;\n                return;\n            }\n            \n            for (var i = 0; i < self._extensions.length; i++) {\n                var ex = self._extensions[i];\n                if (self._external.indexOf(rfile + ex) >= 0) {\n                    row.deps[key] = rfile + ex;\n                    break;\n                }\n            }\n        });\n        \n        if (row.entry || row.expose) {\n            self._bpack.standaloneModule = row.id;\n        }\n        this.push(row);\n        next();\n    });\n};\n\nBrowserify.prototype._emitDeps = function () {\n    var self = this;\n    return through.obj(function (row, enc, next) {\n        self.emit('dep', row);\n        this.push(row);\n        next();\n    })\n};\n\nBrowserify.prototype._debug = function (opts) {\n    var basedir = defined(opts.basedir, process.cwd());\n    return through.obj(function (row, enc, next) {\n        if (opts.debug) {\n            row.sourceRoot = 'file://localhost';\n            row.sourceFile = relativePath(basedir, row.file);\n        }\n        this.push(row);\n        next();\n    });\n};\n\nBrowserify.prototype.reset = function (opts) {\n    if (!opts) opts = {};\n    var hadExports = this._bpack.hasExports;\n    this.pipeline = this._createPipeline(xtend(opts, this._options));\n    this._bpack.hasExports = hadExports;\n    this._entryOrder = 0;\n    this._bundled = false;\n    this.emit('reset');\n};\n\nBrowserify.prototype.bundle = function (cb) {\n    var self = this;\n    if (cb && typeof cb === 'object') {\n        throw new Error(\n            'bundle() no longer accepts option arguments.\\n'\n            + 'Move all option arguments to the browserify() constructor.'\n        );\n    }\n    if (this._bundled) {\n        var recorded = this._recorded;\n        this.reset();\n        recorded.forEach(function (x) {\n            self.pipeline.write(x);\n        });\n    }\n    var output = readonly(this.pipeline);\n    if (cb) {\n        output.on('error', cb);\n        output.pipe(concat(function (body) {\n            cb(null, body);\n        }));\n    }\n\n    function ready () {\n        self.emit('bundle', output);\n        self.pipeline.end();\n    }\n\n    if (this._pending === 0) ready();\n    else this.once('_ready', ready);\n\n    this._bundled = true;\n    return output;\n};\n\nfunction isStream (s) { return s && typeof s.pipe === 'function' }\nfunction isAbsolutePath (file) {\n    var regexp = process.platform === 'win32' ?\n        /^\\w:/ :\n        /^\\//;\n    return regexp.test(file);\n}\nfunction isExternalModule (file) {\n    var regexp = process.platform === 'win32' ?\n        /^(\\.|\\w:)/ :\n        /^[\\/.]/;\n    return !regexp.test(file);\n}\nfunction relativePath (from, to) {\n    // Replace \\ with / for OS-independent behavior\n    return cachedPathRelative(from, to).replace(/\\\\/g, '/');\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/browserify/index.js',
          'importMap': {
            './lib/builtins.js': '/home/xyz/Development/webtorrent/node_modules/browserify/lib/builtins.js',
            'browser-pack': '/home/xyz/Development/webtorrent/node_modules/browser-pack/index.js',
            'browser-resolve': '/home/xyz/Development/webtorrent/node_modules/browser-resolve/index.js',
            'cached-path-relative': '/home/xyz/Development/webtorrent/node_modules/cached-path-relative/lib/index.js',
            'concat-stream': '/home/xyz/Development/webtorrent/node_modules/concat-stream/index.js',
            'defined': '/home/xyz/Development/webtorrent/node_modules/defined/index.js',
            'deps-sort': '/home/xyz/Development/webtorrent/node_modules/deps-sort/index.js',
            'events': 'events',
            'fs': 'fs',
            'has': '/home/xyz/Development/webtorrent/node_modules/has/src/index.js',
            'htmlescape': '/home/xyz/Development/webtorrent/node_modules/htmlescape/htmlescape.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'insert-module-globals': '/home/xyz/Development/webtorrent/node_modules/insert-module-globals/index.js',
            'labeled-stream-splicer': '/home/xyz/Development/webtorrent/node_modules/labeled-stream-splicer/index.js',
            'module-deps': '/home/xyz/Development/webtorrent/node_modules/module-deps/index.js',
            'path': 'path',
            'read-only-stream': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/index.js',
            'resolve': '/home/xyz/Development/webtorrent/node_modules/resolve/index.js',
            'shasum-object': '/home/xyz/Development/webtorrent/node_modules/shasum-object/index.js',
            'syntax-error': '/home/xyz/Development/webtorrent/node_modules/syntax-error/index.js',
            'through2': '/home/xyz/Development/webtorrent/node_modules/through2/through2.js',
            'xtend': '/home/xyz/Development/webtorrent/node_modules/xtend/immutable.js',
          },
          'packageName': 'browserify',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/browserify/index.js',
          'type': 'js',
        },
        'sesCompat': {
          'dynamicRequires': [
            {
              'node': {
                'loc': {
                  'end': {
                    'column': 30,
                    'line': 396,
                  },
                  'start': {
                    'column': 16,
                    'line': 396,
                  },
                },
              },
            },
          ],
          'primordialMutations': [],
          'strictModeViolations': [],
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/browserify/lib/builtins.js': {
        'moduleRecord': {
          'content': "exports.assert = require.resolve('assert/');\nexports.buffer = require.resolve('buffer/');\nexports.child_process = require.resolve('./_empty.js');\nexports.cluster = require.resolve('./_empty.js');\nexports.console = require.resolve('console-browserify');\nexports.constants = require.resolve('constants-browserify');\nexports.crypto = require.resolve('crypto-browserify');\nexports.dgram = require.resolve('./_empty.js');\nexports.dns = require.resolve('./_empty.js');\nexports.domain = require.resolve('domain-browser');\nexports.events = require.resolve('events/');\nexports.fs = require.resolve('./_empty.js');\nexports.http = require.resolve('stream-http');\nexports.https = require.resolve('https-browserify');\nexports.http2 = require.resolve('./_empty.js');\nexports.inspector = require.resolve('./_empty.js');\nexports.module = require.resolve('./_empty.js');\nexports.net = require.resolve('./_empty.js');\nexports.os = require.resolve('os-browserify/browser.js');\nexports.path = require.resolve('path-browserify');\nexports.perf_hooks = require.resolve('./_empty.js')\nexports.punycode = require.resolve('punycode/');\nexports.querystring = require.resolve('querystring-es3/');\nexports.readline = require.resolve('./_empty.js');\nexports.repl = require.resolve('./_empty.js');\nexports.stream = require.resolve('stream-browserify');\nexports._stream_duplex = require.resolve('readable-stream/duplex.js');\nexports._stream_passthrough = require.resolve('readable-stream/passthrough.js');\nexports._stream_readable = require.resolve('readable-stream/readable.js');\nexports._stream_transform = require.resolve('readable-stream/transform.js');\nexports._stream_writable = require.resolve('readable-stream/writable.js');\nexports.string_decoder = require.resolve('string_decoder/');\nexports.sys = require.resolve('util/util.js');\nexports.timers = require.resolve('timers-browserify');\nexports.tls = require.resolve('./_empty.js');\nexports.tty = require.resolve('tty-browserify');\nexports.url = require.resolve('url/');\nexports.util = require.resolve('util/util.js');\nexports.vm = require.resolve('vm-browserify');\nexports.zlib = require.resolve('browserify-zlib');\nexports._process = require.resolve('process/browser');\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/browserify/lib/builtins.js',
          'importMap': {},
          'packageName': 'browserify',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/browserify/lib/builtins.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/buffer-from/index.js': {
        'globals': {
          'Buffer': 'read',
        },
        'moduleRecord': {
          'content': "var toString = Object.prototype.toString\n\nvar isModern = (\n  typeof Buffer.alloc === 'function' &&\n  typeof Buffer.allocUnsafe === 'function' &&\n  typeof Buffer.from === 'function'\n)\n\nfunction isArrayBuffer (input) {\n  return toString.call(input).slice(8, -1) === 'ArrayBuffer'\n}\n\nfunction fromArrayBuffer (obj, byteOffset, length) {\n  byteOffset >>>= 0\n\n  var maxLength = obj.byteLength - byteOffset\n\n  if (maxLength < 0) {\n    throw new RangeError(\"'offset' is out of bounds\")\n  }\n\n  if (length === undefined) {\n    length = maxLength\n  } else {\n    length >>>= 0\n\n    if (length > maxLength) {\n      throw new RangeError(\"'length' is out of bounds\")\n    }\n  }\n\n  return isModern\n    ? Buffer.from(obj.slice(byteOffset, byteOffset + length))\n    : new Buffer(new Uint8Array(obj.slice(byteOffset, byteOffset + length)))\n}\n\nfunction fromString (string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  return isModern\n    ? Buffer.from(string, encoding)\n    : new Buffer(string, encoding)\n}\n\nfunction bufferFrom (value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (isArrayBuffer(value)) {\n    return fromArrayBuffer(value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(value, encodingOrOffset)\n  }\n\n  return isModern\n    ? Buffer.from(value)\n    : new Buffer(value)\n}\n\nmodule.exports = bufferFrom\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/buffer-from/index.js',
          'importMap': {},
          'packageName': 'buffer-from',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/buffer-from/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/cached-path-relative/lib/index.js': {
        'builtin': [
          'path.relative',
          'path',
        ],
        'globals': {
          'process.cwd': 'read',
        },
        'moduleRecord': {
          'content': "/**\n * Modules\n */\n\nvar path = require('path')\n\n/**\n * Vars\n */\n\nvar relative = path.relative\nvar lastCwd = process.cwd()\nvar cache = Object.create(null)\n\n/**\n * Expose cachedPathRelative\n */\n\nmodule.exports = cachedPathRelative\n\n/**\n * cachedPathRelative\n */\n\nfunction cachedPathRelative (from, to) {\n  // If the current working directory changes, we need\n  // to invalidate the cache\n  var cwd = process.cwd()\n  if (cwd !== lastCwd) {\n    cache = {}\n    lastCwd = cwd\n  }\n\n  if (cache[from] && cache[from][to]) return cache[from][to]\n\n  var result = relative.call(path, from, to)\n\n  cache[from] = cache[from] || {}\n  cache[from][to] = result\n\n  return result\n\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/cached-path-relative/lib/index.js',
          'importMap': {
            'path': 'path',
          },
          'packageName': 'cached-path-relative',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/cached-path-relative/lib/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/combine-source-map/index.js': {
        'builtin': [
          'path.join',
          'path.dirname',
        ],
        'moduleRecord': {
          'content': "'use strict';\n\nvar path            =  require('path');\nvar convert         =  require('convert-source-map');\nvar memoize         =  require('lodash.memoize');\nvar createGenerator =  require('inline-source-map');\nvar pathIsAbsolute  =  require('./lib/path-is-absolute');\nvar mappingsFromMap =  require('./lib/mappings-from-map');\n\nvar protocolRx = /^[a-z]+:\\/\\//;\n\n/**\n * Rebases a relative path in 'sourceFile' to be relative\n * to the path where 'sourceFile' is located.\n *\n * This is necessary before adding relative paths to the\n * new combined map to ensure all paths are relative to their\n * original source.\n *\n * The 'sourceRoot' from the original source map is joined\n * as well to ensure the complete path.\n *\n * Resulting paths that are absolute are passed along directly.\n *\n * @param sourceFile {String} path to the original source file that references a map\n * @param relativeRoot {String} sourceRoot in sourceFile's map to combine with relativePath\n * @param relativePath {String} source path from sourceFile's map\n */\nvar rebaseRelativePath = memoize(function(sourceFile, relativeRoot, relativePath) {\n  if (!relativePath) {\n    return relativePath;\n  }\n\n  // join relative path to root (e.g. 'src/' + 'file.js')\n  var relativeRootedPath = relativeRoot ? path.join(relativeRoot, relativePath) : relativePath;\n  relativeRootedPath = relativeRootedPath.replace(/\\\\/g, '/');\n  sourceFile = sourceFile.replace(/\\\\/g, '/');\n\n  if (sourceFile === relativeRootedPath ||    // same path,\n      pathIsAbsolute(relativeRootedPath) ||   // absolute path, nor\n      protocolRx.test(relativeRootedPath)) {  // absolute protocol need rebasing\n    return relativeRootedPath;\n  }\n\n  // make relative to source file\n  return path.join(path.dirname(sourceFile), relativeRootedPath).replace(/\\\\/g, '/');\n}, function(a, b, c) {\n  return a + '::' + b + '::' + c;\n});\n\nfunction resolveMap(source) {\n  var gen = convert.fromSource(source);\n  return gen ? gen.toObject() : null;\n}\n\nfunction hasInlinedSource(existingMap) {\n  return existingMap.sourcesContent && !!existingMap.sourcesContent[0];\n}\n\nfunction Combiner(file, sourceRoot) {\n  // since we include the original code in the map sourceRoot actually not needed\n  this.generator = createGenerator({ file: file || 'generated.js', sourceRoot: sourceRoot });\n}\n\nCombiner.prototype._addGeneratedMap = function (sourceFile, source, offset) {\n  this.generator.addGeneratedMappings(sourceFile, source, offset);\n  this.generator.addSourceContent(sourceFile, source);\n  return this;\n};\n\nCombiner.prototype._addExistingMap = function (sourceFile, source, existingMap, offset) {\n  var mappings = mappingsFromMap(existingMap);\n\n  // add all of the sources from the map\n  for (var i = 0, len = existingMap.sources.length; i < len; i++) {\n    if (!existingMap.sourcesContent) continue;\n\n    this.generator.addSourceContent(\n      rebaseRelativePath(sourceFile, existingMap.sourceRoot, existingMap.sources[i]),\n      existingMap.sourcesContent[i]);\n  }\n\n  // add the mappings, preserving the original mapping 'source'\n  mappings.forEach(function(mapping) {\n    // Add the mappings one at a time because 'inline-source-map' doesn't handle\n    // mapping source filenames. The mapping.source already takes sourceRoot into account\n    // per the SMConsumer.eachMapping function, so pass null for the root here.\n    this.generator.addMappings(\n      rebaseRelativePath(sourceFile, null, mapping.source), [mapping], offset);\n  }, this);\n\n  return this;\n};\n\n/**\n * Adds map to underlying source map.\n * If source contains a source map comment that has the source of the original file inlined it will offset these\n * mappings and include them.\n * If no source map comment is found or it has no source inlined, mappings for the file will be generated and included\n *\n * @name addMap\n * @function\n * @param opts {Object} { sourceFile: {String}, source: {String} }\n * @param offset {Object} { line: {Number}, column: {Number} }\n */\nCombiner.prototype.addFile = function (opts, offset) {\n\n  offset = offset || {};\n  if (!offset.hasOwnProperty('line'))  offset.line    =  0;\n  if (!offset.hasOwnProperty('column')) offset.column =  0;\n\n  var existingMap = resolveMap(opts.source);\n\n  return existingMap && hasInlinedSource(existingMap)\n    ? this._addExistingMap(opts.sourceFile, opts.source, existingMap, offset)\n    : this._addGeneratedMap(opts.sourceFile, opts.source, offset);\n};\n\n/**\n* @name base64\n* @function\n* @return {String} base64 encoded combined source map\n*/\nCombiner.prototype.base64 = function () {\n  return this.generator.base64Encode();\n};\n\n/**\n * @name comment\n * @function\n * @return {String} base64 encoded sourceMappingUrl comment of the combined source map\n */\nCombiner.prototype.comment = function () {\n  return this.generator.inlineMappingUrl();\n};\n\n/**\n * @name create\n * @function\n * @param file {String} optional name of the generated file\n * @param sourceRoot {String} optional sourceRoot of the map to be generated\n * @return {Object} Combiner instance to which source maps can be added and later combined\n */\nexports.create = function (file, sourceRoot) { return new Combiner(file, sourceRoot); };\n\n/**\n * @name removeComments\n * @function\n * @param src\n * @return {String} src with all sourceMappingUrl comments removed\n */\nexports.removeComments = function (src) {\n  if (!src.replace) return src;\n  return src.replace(convert.commentRegex, '').replace(convert.mapFileCommentRegex, '');\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/index.js',
          'importMap': {
            './lib/mappings-from-map': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/lib/mappings-from-map.js',
            './lib/path-is-absolute': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/lib/path-is-absolute.js',
            'convert-source-map': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/node_modules/convert-source-map/index.js',
            'inline-source-map': '/home/xyz/Development/webtorrent/node_modules/inline-source-map/index.js',
            'lodash.memoize': '/home/xyz/Development/webtorrent/node_modules/lodash.memoize/index.js',
            'path': 'path',
          },
          'packageName': 'combine-source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/combine-source-map/lib/mappings-from-map.js': {
        'moduleRecord': {
          'content': "var SMConsumer  =  require('source-map').SourceMapConsumer;\n\n/**\n * @name mappingsFromMap\n * @function\n * @param map {Object} the JSON.parse()'ed map\n * @return {Array} array of mappings\n */\nmodule.exports = function (map) {\n  var consumer = new SMConsumer(map);\n  var mappings = [];\n\n  consumer.eachMapping(function (mapping) {\n    // only set source if we have original position to handle edgecase (see inline-source-map tests)\n    mappings.push({\n      original: mapping.originalColumn != null ? {\n        column: mapping.originalColumn\n      , line: mapping.originalLine\n      } : undefined\n    , generated: {\n        column: mapping.generatedColumn\n      , line: mapping.generatedLine\n      }\n    , source: mapping.originalColumn != null ? mapping.source : undefined\n    , name: mapping.name\n    });\n  });\n\n  return mappings;\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/lib/mappings-from-map.js',
          'importMap': {
            'source-map': '/home/xyz/Development/webtorrent/node_modules/source-map/source-map.js',
          },
          'packageName': 'combine-source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/lib/mappings-from-map.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/combine-source-map/lib/path-is-absolute.js': {
        'globals': {
          'process.platform': 'read',
        },
        'moduleRecord': {
          'content': "'use strict';\n\nfunction posix(path) {\n\treturn path.charAt(0) === '/';\n};\n\nfunction win32(path) {\n\t// https://github.com/joyent/node/blob/b3fcc245fb25539909ef1d5eaa01dbf92e168633/lib/path.js#L56\n\tvar splitDeviceRe = /^([a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/]+[^\\\\\\/]+)?([\\\\\\/])?([\\s\\S]*?)$/;\n\tvar result = splitDeviceRe.exec(path);\n\tvar device = result[1] || '';\n\tvar isUnc = !!device && device.charAt(1) !== ':';\n\n\t// UNC paths are always absolute\n\treturn !!result[2] || isUnc;\n};\n\nmodule.exports = process.platform === 'win32' ? win32 : posix;\nmodule.exports.posix = posix;\nmodule.exports.win32 = win32;",
          'file': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/lib/path-is-absolute.js',
          'importMap': {},
          'packageName': 'combine-source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/lib/path-is-absolute.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/combine-source-map/node_modules/convert-source-map/index.js': {
        'builtin': [
          'fs.readFileSync',
          'path.join',
        ],
        'globals': {
          'Buffer': 'read',
        },
        'moduleRecord': {
          'content': "'use strict';\nvar fs = require('fs');\nvar path = require('path');\n\nvar commentRx = /^\\s*\\/(?:\\/|\\*)[@#]\\s+sourceMappingURL=data:(?:application|text)\\/json;(?:charset[:=]\\S+;)?base64,(.*)$/mg;\nvar mapFileCommentRx =\n  //Example (Extra space between slashes added to solve Safari bug. Exclude space in production):\n  //     / /# sourceMappingURL=foo.js.map           /*# sourceMappingURL=foo.js.map */\n  /(?:\\/\\/[@#][ \\t]+sourceMappingURL=([^\\s'\"]+?)[ \\t]*$)|(?:\\/\\*[@#][ \\t]+sourceMappingURL=([^\\*]+?)[ \\t]*(?:\\*\\/){1}[ \\t]*$)/mg\n\nfunction decodeBase64(base64) {\n  return new Buffer(base64, 'base64').toString();\n}\n\nfunction stripComment(sm) {\n  return sm.split(',').pop();\n}\n\nfunction readFromFileMap(sm, dir) {\n  // NOTE: this will only work on the server since it attempts to read the map file\n\n  var r = mapFileCommentRx.exec(sm);\n  mapFileCommentRx.lastIndex = 0;\n\n  // for some odd reason //# .. captures in 1 and /* .. */ in 2\n  var filename = r[1] || r[2];\n  var filepath = path.join(dir, filename);\n\n  try {\n    return fs.readFileSync(filepath, 'utf8');\n  } catch (e) {\n    throw new Error('An error occurred while trying to read the map file at ' + filepath + '\\n' + e);\n  }\n}\n\nfunction Converter (sm, opts) {\n  opts = opts || {};\n\n  if (opts.isFileComment) sm = readFromFileMap(sm, opts.commentFileDir);\n  if (opts.hasComment) sm = stripComment(sm);\n  if (opts.isEncoded) sm = decodeBase64(sm);\n  if (opts.isJSON || opts.isEncoded) sm = JSON.parse(sm);\n\n  this.sourcemap = sm;\n}\n\nfunction convertFromLargeSource(content){\n  var lines = content.split('\\n');\n  var line;\n  // find first line which contains a source map starting at end of content\n  for (var i = lines.length - 1; i > 0; i--) {\n    line = lines[i]\n    if (~line.indexOf('sourceMappingURL=data:')) return exports.fromComment(line);\n  }\n}\n\nConverter.prototype.toJSON = function (space) {\n  return JSON.stringify(this.sourcemap, null, space);\n};\n\nConverter.prototype.toBase64 = function () {\n  var json = this.toJSON();\n  return new Buffer(json).toString('base64');\n};\n\nConverter.prototype.toComment = function (options) {\n  var base64 = this.toBase64();\n  var data = 'sourceMappingURL=data:application/json;base64,' + base64;\n  return options && options.multiline ? '/*# ' + data + ' */' : '//# ' + data;\n};\n\n// returns copy instead of original\nConverter.prototype.toObject = function () {\n  return JSON.parse(this.toJSON());\n};\n\nConverter.prototype.addProperty = function (key, value) {\n  if (this.sourcemap.hasOwnProperty(key)) throw new Error('property %s already exists on the sourcemap, use set property instead');\n  return this.setProperty(key, value);\n};\n\nConverter.prototype.setProperty = function (key, value) {\n  this.sourcemap[key] = value;\n  return this;\n};\n\nConverter.prototype.getProperty = function (key) {\n  return this.sourcemap[key];\n};\n\nexports.fromObject = function (obj) {\n  return new Converter(obj);\n};\n\nexports.fromJSON = function (json) {\n  return new Converter(json, { isJSON: true });\n};\n\nexports.fromBase64 = function (base64) {\n  return new Converter(base64, { isEncoded: true });\n};\n\nexports.fromComment = function (comment) {\n  comment = comment\n    .replace(/^\\/\\*/g, '//')\n    .replace(/\\*\\/$/g, '');\n\n  return new Converter(comment, { isEncoded: true, hasComment: true });\n};\n\nexports.fromMapFileComment = function (comment, dir) {\n  return new Converter(comment, { commentFileDir: dir, isFileComment: true, isJSON: true });\n};\n\n// Finds last sourcemap comment in file or returns null if none was found\nexports.fromSource = function (content, largeSource) {\n  if (largeSource) {\n    var res = convertFromLargeSource(content);\n    return res ? res : null;\n  }\n\n  var m = content.match(commentRx);\n  commentRx.lastIndex = 0;\n  return m ? exports.fromComment(m.pop()) : null;\n};\n\n// Finds last sourcemap comment in file or returns null if none was found\nexports.fromMapFileSource = function (content, dir) {\n  var m = content.match(mapFileCommentRx);\n  mapFileCommentRx.lastIndex = 0;\n  return m ? exports.fromMapFileComment(m.pop(), dir) : null;\n};\n\nexports.removeComments = function (src) {\n  commentRx.lastIndex = 0;\n  return src.replace(commentRx, '');\n};\n\nexports.removeMapFileComments = function (src) {\n  mapFileCommentRx.lastIndex = 0;\n  return src.replace(mapFileCommentRx, '');\n};\n\nObject.defineProperty(exports, 'commentRegex', {\n  get: function getCommentRegex () {\n    commentRx.lastIndex = 0;\n    return commentRx;\n  }\n});\n\nObject.defineProperty(exports, 'mapFileCommentRegex', {\n  get: function getMapFileCommentRegex () {\n    mapFileCommentRx.lastIndex = 0;\n    return mapFileCommentRx;\n  }\n});\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/node_modules/convert-source-map/index.js',
          'importMap': {
            'fs': 'fs',
            'path': 'path',
          },
          'packageName': 'convert-source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/node_modules/convert-source-map/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/index.js': {
        'globals': {
          'Buffer.concat': 'read',
          'Buffer.isBuffer': 'read',
        },
        'moduleRecord': {
          'content': "var Writable = require('readable-stream').Writable\nvar inherits = require('inherits')\nvar bufferFrom = require('buffer-from')\n\nif (typeof Uint8Array === 'undefined') {\n  var U8 = require('typedarray').Uint8Array\n} else {\n  var U8 = Uint8Array\n}\n\nfunction ConcatStream(opts, cb) {\n  if (!(this instanceof ConcatStream)) return new ConcatStream(opts, cb)\n\n  if (typeof opts === 'function') {\n    cb = opts\n    opts = {}\n  }\n  if (!opts) opts = {}\n\n  var encoding = opts.encoding\n  var shouldInferEncoding = false\n\n  if (!encoding) {\n    shouldInferEncoding = true\n  } else {\n    encoding =  String(encoding).toLowerCase()\n    if (encoding === 'u8' || encoding === 'uint8') {\n      encoding = 'uint8array'\n    }\n  }\n\n  Writable.call(this, { objectMode: true })\n\n  this.encoding = encoding\n  this.shouldInferEncoding = shouldInferEncoding\n\n  if (cb) this.on('finish', function () { cb(this.getBody()) })\n  this.body = []\n}\n\nmodule.exports = ConcatStream\ninherits(ConcatStream, Writable)\n\nConcatStream.prototype._write = function(chunk, enc, next) {\n  this.body.push(chunk)\n  next()\n}\n\nConcatStream.prototype.inferEncoding = function (buff) {\n  var firstBuffer = buff === undefined ? this.body[0] : buff;\n  if (Buffer.isBuffer(firstBuffer)) return 'buffer'\n  if (typeof Uint8Array !== 'undefined' && firstBuffer instanceof Uint8Array) return 'uint8array'\n  if (Array.isArray(firstBuffer)) return 'array'\n  if (typeof firstBuffer === 'string') return 'string'\n  if (Object.prototype.toString.call(firstBuffer) === \"[object Object]\") return 'object'\n  return 'buffer'\n}\n\nConcatStream.prototype.getBody = function () {\n  if (!this.encoding && this.body.length === 0) return []\n  if (this.shouldInferEncoding) this.encoding = this.inferEncoding()\n  if (this.encoding === 'array') return arrayConcat(this.body)\n  if (this.encoding === 'string') return stringConcat(this.body)\n  if (this.encoding === 'buffer') return bufferConcat(this.body)\n  if (this.encoding === 'uint8array') return u8Concat(this.body)\n  return this.body\n}\n\nvar isArray = Array.isArray || function (arr) {\n  return Object.prototype.toString.call(arr) == '[object Array]'\n}\n\nfunction isArrayish (arr) {\n  return /Array\\]$/.test(Object.prototype.toString.call(arr))\n}\n\nfunction isBufferish (p) {\n  return typeof p === 'string' || isArrayish(p) || (p && typeof p.subarray === 'function')\n}\n\nfunction stringConcat (parts) {\n  var strings = []\n  var needsToString = false\n  for (var i = 0; i < parts.length; i++) {\n    var p = parts[i]\n    if (typeof p === 'string') {\n      strings.push(p)\n    } else if (Buffer.isBuffer(p)) {\n      strings.push(p)\n    } else if (isBufferish(p)) {\n      strings.push(bufferFrom(p))\n    } else {\n      strings.push(bufferFrom(String(p)))\n    }\n  }\n  if (Buffer.isBuffer(parts[0])) {\n    strings = Buffer.concat(strings)\n    strings = strings.toString('utf8')\n  } else {\n    strings = strings.join('')\n  }\n  return strings\n}\n\nfunction bufferConcat (parts) {\n  var bufs = []\n  for (var i = 0; i < parts.length; i++) {\n    var p = parts[i]\n    if (Buffer.isBuffer(p)) {\n      bufs.push(p)\n    } else if (isBufferish(p)) {\n      bufs.push(bufferFrom(p))\n    } else {\n      bufs.push(bufferFrom(String(p)))\n    }\n  }\n  return Buffer.concat(bufs)\n}\n\nfunction arrayConcat (parts) {\n  var res = []\n  for (var i = 0; i < parts.length; i++) {\n    res.push.apply(res, parts[i])\n  }\n  return res\n}\n\nfunction u8Concat (parts) {\n  var len = 0\n  for (var i = 0; i < parts.length; i++) {\n    if (typeof parts[i] === 'string') {\n      parts[i] = bufferFrom(parts[i])\n    }\n    len += parts[i].length\n  }\n  var u8 = new U8(len)\n  for (var i = 0, offset = 0; i < parts.length; i++) {\n    var part = parts[i]\n    for (var j = 0; j < part.length; j++) {\n      u8[offset++] = part[j]\n    }\n  }\n  return u8\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/index.js',
          'importMap': {
            'buffer-from': '/home/xyz/Development/webtorrent/node_modules/buffer-from/index.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'readable-stream': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/readable.js',
            'typedarray': '/home/xyz/Development/webtorrent/node_modules/typedarray/index.js',
          },
          'packageName': 'concat-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_duplex.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_duplex.js',
          'importMap': {
            './_stream_readable': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_readable.js',
            './_stream_writable': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_writable.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_duplex.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_passthrough.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_passthrough.js',
          'importMap': {
            './_stream_transform': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_transform.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_passthrough.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_readable.js': {
        'builtin': [
          'events.EventEmitter',
          'util',
          'util.debuglog',
        ],
        'globals': {
          'process.stderr': 'read',
          'process.stdout': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar destroyImpl = require('./internal/streams/destroy');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_readable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/BufferList': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/BufferList.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'events': 'events',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'isarray': '/home/xyz/Development/webtorrent/node_modules/isarray/index.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/safe-buffer/index.js',
            'string_decoder/': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/string_decoder/lib/string_decoder.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_transform.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_transform.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_duplex.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_transform.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_writable.js': {
        'globals': {
          'process.browser': 'read',
          'process.version.slice': 'read',
          'setImmediate': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_writable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/safe-buffer/index.js',
            'util-deprecate': '/home/xyz/Development/webtorrent/node_modules/util-deprecate/node.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_writable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/BufferList.js': {
        'builtin': [
          'util',
          'util.inspect',
          'util.inspect.custom',
        ],
        'moduleRecord': {
          'content': "'use strict';\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = require('safe-buffer').Buffer;\nvar util = require('util');\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/safe-buffer/index.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/destroy.js': {
        'moduleRecord': {
          'content': "'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'importMap': {
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/stream.js': {
        'builtin': [
          'stream',
        ],
        'moduleRecord': {
          'content': "module.exports = require('stream');\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/stream.js',
          'importMap': {
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/stream.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/readable.js': {
        'builtin': [
          'stream',
          'stream.Readable',
          'stream.Writable',
          'stream.Duplex',
          'stream.Transform',
          'stream.PassThrough',
        ],
        'globals': {
          'process.env.READABLE_STREAM': 'read',
        },
        'moduleRecord': {
          'content': "var Stream = require('stream');\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n  exports = module.exports = Stream.Readable;\n  exports.Readable = Stream.Readable;\n  exports.Writable = Stream.Writable;\n  exports.Duplex = Stream.Duplex;\n  exports.Transform = Stream.Transform;\n  exports.PassThrough = Stream.PassThrough;\n  exports.Stream = Stream;\n} else {\n  exports = module.exports = require('./lib/_stream_readable.js');\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = require('./lib/_stream_writable.js');\n  exports.Duplex = require('./lib/_stream_duplex.js');\n  exports.Transform = require('./lib/_stream_transform.js');\n  exports.PassThrough = require('./lib/_stream_passthrough.js');\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/readable.js',
          'importMap': {
            './lib/_stream_duplex.js': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_duplex.js',
            './lib/_stream_passthrough.js': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_passthrough.js',
            './lib/_stream_readable.js': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_readable.js',
            './lib/_stream_transform.js': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_transform.js',
            './lib/_stream_writable.js': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_writable.js',
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/readable-stream/readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/safe-buffer/index.js': {
        'builtin': [
          'buffer.Buffer',
          'buffer',
          'buffer.SlowBuffer',
        ],
        'moduleRecord': {
          'content': "/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/safe-buffer/index.js',
          'importMap': {
            'buffer': 'buffer',
          },
          'packageName': 'safe-buffer',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/safe-buffer/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/string_decoder/lib/string_decoder.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/string_decoder/lib/string_decoder.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/safe-buffer/index.js',
          },
          'packageName': 'string_decoder',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/concat-stream/node_modules/string_decoder/lib/string_decoder.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js': {
        'globals': {
          'Buffer.isBuffer': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
          'importMap': {},
          'packageName': 'core-util-is',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/dash-ast/index.js': {
        'builtin': [
          'assert',
        ],
        'moduleRecord': {
          'content': "var assert = require('assert')\n\nmodule.exports = dashAst\n\n/**\n * Call `cb` on each node in `ast`. If `cb` is an object, `cb.enter` is called before processing a Node's children,\n * and `cb.leave` is called after processing a Node's children.\n */\nfunction dashAst (ast, cb) {\n  assert(ast && typeof ast === 'object' && typeof ast.type === 'string',\n    'dash-ast: ast must be an AST node')\n\n  if (typeof cb === 'object') {\n    assert(typeof cb.enter === 'function' || typeof cb.leave === 'function',\n      'dash-ast: visitor must be an object with enter/leave functions')\n\n    walk(ast, null, cb.enter || undefined, cb.leave || undefined)\n  } else {\n    assert(cb && typeof cb === 'function',\n      'dash-ast: callback must be a function')\n\n    walk(ast, null, cb, undefined)\n  }\n}\n\n/**\n * Call `cb` on each node in `ast`. Each node will have a `.parent` property.\n */\ndashAst.withParent = function dashAstParent (ast, cb) {\n  assert(ast && typeof ast === 'object' && typeof ast.type === 'string',\n    'dash-ast.withParent: ast must be an AST node')\n\n  if (typeof cb === 'object') {\n    assert(typeof cb.enter === 'function' || typeof cb.leave === 'function',\n      'dash-ast.withParent: visitor must be an object with enter/leave functions')\n\n    var enter = cb.enter\n    var leave = cb.leave\n    walk(ast, null, function (node, parent) {\n      node.parent = parent\n      if (enter !== undefined) return enter(node)\n    }, leave ? function (node) { leave(node) } : undefined)\n  } else {\n    assert(cb && typeof cb === 'function',\n      'dash-ast.withParent: callback must be a function')\n\n    walk(ast, null, function (node, parent) {\n      node.parent = parent\n      return cb(node)\n    }, undefined)\n  }\n}\n\nfunction walk (node, parent, enter, leave) {\n  var cont = enter !== undefined ? enter(node, parent) : undefined\n  if (cont === false) return\n\n  for (var k in node) {\n    if (has(node, k)) {\n      if (k === 'parent') continue\n      if (isNode(node[k])) {\n        walk(node[k], node, enter, leave)\n      } else if (Array.isArray(node[k])) {\n        walkArray(node[k], node, enter, leave)\n      }\n    }\n  }\n\n  if (leave !== undefined) leave(node, parent)\n}\n\nfunction walkArray (nodes, parent, enter, leave) {\n  for (var i = 0; i < nodes.length; i++) {\n    if (isNode(nodes[i])) walk(nodes[i], parent, enter, leave)\n  }\n}\n\nfunction isNode (node) {\n  return typeof node === 'object' && node && typeof node.type === 'string'\n}\n\nfunction has (obj, prop) {\n  return Object.prototype.hasOwnProperty.call(obj, prop)\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/dash-ast/index.js',
          'importMap': {
            'assert': 'assert',
          },
          'packageName': 'dash-ast',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/dash-ast/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/defined/index.js': {
        'moduleRecord': {
          'content': 'module.exports = function () {\n    for (var i = 0; i < arguments.length; i++) {\n        if (arguments[i] !== undefined) return arguments[i];\n    }\n};\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/defined/index.js',
          'importMap': {},
          'packageName': 'defined',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/defined/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/deps-sort/index.js': {
        'moduleRecord': {
          'content': "var through = require('through2');\nvar shasum = require('shasum-object');\n\nmodule.exports = function (opts) {\n    if (!opts) opts = {};\n    var rows = [];\n    return through.obj(write, end);\n    \n    function write (row, enc, next) { rows.push(row); next() }\n    \n    function end () {\n        var tr = this;\n        rows.sort(cmp);\n        sorter(rows, tr, opts);\n    }\n};\n\nfunction sorter (rows, tr, opts) {\n    var expose = opts.expose || {};\n    if (Array.isArray(expose)) {\n        expose = expose.reduce(function (acc, key) {\n            acc[key] = true;\n            return acc;\n        }, {});\n    }\n    \n    var hashes = {}, deduped = {};\n    var sameDeps = depCmp();\n    \n    if (opts.dedupe) {\n        rows.forEach(function (row) {\n            var h = shasum(row.source);\n            sameDeps.add(row, h);\n            if (hashes[h]) {\n                hashes[h].push(row);\n            } else {\n                hashes[h] = [row];\n            }\n        });\n        Object.keys(hashes).forEach(function (h) {\n            var rows = hashes[h];\n            while (rows.length > 1) {\n                var row = rows.pop();\n                row.dedupe = rows[0].id;\n                row.sameDeps = sameDeps.cmp(rows[0].deps, row.deps);\n                deduped[row.id] = rows[0].id;\n            }\n        });\n    }\n    \n    if (opts.index) {\n        var index = {};\n        var offset = 0;\n        rows.forEach(function (row, ix) {\n            if (has(expose, row.id)) {\n                row.index = row.id;\n                offset ++;\n                if (expose[row.id] !== true) {\n                    index[expose[row.id]] = row.index;\n                }\n            }\n            else {\n                row.index = ix + 1 - offset;\n            }\n            index[row.id] = row.index;\n        });\n        rows.forEach(function (row) {\n            row.indexDeps = {};\n            Object.keys(row.deps).forEach(function (key) {\n                var id = row.deps[key];\n                row.indexDeps[key] = index[id];\n            });\n            if (row.dedupe) {\n                row.dedupeIndex = index[row.dedupe];\n            }\n            tr.push(row);\n        });\n    }\n    else {\n        rows.forEach(function (row) { tr.push(row) });\n    }\n    tr.push(null);\n}\n\nfunction cmp (a, b) {\n    return a.id + a.hash < b.id + b.hash ? -1 : 1;\n}\n\nfunction has (obj, key) {\n    return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\nfunction depCmp () {\n    var deps = {}, hashes = {};\n    return { add: add, cmp: cmp }\n    \n    function add (row, hash) {\n        deps[row.id] = row.deps;\n        hashes[row.id] = hash;\n    }\n    function cmp (a, b, limit) {\n        if (!a && !b) return true;\n        if (!a || !b) return false;\n        \n        var keys = Object.keys(a);\n        if (keys.length !== Object.keys(b).length) return false;\n\n        for (var i = 0; i < keys.length; i++) {\n            var k = keys[i], ka = a[k], kb = b[k];\n            var ha = hashes[ka];\n            var hb = hashes[kb];\n            var da = deps[ka];\n            var db = deps[kb];\n\n            if (ka === kb) continue;\n            if (ha !== hb || (!limit && !cmp(da, db, 1))) {\n                return false;\n            }\n        }\n        return true;\n    }\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/deps-sort/index.js',
          'importMap': {
            'shasum-object': '/home/xyz/Development/webtorrent/node_modules/shasum-object/index.js',
            'through2': '/home/xyz/Development/webtorrent/node_modules/through2/through2.js',
          },
          'packageName': 'deps-sort',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/deps-sort/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/detective/index.js': {
        'moduleRecord': {
          'content': "var acorn = require('acorn-node');\nvar walk = require('acorn-node/walk');\nvar defined = require('defined');\n\nvar requireRe = /\\brequire\\b/;\n\nfunction parse (src, opts) {\n    if (!opts) opts = {};\n    var acornOpts = {\n        ranges: defined(opts.ranges, opts.range),\n        locations: defined(opts.locations, opts.loc),\n        allowReserved: defined(opts.allowReserved, true),\n        allowImportExportEverywhere: defined(opts.allowImportExportEverywhere, false)\n    };\n\n    // Use acorn-node's defaults for the rest.\n    if (opts.ecmaVersion != null) acornOpts.ecmaVersion = opts.ecmaVersion;\n    if (opts.sourceType != null) acornOpts.sourceType = opts.sourceType;\n    if (opts.allowHashBang != null) acornOpts.allowHashBang = opts.allowHashBang;\n    if (opts.allowReturnOutsideFunction != null) acornOpts.allowReturnOutsideFunction = opts.allowReturnOutsideFunction;\n\n    return acorn.parse(src, acornOpts);\n}\n\nvar exports = module.exports = function (src, opts) {\n    return exports.find(src, opts).strings;\n};\n\nexports.find = function (src, opts) {\n    if (!opts) opts = {};\n    \n    var word = opts.word === undefined ? 'require' : opts.word;\n    if (typeof src !== 'string') src = String(src);\n    \n    var isRequire = opts.isRequire || function (node) {\n        return node.callee.type === 'Identifier'\n            && node.callee.name === word\n        ;\n    };\n    \n    var modules = { strings : [], expressions : [] };\n    if (opts.nodes) modules.nodes = [];\n    \n    var wordRe = word === 'require' ? requireRe : RegExp('\\\\b' + word + '\\\\b');\n    if (!wordRe.test(src)) return modules;\n    \n    var ast = parse(src, opts.parse);\n    \n    function visit(node, st, c) {\n        var hasRequire = wordRe.test(src.slice(node.start, node.end));\n        if (!hasRequire) return;\n        walk.base[node.type](node, st, c);\n        if (node.type !== 'CallExpression') return;\n        if (isRequire(node)) {\n            if (node.arguments.length) {\n                var arg = node.arguments[0];\n                if (arg.type === 'Literal') {\n                    modules.strings.push(arg.value);\n                }\n                else if (arg.type === 'TemplateLiteral'\n                        && arg.quasis.length === 1\n                        && arg.expressions.length === 0) {\n\n                    modules.strings.push(arg.quasis[0].value.raw);\n                }\n                else {\n                    modules.expressions.push(src.slice(arg.start, arg.end));\n                }\n            }\n            if (opts.nodes) modules.nodes.push(node);\n        }\n    }\n    \n    walk.recursive(ast, null, {\n        Statement: visit,\n        Expression: visit\n    });\n    \n    return modules;\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/detective/index.js',
          'importMap': {
            'acorn-node': '/home/xyz/Development/webtorrent/node_modules/acorn-node/index.js',
            'acorn-node/walk': '/home/xyz/Development/webtorrent/node_modules/acorn-node/walk.js',
            'defined': '/home/xyz/Development/webtorrent/node_modules/defined/index.js',
          },
          'packageName': 'detective',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/detective/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/index.js': {
        'moduleRecord': {
          'content': '"use strict";\n\nvar stream = require("readable-stream");\n\nfunction DuplexWrapper(options, writable, readable) {\n  if (typeof readable === "undefined") {\n    readable = writable;\n    writable = options;\n    options = null;\n  }\n\n  stream.Duplex.call(this, options);\n\n  if (typeof readable.read !== "function") {\n    readable = (new stream.Readable(options)).wrap(readable);\n  }\n\n  this._writable = writable;\n  this._readable = readable;\n  this._waiting = false;\n\n  var self = this;\n\n  writable.once("finish", function() {\n    self.end();\n  });\n\n  this.once("finish", function() {\n    writable.end();\n  });\n\n  readable.on("readable", function() {\n    if (self._waiting) {\n      self._waiting = false;\n      self._read();\n    }\n  });\n\n  readable.once("end", function() {\n    self.push(null);\n  });\n\n  if (!options || typeof options.bubbleErrors === "undefined" || options.bubbleErrors) {\n    writable.on("error", function(err) {\n      self.emit("error", err);\n    });\n\n    readable.on("error", function(err) {\n      self.emit("error", err);\n    });\n  }\n}\n\nDuplexWrapper.prototype = Object.create(stream.Duplex.prototype, {constructor: {value: DuplexWrapper}});\n\nDuplexWrapper.prototype._write = function _write(input, encoding, done) {\n  this._writable.write(input, encoding, done);\n};\n\nDuplexWrapper.prototype._read = function _read() {\n  var buf;\n  var reads = 0;\n  while ((buf = this._readable.read()) !== null) {\n    this.push(buf);\n    reads++;\n  }\n  if (reads === 0) {\n    this._waiting = true;\n  }\n};\n\nmodule.exports = function duplex2(options, writable, readable) {\n  return new DuplexWrapper(options, writable, readable);\n};\n\nmodule.exports.DuplexWrapper = DuplexWrapper;\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/index.js',
          'importMap': {
            'readable-stream': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/readable.js',
          },
          'packageName': 'duplexer2',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_duplex.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_duplex.js',
          'importMap': {
            './_stream_readable': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_readable.js',
            './_stream_writable': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_writable.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_duplex.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_passthrough.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_passthrough.js',
          'importMap': {
            './_stream_transform': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_transform.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_passthrough.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_readable.js': {
        'builtin': [
          'events.EventEmitter',
          'util',
          'util.debuglog',
        ],
        'globals': {
          'process.stderr': 'read',
          'process.stdout': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar destroyImpl = require('./internal/streams/destroy');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_readable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/BufferList': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/BufferList.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'events': 'events',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'isarray': '/home/xyz/Development/webtorrent/node_modules/isarray/index.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/safe-buffer/index.js',
            'string_decoder/': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/string_decoder/lib/string_decoder.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_transform.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_transform.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_duplex.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_transform.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_writable.js': {
        'globals': {
          'process.browser': 'read',
          'process.version.slice': 'read',
          'setImmediate': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_writable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/safe-buffer/index.js',
            'util-deprecate': '/home/xyz/Development/webtorrent/node_modules/util-deprecate/node.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_writable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/BufferList.js': {
        'builtin': [
          'util',
          'util.inspect',
          'util.inspect.custom',
        ],
        'moduleRecord': {
          'content': "'use strict';\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = require('safe-buffer').Buffer;\nvar util = require('util');\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/safe-buffer/index.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/destroy.js': {
        'moduleRecord': {
          'content': "'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'importMap': {
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/stream.js': {
        'builtin': [
          'stream',
        ],
        'moduleRecord': {
          'content': "module.exports = require('stream');\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/stream.js',
          'importMap': {
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/internal/streams/stream.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/readable.js': {
        'builtin': [
          'stream',
          'stream.Readable',
          'stream.Writable',
          'stream.Duplex',
          'stream.Transform',
          'stream.PassThrough',
        ],
        'globals': {
          'process.env.READABLE_STREAM': 'read',
        },
        'moduleRecord': {
          'content': "var Stream = require('stream');\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n  exports = module.exports = Stream.Readable;\n  exports.Readable = Stream.Readable;\n  exports.Writable = Stream.Writable;\n  exports.Duplex = Stream.Duplex;\n  exports.Transform = Stream.Transform;\n  exports.PassThrough = Stream.PassThrough;\n  exports.Stream = Stream;\n} else {\n  exports = module.exports = require('./lib/_stream_readable.js');\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = require('./lib/_stream_writable.js');\n  exports.Duplex = require('./lib/_stream_duplex.js');\n  exports.Transform = require('./lib/_stream_transform.js');\n  exports.PassThrough = require('./lib/_stream_passthrough.js');\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/readable.js',
          'importMap': {
            './lib/_stream_duplex.js': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_duplex.js',
            './lib/_stream_passthrough.js': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_passthrough.js',
            './lib/_stream_readable.js': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_readable.js',
            './lib/_stream_transform.js': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_transform.js',
            './lib/_stream_writable.js': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/lib/_stream_writable.js',
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/readable-stream/readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/safe-buffer/index.js': {
        'builtin': [
          'buffer.Buffer',
          'buffer',
          'buffer.SlowBuffer',
        ],
        'moduleRecord': {
          'content': "/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/safe-buffer/index.js',
          'importMap': {
            'buffer': 'buffer',
          },
          'packageName': 'safe-buffer',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/safe-buffer/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/string_decoder/lib/string_decoder.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/string_decoder/lib/string_decoder.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/safe-buffer/index.js',
          },
          'packageName': 'string_decoder',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/duplexer2/node_modules/string_decoder/lib/string_decoder.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/fast-safe-stringify/index.js': {
        'moduleRecord': {
          'content': "module.exports = stringify\nstringify.default = stringify\nstringify.stable = deterministicStringify\nstringify.stableStringify = deterministicStringify\n\nvar arr = []\nvar replacerStack = []\n\n// Regular stringify\nfunction stringify (obj, replacer, spacer) {\n  decirc(obj, '', [], undefined)\n  var res\n  if (replacerStack.length === 0) {\n    res = JSON.stringify(obj, replacer, spacer)\n  } else {\n    res = JSON.stringify(obj, replaceGetterValues(replacer), spacer)\n  }\n  while (arr.length !== 0) {\n    var part = arr.pop()\n    if (part.length === 4) {\n      Object.defineProperty(part[0], part[1], part[3])\n    } else {\n      part[0][part[1]] = part[2]\n    }\n  }\n  return res\n}\nfunction decirc (val, k, stack, parent) {\n  var i\n  if (typeof val === 'object' && val !== null) {\n    for (i = 0; i < stack.length; i++) {\n      if (stack[i] === val) {\n        var propertyDescriptor = Object.getOwnPropertyDescriptor(parent, k)\n        if (propertyDescriptor.get !== undefined) {\n          if (propertyDescriptor.configurable) {\n            Object.defineProperty(parent, k, { value: '[Circular]' })\n            arr.push([parent, k, val, propertyDescriptor])\n          } else {\n            replacerStack.push([val, k])\n          }\n        } else {\n          parent[k] = '[Circular]'\n          arr.push([parent, k, val])\n        }\n        return\n      }\n    }\n    stack.push(val)\n    // Optimize for Arrays. Big arrays could kill the performance otherwise!\n    if (Array.isArray(val)) {\n      for (i = 0; i < val.length; i++) {\n        decirc(val[i], i, stack, val)\n      }\n    } else {\n      var keys = Object.keys(val)\n      for (i = 0; i < keys.length; i++) {\n        var key = keys[i]\n        decirc(val[key], key, stack, val)\n      }\n    }\n    stack.pop()\n  }\n}\n\n// Stable-stringify\nfunction compareFunction (a, b) {\n  if (a < b) {\n    return -1\n  }\n  if (a > b) {\n    return 1\n  }\n  return 0\n}\n\nfunction deterministicStringify (obj, replacer, spacer) {\n  var tmp = deterministicDecirc(obj, '', [], undefined) || obj\n  var res\n  if (replacerStack.length === 0) {\n    res = JSON.stringify(tmp, replacer, spacer)\n  } else {\n    res = JSON.stringify(tmp, replaceGetterValues(replacer), spacer)\n  }\n  while (arr.length !== 0) {\n    var part = arr.pop()\n    if (part.length === 4) {\n      Object.defineProperty(part[0], part[1], part[3])\n    } else {\n      part[0][part[1]] = part[2]\n    }\n  }\n  return res\n}\n\nfunction deterministicDecirc (val, k, stack, parent) {\n  var i\n  if (typeof val === 'object' && val !== null) {\n    for (i = 0; i < stack.length; i++) {\n      if (stack[i] === val) {\n        var propertyDescriptor = Object.getOwnPropertyDescriptor(parent, k)\n        if (propertyDescriptor.get !== undefined) {\n          if (propertyDescriptor.configurable) {\n            Object.defineProperty(parent, k, { value: '[Circular]' })\n            arr.push([parent, k, val, propertyDescriptor])\n          } else {\n            replacerStack.push([val, k])\n          }\n        } else {\n          parent[k] = '[Circular]'\n          arr.push([parent, k, val])\n        }\n        return\n      }\n    }\n    if (typeof val.toJSON === 'function') {\n      return\n    }\n    stack.push(val)\n    // Optimize for Arrays. Big arrays could kill the performance otherwise!\n    if (Array.isArray(val)) {\n      for (i = 0; i < val.length; i++) {\n        deterministicDecirc(val[i], i, stack, val)\n      }\n    } else {\n      // Create a temporary object in the required way\n      var tmp = {}\n      var keys = Object.keys(val).sort(compareFunction)\n      for (i = 0; i < keys.length; i++) {\n        var key = keys[i]\n        deterministicDecirc(val[key], key, stack, val)\n        tmp[key] = val[key]\n      }\n      if (parent !== undefined) {\n        arr.push([parent, k, val])\n        parent[k] = tmp\n      } else {\n        return tmp\n      }\n    }\n    stack.pop()\n  }\n}\n\n// wraps replacer function to handle values we couldn't replace\n// and mark them as [Circular]\nfunction replaceGetterValues (replacer) {\n  replacer = replacer !== undefined ? replacer : function (k, v) { return v }\n  return function (key, val) {\n    if (replacerStack.length > 0) {\n      for (var i = 0; i < replacerStack.length; i++) {\n        var part = replacerStack[i]\n        if (part[1] === key && part[0] === val) {\n          val = '[Circular]'\n          replacerStack.splice(i, 1)\n          break\n        }\n      }\n    }\n    return replacer.call(this, key, val)\n  }\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/fast-safe-stringify/index.js',
          'importMap': {},
          'packageName': 'fast-safe-stringify',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/fast-safe-stringify/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/function-bind/implementation.js': {
        'moduleRecord': {
          'content': "'use strict';\n\n/* eslint no-invalid-this: 1 */\n\nvar ERROR_MESSAGE = 'Function.prototype.bind called on incompatible ';\nvar slice = Array.prototype.slice;\nvar toStr = Object.prototype.toString;\nvar funcType = '[object Function]';\n\nmodule.exports = function bind(that) {\n    var target = this;\n    if (typeof target !== 'function' || toStr.call(target) !== funcType) {\n        throw new TypeError(ERROR_MESSAGE + target);\n    }\n    var args = slice.call(arguments, 1);\n\n    var bound;\n    var binder = function () {\n        if (this instanceof bound) {\n            var result = target.apply(\n                this,\n                args.concat(slice.call(arguments))\n            );\n            if (Object(result) === result) {\n                return result;\n            }\n            return this;\n        } else {\n            return target.apply(\n                that,\n                args.concat(slice.call(arguments))\n            );\n        }\n    };\n\n    var boundLength = Math.max(0, target.length - args.length);\n    var boundArgs = [];\n    for (var i = 0; i < boundLength; i++) {\n        boundArgs.push('$' + i);\n    }\n\n    bound = Function('binder', 'return function (' + boundArgs.join(',') + '){ return binder.apply(this,arguments); }')(binder);\n\n    if (target.prototype) {\n        var Empty = function Empty() {};\n        Empty.prototype = target.prototype;\n        bound.prototype = new Empty();\n        Empty.prototype = null;\n    }\n\n    return bound;\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/function-bind/implementation.js',
          'importMap': {},
          'packageName': 'function-bind',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/function-bind/implementation.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/function-bind/index.js': {
        'moduleRecord': {
          'content': "'use strict';\n\nvar implementation = require('./implementation');\n\nmodule.exports = Function.prototype.bind || implementation;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/function-bind/index.js',
          'importMap': {
            './implementation': '/home/xyz/Development/webtorrent/node_modules/function-bind/implementation.js',
          },
          'packageName': 'function-bind',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/function-bind/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/get-assigned-identifiers/index.js': {
        'builtin': [
          'assert.equal',
        ],
        'moduleRecord': {
          'content': "var assert = require('assert')\n\n/**\n * Get a list of all identifiers that are initialised by this (possibly destructuring)\n * node.\n *\n * eg with input:\n *\n * var { a: [b, ...c], d } = xyz\n *\n * this returns the nodes for 'b', 'c', and 'd'\n */\nmodule.exports = function getAssignedIdentifiers (node, identifiers) {\n  assert.equal(typeof node, 'object', 'get-assigned-identifiers: node must be object')\n  assert.equal(typeof node.type, 'string', 'get-assigned-identifiers: node must have a type')\n\n  identifiers = identifiers || []\n\n  if (node.type === 'ImportDeclaration') {\n    node.specifiers.forEach(function (el) {\n      getAssignedIdentifiers(el, identifiers)\n    })\n  }\n\n  if (node.type === 'ImportDefaultSpecifier' || node.type === 'ImportNamespaceSpecifier' || node.type === 'ImportSpecifier') {\n    node = node.local\n  }\n\n  if (node.type === 'RestElement') {\n    node = node.argument\n  }\n\n  if (node.type === 'ArrayPattern') {\n    node.elements.forEach(function (el) {\n      // `el` might be `null` in case of `[x,,y] = whatever`\n      if (el) {\n        getAssignedIdentifiers(el, identifiers)\n      }\n    })\n  }\n\n  if (node.type === 'ObjectPattern') {\n    node.properties.forEach(function (prop) {\n      if (prop.type === 'Property') {\n        getAssignedIdentifiers(prop.value, identifiers)\n      } else if (prop.type === 'RestElement') {\n        getAssignedIdentifiers(prop, identifiers)\n      }\n    })\n  }\n\n  if (node.type === 'Identifier') {\n    identifiers.push(node)\n  }\n\n  return identifiers\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/get-assigned-identifiers/index.js',
          'importMap': {
            'assert': 'assert',
          },
          'packageName': 'get-assigned-identifiers',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/get-assigned-identifiers/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/has/src/index.js': {
        'moduleRecord': {
          'content': "'use strict';\n\nvar bind = require('function-bind');\n\nmodule.exports = bind.call(Function.call, Object.prototype.hasOwnProperty);\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/has/src/index.js',
          'importMap': {
            'function-bind': '/home/xyz/Development/webtorrent/node_modules/function-bind/index.js',
          },
          'packageName': 'has',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/has/src/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/htmlescape/htmlescape.js': {
        'moduleRecord': {
          'content': "/**\n * Properly escape JSON for usage as an object literal inside of a `<script>` tag.\n * JS implementation of http://golang.org/pkg/encoding/json/#HTMLEscape\n * More info: http://timelessrepo.com/json-isnt-a-javascript-subset\n */\n\n'use strict';\n\nvar ESCAPE_LOOKUP = {\n  '&': '\\\\u0026',\n  '>': '\\\\u003e',\n  '<': '\\\\u003c',\n  '\\u2028': '\\\\u2028',\n  '\\u2029': '\\\\u2029'\n};\n\nvar ESCAPE_REGEX = /[&><\\u2028\\u2029]/g;\n\nfunction escaper(match) {\n  return ESCAPE_LOOKUP[match];\n}\n\nmodule.exports = function(obj) {\n  return JSON.stringify(obj).replace(ESCAPE_REGEX, escaper);\n};\n\n/***/\n\nvar TERMINATORS_LOOKUP = {\n  '\\u2028': '\\\\u2028',\n  '\\u2029': '\\\\u2029'\n};\n\nvar TERMINATORS_REGEX = /[\\u2028\\u2029]/g;\n\nfunction sanitizer(match) {\n  return TERMINATORS_LOOKUP[match];\n}\n\nmodule.exports.sanitize = function(str) {\n  return str.replace(TERMINATORS_REGEX, sanitizer);\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/htmlescape/htmlescape.js',
          'importMap': {},
          'packageName': 'htmlescape',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/htmlescape/htmlescape.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js': {
        'builtin': [
          'util.inherits',
        ],
        'moduleRecord': {
          'content': "try {\n  var util = require('util');\n  /* istanbul ignore next */\n  if (typeof util.inherits !== 'function') throw '';\n  module.exports = util.inherits;\n} catch (e) {\n  /* istanbul ignore next */\n  module.exports = require('./inherits_browser.js');\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          'importMap': {
            './inherits_browser.js': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits_browser.js',
            'util': 'util',
          },
          'packageName': 'inherits',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/inherits/inherits_browser.js': {
        'moduleRecord': {
          'content': "if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits_browser.js',
          'importMap': {},
          'packageName': 'inherits',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits_browser.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/inline-source-map/index.js': {
        'globals': {
          'Buffer': 'read',
        },
        'moduleRecord': {
          'content': "'use strict';\nvar SourceMapGenerator = require('source-map').SourceMapGenerator;\n\nfunction offsetMapping(mapping, offset) {\n  return { line: offset.line + mapping.line, column: offset.column + mapping.column };\n}\n\nfunction newlinesIn(src) {\n  if (!src) return 0;\n  var newlines = src.match(/\\n/g);\n\n  return newlines ? newlines.length : 0;\n}\n \nfunction Generator(opts) {\n  opts = opts || {};\n  this.generator = new SourceMapGenerator({ file: opts.file || '', sourceRoot: opts.sourceRoot || '' });\n  this.sourcesContent = undefined;\n  this.opts = opts;\n}\n\n/**\n * Adds the given mappings to the generator and offsets them if offset is given \n *\n * @name addMappings\n * @function\n * @param sourceFile {String} name of the source file\n * @param mappings {Array{{Object}} each object has the form { original: { line: _, column: _ }, generated: { line: _, column: _ } }\n * @param offset {Object} offset to apply to each mapping. Has the form { line: _, column: _ }\n * @return {Object} the generator to allow chaining\n */\nGenerator.prototype.addMappings = function (sourceFile, mappings, offset) { \n  var generator = this.generator; \n\n  offset = offset || {};\n  offset.line = offset.hasOwnProperty('line') ? offset.line : 0;\n  offset.column = offset.hasOwnProperty('column') ? offset.column : 0;\n\n  mappings.forEach(function (m) {\n    // only set source if we have original position to handle edgecase (see inline-source-map tests)\n    generator.addMapping({\n        source    :  m.original ? sourceFile : undefined\n      , original  :  m.original\n      , generated :  offsetMapping(m.generated, offset)\n    });\n  });\n  return this;\n};\n\n/**\n * Generates mappings for the given source, assuming that no translation from original to generated is necessary.\n *\n * @name addGeneratedMappings\n * @function\n * @param sourceFile {String} name of the source file\n * @param source {String} source of the file\n * @param offset {Object} offset to apply to each mapping. Has the form { line: _, column: _ }\n * @return {Object} the generator to allow chaining\n */\nGenerator.prototype.addGeneratedMappings = function (sourceFile, source, offset) {\n  var mappings = []\n    , linesToGenerate = newlinesIn(source) + 1;\n\n  for (var line = 1; line <= linesToGenerate; line++) {\n    var location = { line: line, column: 0 };\n    mappings.push({ original: location, generated: location });\n  }\n\n  return this.addMappings(sourceFile, mappings, offset);\n};\n\n/**\n * Adds source content for the given source file.\n * \n * @name addSourceContent\n * @function\n * @param sourceFile {String} The source file for which a mapping is included\n * @param sourcesContent {String} The content of the source file\n * @return {Object} The generator to allow chaining\n */\nGenerator.prototype.addSourceContent = function (sourceFile, sourcesContent) {\n  this.sourcesContent = this.sourcesContent || {};\n  this.sourcesContent[sourceFile] = sourcesContent;\n  return this;\n};\n\n/**\n * @name base64Encode\n * @function\n * @return {String} bas64 encoded representation of the added mappings\n */\nGenerator.prototype.base64Encode = function () {\n  var map = this.toString();\n  return new Buffer(map).toString('base64');\n};\n\n/**\n * @name inlineMappingUrl\n * @function\n * @return {String} comment with base64 encoded representation of the added mappings. Can be inlined at the end of the generated file. \n */\nGenerator.prototype.inlineMappingUrl = function () {\n  var charset = this.opts.charset || 'utf-8';\n  return '//# sourceMappingURL=data:application/json;charset=' + charset + ';base64,' + this.base64Encode();\n};\n\nGenerator.prototype.toJSON = function () {\n  var map = this.generator.toJSON();\n  if (!this.sourcesContent) return map;\n\n  var toSourcesContent = (function (s) {\n    if (typeof this.sourcesContent[s] === 'string') {\n      return this.sourcesContent[s];\n    } else {\n      return null;\n    }\n  }).bind(this);\n  map.sourcesContent = map.sources.map(toSourcesContent);\n  return map;\n};\n\nGenerator.prototype.toString = function () {\n  return JSON.stringify(this);\n};\n\nGenerator.prototype._mappings = function () {\n  return this.generator._mappings._array;\n};\n\nGenerator.prototype.gen = function () {\n  return this.generator;\n};\n\nmodule.exports = function (opts) { return new Generator(opts); };\nmodule.exports.Generator = Generator;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/inline-source-map/index.js',
          'importMap': {
            'source-map': '/home/xyz/Development/webtorrent/node_modules/source-map/source-map.js',
          },
          'packageName': 'inline-source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/inline-source-map/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/insert-module-globals/index.js': {
        'builtin': [
          'path.isAbsolute',
          'path.relative',
          'path.dirname',
          'path.sep',
        ],
        'globals': {
          'Buffer.concat': 'read',
          'Buffer.isBuffer': 'read',
        },
        'moduleRecord': {
          'content': "var undeclaredIdentifiers = require('undeclared-identifiers');\nvar through = require('through2');\nvar merge = require('xtend');\nvar parse = require('acorn-node').parse;\n\nvar path = require('path');\nvar isAbsolute = path.isAbsolute || require('path-is-absolute');\nvar processPath = require.resolve('process/browser.js');\nvar isbufferPath = require.resolve('is-buffer')\nvar combineSourceMap = require('combine-source-map');\n\nfunction getRelativeRequirePath(fullPath, fromPath) {\n  var relpath = path.relative(path.dirname(fromPath), fullPath);\n  // If fullPath is in the same directory or a subdirectory of fromPath,\n  // relpath will result in something like \"index.js\", \"src/abc.js\".\n  // require() needs \"./\" prepended to these paths.\n  if (!/^\\./.test(relpath) && !isAbsolute(relpath)) {\n    relpath = \"./\" + relpath;\n  }\n  // On Windows: Convert path separators to what require() expects\n  if (path.sep === '\\\\') {\n    relpath = relpath.replace(/\\\\/g, '/');\n  }\n  return relpath;\n}\n\nvar defaultVars = {\n    process: function (file) {\n        var relpath = getRelativeRequirePath(processPath, file);\n        return 'require(' + JSON.stringify(relpath) + ')';\n    },\n    global: function () {\n        return 'typeof global !== \"undefined\" ? global : '\n            + 'typeof self !== \"undefined\" ? self : '\n            + 'typeof window !== \"undefined\" ? window : {}'\n        ;\n    },\n    'Buffer.isBuffer': function (file) {\n        var relpath = getRelativeRequirePath(isbufferPath, file);\n        return 'require(' + JSON.stringify(relpath) + ')';\n    },\n    Buffer: function () {\n        return 'require(\"buffer\").Buffer';\n    },\n    setImmediate: function () {\n        return 'require(\"timers\").setImmediate';\n    },\n    clearImmediate: function () {\n        return 'require(\"timers\").clearImmediate';\n    },\n    __filename: function (file, basedir) {\n        var relpath = path.relative(basedir, file);\n        // standardize path separators, use slash in Windows too\n        if ( path.sep === '\\\\' ) {\n          relpath = relpath.replace(/\\\\/g, '/');\n        }\n        var filename = '/' + relpath;\n        return JSON.stringify(filename);\n    },\n    __dirname: function (file, basedir) {\n        var relpath = path.relative(basedir, file);\n        // standardize path separators, use slash in Windows too\n        if ( path.sep === '\\\\' ) {\n          relpath = relpath.replace(/\\\\/g, '/');\n        }\n        var dir = path.dirname('/' + relpath );\n        return JSON.stringify(dir);\n    }\n};\n\nmodule.exports = function (file, opts) {\n    if (/\\.json$/i.test(file)) return through();\n    if (!opts) opts = {};\n    \n    var basedir = opts.basedir || '/';\n    var vars = merge(defaultVars, opts.vars);\n    var varNames = Object.keys(vars).filter(function(name) {\n        return typeof vars[name] === 'function';\n    });\n    \n    var quick = RegExp(varNames.map(function (name) {\n        return '\\\\b' + name + '\\\\b';\n    }).join('|'));\n    \n    var chunks = [];\n    \n    return through(write, end);\n    \n    function write (chunk, enc, next) { chunks.push(chunk); next() }\n    \n    function end () {\n        var self = this;\n        var source = Buffer.isBuffer(chunks[0])\n            ? Buffer.concat(chunks).toString('utf8')\n            : chunks.join('')\n        ;\n        source = source\n            .replace(/^\\ufeff/, '')\n            .replace(/^#![^\\n]*\\n/, '\\n');\n        \n        if (opts.always !== true && !quick.test(source)) {\n            this.push(source);\n            this.push(null);\n            return;\n        }\n        \n        try {\n            var undeclared = opts.always\n                ? { identifiers: varNames, properties: [] }\n                : undeclaredIdentifiers(parse(source), { wildcard: true })\n            ;\n        }\n        catch (err) {\n            var e = new SyntaxError(\n                (err.message || err) + ' while parsing ' + file\n            );\n            e.type = 'syntax';\n            e.filename = file;\n            return this.emit('error', e);\n        }\n        \n        var globals = {};\n        \n        varNames.forEach(function (name) {\n            if (!/\\./.test(name)) return;\n            var parts = name.split('.')\n            var prop = undeclared.properties.indexOf(name)\n            if (prop === -1 || countprops(undeclared.properties, parts[0]) > 1) return;\n            var value = vars[name](file, basedir);\n            if (!value) return;\n            globals[parts[0]] = '{'\n                + JSON.stringify(parts[1]) + ':' + value + '}';\n            self.emit('global', name);\n        });\n        varNames.forEach(function (name) {\n            if (/\\./.test(name)) return;\n            if (globals[name]) return;\n            if (undeclared.identifiers.indexOf(name) < 0) return;\n            var value = vars[name](file, basedir);\n            if (!value) return;\n            globals[name] = value;\n            self.emit('global', name);\n        });\n        \n        this.push(closeOver(globals, source, file, opts));\n        this.push(null);\n    }\n};\n\nmodule.exports.vars = defaultVars;\n\nfunction closeOver (globals, src, file, opts) {\n    var keys = Object.keys(globals);\n    if (keys.length === 0) return src;\n    var values = keys.map(function (key) { return globals[key] });\n    \n    // we double-wrap the source in IIFEs to prevent code like\n    //     (function(Buffer){ const Buffer = null }())\n    // which causes a parse error.\n    var wrappedSource = '(function (){\\n' + src + '\\n}).call(this)';\n    if (keys.length <= 3) {\n        wrappedSource = '(function (' + keys.join(',') + '){'\n            + wrappedSource + '}).call(this,' + values.join(',') + ')'\n        ;\n    }\n    else {\n      // necessary to make arguments[3..6] still work for workerify etc\n      // a,b,c,arguments[3..6],d,e,f...\n      var extra = [ '__argument0', '__argument1', '__argument2', '__argument3' ];\n      var names = keys.slice(0,3).concat(extra).concat(keys.slice(3));\n      values.splice(3, 0,\n          'arguments[3]','arguments[4]',\n          'arguments[5]','arguments[6]'\n      );\n      wrappedSource = '(function (' + names.join(',') + '){'\n        + wrappedSource + '}).call(this,' + values.join(',') + ')';\n    }\n\n    // Generate source maps if wanted. Including the right offset for\n    // the wrapped source.\n    if (!opts.debug) {\n        return wrappedSource;\n    }\n    var sourceFile = path.relative(opts.basedir, file)\n        .replace(/\\\\/g, '/');\n    var sourceMap = combineSourceMap.create().addFile(\n        { sourceFile: sourceFile, source: src},\n        { line: 1 });\n    return combineSourceMap.removeComments(wrappedSource) + \"\\n\"\n        + sourceMap.comment();\n}\n\nfunction countprops (props, name) {\n    return props.filter(function (prop) {\n        return prop.slice(0, name.length + 1) === name + '.';\n    }).length;\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/insert-module-globals/index.js',
          'importMap': {
            'acorn-node': '/home/xyz/Development/webtorrent/node_modules/acorn-node/index.js',
            'combine-source-map': '/home/xyz/Development/webtorrent/node_modules/combine-source-map/index.js',
            'path': 'path',
            'path-is-absolute': '/home/xyz/Development/webtorrent/node_modules/path-is-absolute/index.js',
            'through2': '/home/xyz/Development/webtorrent/node_modules/through2/through2.js',
            'undeclared-identifiers': '/home/xyz/Development/webtorrent/node_modules/undeclared-identifiers/index.js',
            'xtend': '/home/xyz/Development/webtorrent/node_modules/xtend/immutable.js',
          },
          'packageName': 'insert-module-globals',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/insert-module-globals/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/is-core-module/core.json': {
        'moduleRecord': {
          'content': 'module.exports={\n\t"assert": true,\n\t"assert/strict": ">= 15",\n\t"async_hooks": ">= 8",\n\t"buffer_ieee754": "< 0.9.7",\n\t"buffer": true,\n\t"child_process": true,\n\t"cluster": true,\n\t"console": true,\n\t"constants": true,\n\t"crypto": true,\n\t"_debug_agent": ">= 1 && < 8",\n\t"_debugger": "< 8",\n\t"dgram": true,\n\t"diagnostics_channel": ">= 15.1",\n\t"dns": true,\n\t"dns/promises": ">= 15",\n\t"domain": ">= 0.7.12",\n\t"events": true,\n\t"freelist": "< 6",\n\t"fs": true,\n\t"fs/promises": [">= 10 && < 10.1", ">= 14"],\n\t"_http_agent": ">= 0.11.1",\n\t"_http_client": ">= 0.11.1",\n\t"_http_common": ">= 0.11.1",\n\t"_http_incoming": ">= 0.11.1",\n\t"_http_outgoing": ">= 0.11.1",\n\t"_http_server": ">= 0.11.1",\n\t"http": true,\n\t"http2": ">= 8.8",\n\t"https": true,\n\t"inspector": ">= 8.0.0",\n\t"_linklist": "< 8",\n\t"module": true,\n\t"net": true,\n\t"node-inspect/lib/_inspect": ">= 7.6.0 && < 12",\n\t"node-inspect/lib/internal/inspect_client": ">= 7.6.0 && < 12",\n\t"node-inspect/lib/internal/inspect_repl": ">= 7.6.0 && < 12",\n\t"os": true,\n\t"path": true,\n\t"path/posix": ">= 15.3",\n\t"path/win32": ">= 15.3",\n\t"perf_hooks": ">= 8.5",\n\t"process": ">= 1",\n\t"punycode": true,\n\t"querystring": true,\n\t"readline": true,\n\t"repl": true,\n\t"smalloc": ">= 0.11.5 && < 3",\n\t"_stream_duplex": ">= 0.9.4",\n\t"_stream_transform": ">= 0.9.4",\n\t"_stream_wrap": ">= 1.4.1",\n\t"_stream_passthrough": ">= 0.9.4",\n\t"_stream_readable": ">= 0.9.4",\n\t"_stream_writable": ">= 0.9.4",\n\t"stream": true,\n\t"stream/promises": ">= 15",\n\t"string_decoder": true,\n\t"sys": [">= 0.6 && < 0.7", ">= 0.8"],\n\t"timers": true,\n\t"timers/promises": ">= 15",\n\t"_tls_common": ">= 0.11.13",\n\t"_tls_legacy": ">= 0.11.3 && < 10",\n\t"_tls_wrap": ">= 0.11.3",\n\t"tls": true,\n\t"trace_events": ">= 10",\n\t"tty": true,\n\t"url": true,\n\t"util": true,\n\t"util/types": ">= 15.3",\n\t"v8/tools/arguments": ">= 10 && < 12",\n\t"v8/tools/codemap": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n\t"v8/tools/consarray": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n\t"v8/tools/csvparser": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n\t"v8/tools/logreader": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n\t"v8/tools/profile_view": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n\t"v8/tools/splaytree": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n\t"v8": ">= 1",\n\t"vm": true,\n\t"wasi": ">= 13.4 && < 13.5",\n\t"worker_threads": ">= 11.7",\n\t"zlib": true\n}\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/is-core-module/core.json',
          'importMap': {},
          'packageName': 'is-core-module',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/is-core-module/core.json',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/is-core-module/index.js': {
        'globals': {
          'process.versions': 'read',
        },
        'moduleRecord': {
          'content': "'use strict';\n\nvar has = require('has');\n\nfunction specifierIncluded(current, specifier) {\n\tvar nodeParts = current.split('.');\n\tvar parts = specifier.split(' ');\n\tvar op = parts.length > 1 ? parts[0] : '=';\n\tvar versionParts = (parts.length > 1 ? parts[1] : parts[0]).split('.');\n\n\tfor (var i = 0; i < 3; ++i) {\n\t\tvar cur = parseInt(nodeParts[i] || 0, 10);\n\t\tvar ver = parseInt(versionParts[i] || 0, 10);\n\t\tif (cur === ver) {\n\t\t\tcontinue; // eslint-disable-line no-restricted-syntax, no-continue\n\t\t}\n\t\tif (op === '<') {\n\t\t\treturn cur < ver;\n\t\t}\n\t\tif (op === '>=') {\n\t\t\treturn cur >= ver;\n\t\t}\n\t\treturn false;\n\t}\n\treturn op === '>=';\n}\n\nfunction matchesRange(current, range) {\n\tvar specifiers = range.split(/ ?&& ?/);\n\tif (specifiers.length === 0) {\n\t\treturn false;\n\t}\n\tfor (var i = 0; i < specifiers.length; ++i) {\n\t\tif (!specifierIncluded(current, specifiers[i])) {\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n}\n\nfunction versionIncluded(nodeVersion, specifierValue) {\n\tif (typeof specifierValue === 'boolean') {\n\t\treturn specifierValue;\n\t}\n\n\tvar current = typeof nodeVersion === 'undefined'\n\t\t? process.versions && process.versions.node && process.versions.node\n\t\t: nodeVersion;\n\n\tif (typeof current !== 'string') {\n\t\tthrow new TypeError(typeof nodeVersion === 'undefined' ? 'Unable to determine current node version' : 'If provided, a valid node version is required');\n\t}\n\n\tif (specifierValue && typeof specifierValue === 'object') {\n\t\tfor (var i = 0; i < specifierValue.length; ++i) {\n\t\t\tif (matchesRange(current, specifierValue[i])) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\treturn matchesRange(current, specifierValue);\n}\n\nvar data = require('./core.json');\n\nmodule.exports = function isCore(x, nodeVersion) {\n\treturn has(data, x) && versionIncluded(nodeVersion, data[x]);\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/is-core-module/index.js',
          'importMap': {
            './core.json': '/home/xyz/Development/webtorrent/node_modules/is-core-module/core.json',
            'has': '/home/xyz/Development/webtorrent/node_modules/has/src/index.js',
          },
          'packageName': 'is-core-module',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/is-core-module/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/isarray/index.js': {
        'moduleRecord': {
          'content': "var toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/isarray/index.js',
          'importMap': {},
          'packageName': 'isarray',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/isarray/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/jsonparse/jsonparse.js': {
        'globals': {
          'Buffer': 'read',
        },
        'moduleRecord': {
          'content': "/*global Buffer*/\n// Named constants with unique integer values\nvar C = {};\n// Tokens\nvar LEFT_BRACE    = C.LEFT_BRACE    = 0x1;\nvar RIGHT_BRACE   = C.RIGHT_BRACE   = 0x2;\nvar LEFT_BRACKET  = C.LEFT_BRACKET  = 0x3;\nvar RIGHT_BRACKET = C.RIGHT_BRACKET = 0x4;\nvar COLON         = C.COLON         = 0x5;\nvar COMMA         = C.COMMA         = 0x6;\nvar TRUE          = C.TRUE          = 0x7;\nvar FALSE         = C.FALSE         = 0x8;\nvar NULL          = C.NULL          = 0x9;\nvar STRING        = C.STRING        = 0xa;\nvar NUMBER        = C.NUMBER        = 0xb;\n// Tokenizer States\nvar START   = C.START   = 0x11;\nvar STOP    = C.STOP    = 0x12;\nvar TRUE1   = C.TRUE1   = 0x21;\nvar TRUE2   = C.TRUE2   = 0x22;\nvar TRUE3   = C.TRUE3   = 0x23;\nvar FALSE1  = C.FALSE1  = 0x31;\nvar FALSE2  = C.FALSE2  = 0x32;\nvar FALSE3  = C.FALSE3  = 0x33;\nvar FALSE4  = C.FALSE4  = 0x34;\nvar NULL1   = C.NULL1   = 0x41;\nvar NULL2   = C.NULL2   = 0x42;\nvar NULL3   = C.NULL3   = 0x43;\nvar NUMBER1 = C.NUMBER1 = 0x51;\nvar NUMBER3 = C.NUMBER3 = 0x53;\nvar STRING1 = C.STRING1 = 0x61;\nvar STRING2 = C.STRING2 = 0x62;\nvar STRING3 = C.STRING3 = 0x63;\nvar STRING4 = C.STRING4 = 0x64;\nvar STRING5 = C.STRING5 = 0x65;\nvar STRING6 = C.STRING6 = 0x66;\n// Parser States\nvar VALUE   = C.VALUE   = 0x71;\nvar KEY     = C.KEY     = 0x72;\n// Parser Modes\nvar OBJECT  = C.OBJECT  = 0x81;\nvar ARRAY   = C.ARRAY   = 0x82;\n// Character constants\nvar BACK_SLASH =      \"\\\\\".charCodeAt(0);\nvar FORWARD_SLASH =   \"\\/\".charCodeAt(0);\nvar BACKSPACE =       \"\\b\".charCodeAt(0);\nvar FORM_FEED =       \"\\f\".charCodeAt(0);\nvar NEWLINE =         \"\\n\".charCodeAt(0);\nvar CARRIAGE_RETURN = \"\\r\".charCodeAt(0);\nvar TAB =             \"\\t\".charCodeAt(0);\n\nvar STRING_BUFFER_SIZE = 64 * 1024;\n\nfunction Parser() {\n  this.tState = START;\n  this.value = undefined;\n\n  this.string = undefined; // string data\n  this.stringBuffer = Buffer.alloc ? Buffer.alloc(STRING_BUFFER_SIZE) : new Buffer(STRING_BUFFER_SIZE);\n  this.stringBufferOffset = 0;\n  this.unicode = undefined; // unicode escapes\n  this.highSurrogate = undefined;\n\n  this.key = undefined;\n  this.mode = undefined;\n  this.stack = [];\n  this.state = VALUE;\n  this.bytes_remaining = 0; // number of bytes remaining in multi byte utf8 char to read after split boundary\n  this.bytes_in_sequence = 0; // bytes in multi byte utf8 char to read\n  this.temp_buffs = { \"2\": new Buffer(2), \"3\": new Buffer(3), \"4\": new Buffer(4) }; // for rebuilding chars split before boundary is reached\n\n  // Stream offset\n  this.offset = -1;\n}\n\n// Slow code to string converter (only used when throwing syntax errors)\nParser.toknam = function (code) {\n  var keys = Object.keys(C);\n  for (var i = 0, l = keys.length; i < l; i++) {\n    var key = keys[i];\n    if (C[key] === code) { return key; }\n  }\n  return code && (\"0x\" + code.toString(16));\n};\n\nvar proto = Parser.prototype;\nproto.onError = function (err) { throw err; };\nproto.charError = function (buffer, i) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + JSON.stringify(String.fromCharCode(buffer[i])) + \" at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n};\nproto.appendStringChar = function (char) {\n  if (this.stringBufferOffset >= STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8');\n    this.stringBufferOffset = 0;\n  }\n\n  this.stringBuffer[this.stringBufferOffset++] = char;\n};\nproto.appendStringBuf = function (buf, start, end) {\n  var size = buf.length;\n  if (typeof start === 'number') {\n    if (typeof end === 'number') {\n      if (end < 0) {\n        // adding a negative end decreeses the size\n        size = buf.length - start + end;\n      } else {\n        size = end - start;\n      }\n    } else {\n      size = buf.length - start;\n    }\n  }\n\n  if (size < 0) {\n    size = 0;\n  }\n\n  if (this.stringBufferOffset + size > STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n    this.stringBufferOffset = 0;\n  }\n\n  buf.copy(this.stringBuffer, this.stringBufferOffset, start, end);\n  this.stringBufferOffset += size;\n};\nproto.write = function (buffer) {\n  if (typeof buffer === \"string\") buffer = new Buffer(buffer);\n  var n;\n  for (var i = 0, l = buffer.length; i < l; i++) {\n    if (this.tState === START){\n      n = buffer[i];\n      this.offset++;\n      if(n === 0x7b){ this.onToken(LEFT_BRACE, \"{\"); // {\n      }else if(n === 0x7d){ this.onToken(RIGHT_BRACE, \"}\"); // }\n      }else if(n === 0x5b){ this.onToken(LEFT_BRACKET, \"[\"); // [\n      }else if(n === 0x5d){ this.onToken(RIGHT_BRACKET, \"]\"); // ]\n      }else if(n === 0x3a){ this.onToken(COLON, \":\");  // :\n      }else if(n === 0x2c){ this.onToken(COMMA, \",\"); // ,\n      }else if(n === 0x74){ this.tState = TRUE1;  // t\n      }else if(n === 0x66){ this.tState = FALSE1;  // f\n      }else if(n === 0x6e){ this.tState = NULL1; // n\n      }else if(n === 0x22){ // \"\n        this.string = \"\";\n        this.stringBufferOffset = 0;\n        this.tState = STRING1;\n      }else if(n === 0x2d){ this.string = \"-\"; this.tState = NUMBER1; // -\n      }else{\n        if (n >= 0x30 && n < 0x40) { // 1-9\n          this.string = String.fromCharCode(n); this.tState = NUMBER3;\n        } else if (n === 0x20 || n === 0x09 || n === 0x0a || n === 0x0d) {\n          // whitespace\n        } else {\n          return this.charError(buffer, i);\n        }\n      }\n    }else if (this.tState === STRING1){ // After open quote\n      n = buffer[i]; // get current byte from buffer\n      // check for carry over of a multi byte char split between data chunks\n      // & fill temp buffer it with start of this data chunk up to the boundary limit set in the last iteration\n      if (this.bytes_remaining > 0) {\n        for (var j = 0; j < this.bytes_remaining; j++) {\n          this.temp_buffs[this.bytes_in_sequence][this.bytes_in_sequence - this.bytes_remaining + j] = buffer[j];\n        }\n\n        this.appendStringBuf(this.temp_buffs[this.bytes_in_sequence]);\n        this.bytes_in_sequence = this.bytes_remaining = 0;\n        i = i + j - 1;\n      } else if (this.bytes_remaining === 0 && n >= 128) { // else if no remainder bytes carried over, parse multi byte (>=128) chars one at a time\n        if (n <= 193 || n > 244) {\n          return this.onError(new Error(\"Invalid UTF-8 character at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n        }\n        if ((n >= 194) && (n <= 223)) this.bytes_in_sequence = 2;\n        if ((n >= 224) && (n <= 239)) this.bytes_in_sequence = 3;\n        if ((n >= 240) && (n <= 244)) this.bytes_in_sequence = 4;\n        if ((this.bytes_in_sequence + i) > buffer.length) { // if bytes needed to complete char fall outside buffer length, we have a boundary split\n          for (var k = 0; k <= (buffer.length - 1 - i); k++) {\n            this.temp_buffs[this.bytes_in_sequence][k] = buffer[i + k]; // fill temp buffer of correct size with bytes available in this chunk\n          }\n          this.bytes_remaining = (i + this.bytes_in_sequence) - buffer.length;\n          i = buffer.length - 1;\n        } else {\n          this.appendStringBuf(buffer, i, i + this.bytes_in_sequence);\n          i = i + this.bytes_in_sequence - 1;\n        }\n      } else if (n === 0x22) {\n        this.tState = START;\n        this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n        this.stringBufferOffset = 0;\n        this.onToken(STRING, this.string);\n        this.offset += Buffer.byteLength(this.string, 'utf8') + 1;\n        this.string = undefined;\n      }\n      else if (n === 0x5c) {\n        this.tState = STRING2;\n      }\n      else if (n >= 0x20) { this.appendStringChar(n); }\n      else {\n          return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING2){ // After backslash\n      n = buffer[i];\n      if(n === 0x22){ this.appendStringChar(n); this.tState = STRING1;\n      }else if(n === 0x5c){ this.appendStringChar(BACK_SLASH); this.tState = STRING1;\n      }else if(n === 0x2f){ this.appendStringChar(FORWARD_SLASH); this.tState = STRING1;\n      }else if(n === 0x62){ this.appendStringChar(BACKSPACE); this.tState = STRING1;\n      }else if(n === 0x66){ this.appendStringChar(FORM_FEED); this.tState = STRING1;\n      }else if(n === 0x6e){ this.appendStringChar(NEWLINE); this.tState = STRING1;\n      }else if(n === 0x72){ this.appendStringChar(CARRIAGE_RETURN); this.tState = STRING1;\n      }else if(n === 0x74){ this.appendStringChar(TAB); this.tState = STRING1;\n      }else if(n === 0x75){ this.unicode = \"\"; this.tState = STRING3;\n      }else{\n        return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING3 || this.tState === STRING4 || this.tState === STRING5 || this.tState === STRING6){ // unicode hex codes\n      n = buffer[i];\n      // 0-9 A-F a-f\n      if ((n >= 0x30 && n < 0x40) || (n > 0x40 && n <= 0x46) || (n > 0x60 && n <= 0x66)) {\n        this.unicode += String.fromCharCode(n);\n        if (this.tState++ === STRING6) {\n          var intVal = parseInt(this.unicode, 16);\n          this.unicode = undefined;\n          if (this.highSurrogate !== undefined && intVal >= 0xDC00 && intVal < (0xDFFF + 1)) { //<56320,57343> - lowSurrogate\n            this.appendStringBuf(new Buffer(String.fromCharCode(this.highSurrogate, intVal)));\n            this.highSurrogate = undefined;\n          } else if (this.highSurrogate === undefined && intVal >= 0xD800 && intVal < (0xDBFF + 1)) { //<55296,56319> - highSurrogate\n            this.highSurrogate = intVal;\n          } else {\n            if (this.highSurrogate !== undefined) {\n              this.appendStringBuf(new Buffer(String.fromCharCode(this.highSurrogate)));\n              this.highSurrogate = undefined;\n            }\n            this.appendStringBuf(new Buffer(String.fromCharCode(intVal)));\n          }\n          this.tState = STRING1;\n        }\n      } else {\n        return this.charError(buffer, i);\n      }\n    } else if (this.tState === NUMBER1 || this.tState === NUMBER3) {\n        n = buffer[i];\n\n        switch (n) {\n          case 0x30: // 0\n          case 0x31: // 1\n          case 0x32: // 2\n          case 0x33: // 3\n          case 0x34: // 4\n          case 0x35: // 5\n          case 0x36: // 6\n          case 0x37: // 7\n          case 0x38: // 8\n          case 0x39: // 9\n          case 0x2e: // .\n          case 0x65: // e\n          case 0x45: // E\n          case 0x2b: // +\n          case 0x2d: // -\n            this.string += String.fromCharCode(n);\n            this.tState = NUMBER3;\n            break;\n          default:\n            this.tState = START;\n            var result = Number(this.string);\n\n            if (isNaN(result)){\n              return this.charError(buffer, i);\n            }\n\n            if ((this.string.match(/[0-9]+/) == this.string) && (result.toString() != this.string)) {\n              // Long string of digits which is an ID string and not valid and/or safe JavaScript integer Number\n              this.onToken(STRING, this.string);\n            } else {\n              this.onToken(NUMBER, result);\n            }\n\n            this.offset += this.string.length - 1;\n            this.string = undefined;\n            i--;\n            break;\n        }\n    }else if (this.tState === TRUE1){ // r\n      if (buffer[i] === 0x72) { this.tState = TRUE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE2){ // u\n      if (buffer[i] === 0x75) { this.tState = TRUE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE3){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(TRUE, true); this.offset+= 3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE1){ // a\n      if (buffer[i] === 0x61) { this.tState = FALSE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE2){ // l\n      if (buffer[i] === 0x6c) { this.tState = FALSE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE3){ // s\n      if (buffer[i] === 0x73) { this.tState = FALSE4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE4){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(FALSE, false); this.offset+= 4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL1){ // u\n      if (buffer[i] === 0x75) { this.tState = NULL2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL2){ // l\n      if (buffer[i] === 0x6c) { this.tState = NULL3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL3){ // l\n      if (buffer[i] === 0x6c) { this.tState = START; this.onToken(NULL, null); this.offset += 3; }\n      else { return this.charError(buffer, i); }\n    }\n  }\n};\nproto.onToken = function (token, value) {\n  // Override this to get events\n};\n\nproto.parseError = function (token, value) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + Parser.toknam(token) + (value ? (\"(\" + JSON.stringify(value) + \")\") : \"\") + \" in state \" + Parser.toknam(this.state)));\n};\nproto.push = function () {\n  this.stack.push({value: this.value, key: this.key, mode: this.mode});\n};\nproto.pop = function () {\n  var value = this.value;\n  var parent = this.stack.pop();\n  this.value = parent.value;\n  this.key = parent.key;\n  this.mode = parent.mode;\n  this.emit(value);\n  if (!this.mode) { this.state = VALUE; }\n};\nproto.emit = function (value) {\n  if (this.mode) { this.state = COMMA; }\n  this.onValue(value);\n};\nproto.onValue = function (value) {\n  // Override me\n};\nproto.onToken = function (token, value) {\n  if(this.state === VALUE){\n    if(token === STRING || token === NUMBER || token === TRUE || token === FALSE || token === NULL){\n      if (this.value) {\n        this.value[this.key] = value;\n      }\n      this.emit(value);\n    }else if(token === LEFT_BRACE){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = {};\n      } else {\n        this.value = {};\n      }\n      this.key = undefined;\n      this.state = KEY;\n      this.mode = OBJECT;\n    }else if(token === LEFT_BRACKET){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = [];\n      } else {\n        this.value = [];\n      }\n      this.key = 0;\n      this.mode = ARRAY;\n      this.state = VALUE;\n    }else if(token === RIGHT_BRACE){\n      if (this.mode === OBJECT) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else if(token === RIGHT_BRACKET){\n      if (this.mode === ARRAY) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else{\n      return this.parseError(token, value);\n    }\n  }else if(this.state === KEY){\n    if (token === STRING) {\n      this.key = value;\n      this.state = COLON;\n    } else if (token === RIGHT_BRACE) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else if(this.state === COLON){\n    if (token === COLON) { this.state = VALUE; }\n    else { return this.parseError(token, value); }\n  }else if(this.state === COMMA){\n    if (token === COMMA) {\n      if (this.mode === ARRAY) { this.key++; this.state = VALUE; }\n      else if (this.mode === OBJECT) { this.state = KEY; }\n\n    } else if (token === RIGHT_BRACKET && this.mode === ARRAY || token === RIGHT_BRACE && this.mode === OBJECT) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else{\n    return this.parseError(token, value);\n  }\n};\n\nParser.C = C;\n\nmodule.exports = Parser;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/jsonparse/jsonparse.js',
          'importMap': {},
          'packageName': 'jsonparse',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/jsonparse/jsonparse.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/labeled-stream-splicer/index.js': {
        'moduleRecord': {
          'content': "var Splicer = require('stream-splicer');\nvar inherits = require('inherits');\n\nmodule.exports = Labeled;\ninherits(Labeled, Splicer);\n\nmodule.exports.obj = function (streams, opts) {\n    if (!opts) opts = {};\n    opts.objectMode = true;\n    return new Labeled(streams, opts);\n};\n\nfunction Labeled (streams, opts) {\n    if (!(this instanceof Labeled)) return new Labeled(streams, opts);\n    Splicer.call(this, [], opts);\n    \n    var reps = [];\n    for (var i = 0; i < streams.length; i++) {\n        var s = streams[i];\n        if (typeof s === 'string') continue;\n        if (Array.isArray(s)) {\n            s = new Labeled(s, opts);\n        }\n        if (i >= 0 && typeof streams[i-1] === 'string') {\n            s.label = streams[i-1];\n        }\n        reps.push(s);\n    }\n    if (typeof streams[i-1] === 'string') {\n        reps.push(new Labeled([], opts));\n    }\n    this.splice.apply(this, [0,0].concat(reps));\n}\n\nLabeled.prototype.indexOf = function (stream) {\n    if (typeof stream === 'string') {\n        for (var i = 0; i < this._streams.length; i++) {\n            if (this._streams[i].label === stream) return i;\n        }\n        return -1;\n    }\n    else {\n        return Splicer.prototype.indexOf.call(this, stream);\n    }\n};\n\nLabeled.prototype.get = function (key) {\n    if (typeof key === 'string') {\n        var ix = this.indexOf(key);\n        if (ix < 0) return undefined;\n        return this._streams[ix];\n    }\n    else return Splicer.prototype.get.call(this, key);\n};\n\nLabeled.prototype.splice = function (key) {\n    var ix;\n    if (typeof key === 'string') {\n        ix = this.indexOf(key);\n    }\n    else ix = key;\n    var args = [ ix ].concat([].slice.call(arguments, 1));\n    return Splicer.prototype.splice.apply(this, args);\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/labeled-stream-splicer/index.js',
          'importMap': {
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'stream-splicer': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/index.js',
          },
          'packageName': 'labeled-stream-splicer',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/labeled-stream-splicer/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/lodash.memoize/index.js': {
        'moduleRecord': {
          'content': "/**\n * lodash 3.0.4 (Custom Build) <https://lodash.com/>\n * Build: `lodash modern modularize exports=\"npm\" -o ./`\n * Copyright 2012-2015 The Dojo Foundation <http://dojofoundation.org/>\n * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>\n * Copyright 2009-2015 Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n * Available under MIT license <https://lodash.com/license>\n */\n\n/** Used as the `TypeError` message for \"Functions\" methods. */\nvar FUNC_ERROR_TEXT = 'Expected a function';\n\n/** Used for native method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Creates a cache object to store key/value pairs.\n *\n * @private\n * @static\n * @name Cache\n * @memberOf _.memoize\n */\nfunction MapCache() {\n  this.__data__ = {};\n}\n\n/**\n * Removes `key` and its value from the cache.\n *\n * @private\n * @name delete\n * @memberOf _.memoize.Cache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed successfully, else `false`.\n */\nfunction mapDelete(key) {\n  return this.has(key) && delete this.__data__[key];\n}\n\n/**\n * Gets the cached value for `key`.\n *\n * @private\n * @name get\n * @memberOf _.memoize.Cache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the cached value.\n */\nfunction mapGet(key) {\n  return key == '__proto__' ? undefined : this.__data__[key];\n}\n\n/**\n * Checks if a cached value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf _.memoize.Cache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction mapHas(key) {\n  return key != '__proto__' && hasOwnProperty.call(this.__data__, key);\n}\n\n/**\n * Sets `value` to `key` of the cache.\n *\n * @private\n * @name set\n * @memberOf _.memoize.Cache\n * @param {string} key The key of the value to cache.\n * @param {*} value The value to cache.\n * @returns {Object} Returns the cache object.\n */\nfunction mapSet(key, value) {\n  if (key != '__proto__') {\n    this.__data__[key] = value;\n  }\n  return this;\n}\n\n/**\n * Creates a function that memoizes the result of `func`. If `resolver` is\n * provided it determines the cache key for storing the result based on the\n * arguments provided to the memoized function. By default, the first argument\n * provided to the memoized function is coerced to a string and used as the\n * cache key. The `func` is invoked with the `this` binding of the memoized\n * function.\n *\n * **Note:** The cache is exposed as the `cache` property on the memoized\n * function. Its creation may be customized by replacing the `_.memoize.Cache`\n * constructor with one whose instances implement the [`Map`](https://people.mozilla.org/~jorendorff/es6-draft.html#sec-properties-of-the-map-prototype-object)\n * method interface of `get`, `has`, and `set`.\n *\n * @static\n * @memberOf _\n * @category Function\n * @param {Function} func The function to have its output memoized.\n * @param {Function} [resolver] The function to resolve the cache key.\n * @returns {Function} Returns the new memoizing function.\n * @example\n *\n * var upperCase = _.memoize(function(string) {\n *   return string.toUpperCase();\n * });\n *\n * upperCase('fred');\n * // => 'FRED'\n *\n * // modifying the result cache\n * upperCase.cache.set('fred', 'BARNEY');\n * upperCase('fred');\n * // => 'BARNEY'\n *\n * // replacing `_.memoize.Cache`\n * var object = { 'user': 'fred' };\n * var other = { 'user': 'barney' };\n * var identity = _.memoize(_.identity);\n *\n * identity(object);\n * // => { 'user': 'fred' }\n * identity(other);\n * // => { 'user': 'fred' }\n *\n * _.memoize.Cache = WeakMap;\n * var identity = _.memoize(_.identity);\n *\n * identity(object);\n * // => { 'user': 'fred' }\n * identity(other);\n * // => { 'user': 'barney' }\n */\nfunction memoize(func, resolver) {\n  if (typeof func != 'function' || (resolver && typeof resolver != 'function')) {\n    throw new TypeError(FUNC_ERROR_TEXT);\n  }\n  var memoized = function() {\n    var args = arguments,\n        key = resolver ? resolver.apply(this, args) : args[0],\n        cache = memoized.cache;\n\n    if (cache.has(key)) {\n      return cache.get(key);\n    }\n    var result = func.apply(this, args);\n    memoized.cache = cache.set(key, result);\n    return result;\n  };\n  memoized.cache = new memoize.Cache;\n  return memoized;\n}\n\n// Add functions to the `Map` cache.\nMapCache.prototype['delete'] = mapDelete;\nMapCache.prototype.get = mapGet;\nMapCache.prototype.has = mapHas;\nMapCache.prototype.set = mapSet;\n\n// Assign cache to `_.memoize`.\nmemoize.Cache = MapCache;\n\nmodule.exports = memoize;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/lodash.memoize/index.js',
          'importMap': {},
          'packageName': 'lodash.memoize',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/lodash.memoize/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/index.js': {
        'builtin': [
          'fs.createReadStream',
          'fs.readFile',
          'path.delimiter',
          'path.resolve',
          'path.join',
          'path.dirname',
        ],
        'globals': {
          'process.cwd': 'read',
          'process.env.NODE_PATH': 'read',
          'process.nextTick': 'read',
          'process.platform': 'read',
          'setTimeout': 'read',
          'tr': 'read',
        },
        'moduleRecord': {
          'content': "var fs = require('fs');\nvar path = require('path');\nvar relativePath = require('cached-path-relative');\n\nvar browserResolve = require('browser-resolve');\nvar nodeResolve = require('resolve');\nvar detective = require('detective');\nvar through = require('through2');\nvar concat = require('concat-stream');\nvar parents = require('parents');\nvar combine = require('stream-combiner2');\nvar duplexer = require('duplexer2');\nvar xtend = require('xtend');\nvar defined = require('defined');\n\nvar inherits = require('inherits');\nvar Transform = require('readable-stream').Transform;\n\nmodule.exports = Deps;\ninherits(Deps, Transform);\n\nfunction Deps (opts) {\n    var self = this;\n    if (!(this instanceof Deps)) return new Deps(opts);\n    Transform.call(this, { objectMode: true });\n    \n    if (!opts) opts = {};\n    \n    this.basedir = opts.basedir || process.cwd();\n    this.persistentCache = opts.persistentCache || function (file, id, pkg, fallback, cb) {\n        process.nextTick(function () {\n            fallback(null, cb);\n        });\n    };\n    this.cache = opts.cache;\n    this.fileCache = opts.fileCache;\n    this.pkgCache = opts.packageCache || {};\n    this.pkgFileCache = {};\n    this.pkgFileCachePending = {};\n    this._emittedPkg = {};\n    this._transformDeps = {};\n    this.visited = {};\n    this.walking = {};\n    this.entries = [];\n    this._input = [];\n    \n    this.paths = opts.paths || process.env.NODE_PATH || '';\n    if (typeof this.paths === 'string') {\n        var delimiter = path.delimiter || (process.platform === 'win32' ? ';' : ':');\n        this.paths = this.paths.split(delimiter);\n    }\n    this.paths = this.paths\n        .filter(Boolean)\n        .map(function (p) {\n            return path.resolve(self.basedir, p);\n        });\n    \n    this.transforms = [].concat(opts.transform).filter(Boolean);\n    this.globalTransforms = [].concat(opts.globalTransform).filter(Boolean);\n    this.resolver = opts.resolve || browserResolve;\n    this.detective = opts.detect || detective;\n    this.options = xtend(opts);\n    if (!this.options.modules) this.options.modules = {};\n\n    // If the caller passes options.expose, store resolved pathnames for exposed\n    // modules in it. If not, set it anyway so it's defined later.\n    if (!this.options.expose) this.options.expose = {};\n    this.pending = 0;\n    this.inputPending = 0;\n    \n    var topfile = path.join(this.basedir, '__fake.js');\n    this.top = {\n        id: topfile,\n        filename: topfile,\n        paths: this.paths,\n        basedir: this.basedir\n    };\n}\n\nDeps.prototype._isTopLevel = function (file) {\n    var isTopLevel = this.entries.some(function (main) {\n        var m = relativePath(path.dirname(main), file);\n        return m.split(/[\\\\\\/]/).indexOf('node_modules') < 0;\n    });\n    if (!isTopLevel) {\n        var m = relativePath(this.basedir, file);\n        isTopLevel = m.split(/[\\\\\\/]/).indexOf('node_modules') < 0;\n    }\n    return isTopLevel;\n};\n\nDeps.prototype._transform = function (row, enc, next) {\n    var self = this;\n    if (typeof row === 'string') {\n        row = { file: row };\n    }\n    if (row.transform && row.global) {\n        this.globalTransforms.push([ row.transform, row.options ]);\n        return next();\n    }\n    else if (row.transform) {\n        this.transforms.push([ row.transform, row.options ]);\n        return next();\n    }\n    \n    self.pending ++;\n    var basedir = defined(row.basedir, self.basedir);\n    \n    if (row.entry !== false) {\n        self.entries.push(path.resolve(basedir, row.file || row.id));\n    }\n    \n    self.lookupPackage(row.file, function (err, pkg) {\n        if (err && self.options.ignoreMissing) {\n            self.emit('missing', row.file, self.top);\n            self.pending --;\n            return next();\n        }\n        if (err) return self.emit('error', err)\n        self.pending --;\n        self._input.push({ row: row, pkg: pkg });\n        next();\n    });\n};\n\nDeps.prototype._flush = function () {\n    var self = this;\n    var files = {};\n    self._input.forEach(function (r) {\n        var w = r.row, f = files[w.file || w.id];\n        if (f) {\n            f.row.entry = f.row.entry || w.entry;\n            var ex = f.row.expose || w.expose;\n            f.row.expose = ex;\n            if (ex && f.row.file === f.row.id && w.file !== w.id) {\n                f.row.id = w.id;\n            }\n        }\n        else files[w.file || w.id] = r;\n    });\n    \n    Object.keys(files).forEach(function (key) {\n        var r = files[key];\n        var pkg = r.pkg || {};\n        var dir = r.row.file ? path.dirname(r.row.file) : self.basedir;\n        if (!pkg.__dirname) pkg.__dirname = dir;\n        self.walk(r.row, xtend(self.top, {\n            filename: path.join(dir, '_fake.js')\n        }));\n    });\n    if (this.pending === 0) this.push(null);\n    this._ended = true;\n};\n\nDeps.prototype.resolve = function (id, parent, cb) {\n    var self = this;\n    var opts = self.options;\n    \n    if (xhas(self.cache, parent.id, 'deps', id)\n    && self.cache[parent.id].deps[id]) {\n        var file = self.cache[parent.id].deps[id];\n        var pkg = self.pkgCache[file];\n        if (pkg) return cb(null, file, pkg);\n        return self.lookupPackage(file, function (err, pkg) {\n            cb(null, file, pkg);\n        });\n    }\n    \n    parent.packageFilter = function (p, x) {\n        var pkgdir = path.dirname(x);\n        if (opts.packageFilter) p = opts.packageFilter(p, x);\n        p.__dirname = pkgdir;\n\n        return p;\n    };\n\n    // have `resolve` do all the package.json lookups,\n    // see discussion in https://github.com/browserify/browser-resolve/issues/93#issuecomment-667837808\n    parent.package = undefined;\n    \n    if (opts.extensions) parent.extensions = opts.extensions;\n    if (opts.modules) parent.modules = opts.modules;\n    \n    self.resolver(id, parent, function onresolve (err, file, pkg, fakePath) {\n        if (err) return cb(err);\n        if (!file) return cb(new Error(\n            'module not found: \"' + id + '\" from file '\n            + parent.filename\n        ));\n        \n        if (!pkg || !pkg.__dirname) {\n            self.lookupPackage(file, function (err, p) {\n                if (err) return cb(err);\n                if (!p) p = {};\n                if (!p.__dirname) p.__dirname = path.dirname(file);\n                self.pkgCache[file] = p;\n                onresolve(err, file, opts.packageFilter\n                    ? opts.packageFilter(p, p.__dirname) : p,\n                    fakePath\n                );\n            });\n        }\n        else cb(err, file, pkg, fakePath);\n    });\n};\n\nDeps.prototype.readFile = function (file, id, pkg) {\n    var self = this;\n    if (xhas(this.fileCache, file)) {\n        return toStream(this.fileCache[file]);\n    }\n    var rs = fs.createReadStream(file, {\n        encoding: 'utf8'\n    });\n    return rs;\n};\n\nDeps.prototype.getTransforms = function (file, pkg, opts) {\n    if (!opts) opts = {};\n    var self = this;\n    \n    var isTopLevel;\n    if (opts.builtin || opts.inNodeModules) isTopLevel = false;\n    else isTopLevel = this._isTopLevel(file);\n    \n    var transforms = [].concat(isTopLevel ? this.transforms : [])\n        .concat(getTransforms(pkg, {\n            globalTransform: this.globalTransforms,\n            transformKey: this.options.transformKey\n        }))\n    ;\n    if (transforms.length === 0) return through();\n    \n    var pending = transforms.length;\n    var streams = [];\n    var input = through();\n    var output = through();\n    var dup = duplexer(input, output);\n    \n    for (var i = 0; i < transforms.length; i++) (function (i) {\n        makeTransform(transforms[i], function (err, trs) {\n            if (err) {\n                return dup.emit('error', err);\n            }\n            streams[i] = trs;\n            if (-- pending === 0) done();\n        });\n    })(i);\n    return dup;\n    \n    function done () {\n        var middle = combine.apply(null, streams);\n        middle.on('error', function (err) {\n            err.message += ' while parsing file: ' + file;\n            if (!err.filename) err.filename = file;\n            dup.emit('error', err);\n        });\n        input.pipe(middle).pipe(output);\n    }\n    \n    function makeTransform (tr, cb) {\n        var trOpts = {};\n        if (Array.isArray(tr)) {\n            trOpts = tr[1] || {};\n            tr = tr[0];\n        }\n        trOpts._flags = trOpts.hasOwnProperty('_flags') ? trOpts._flags : self.options;\n        if (typeof tr === 'function') {\n            var t = tr(file, trOpts);\n            // allow transforms to `stream.emit('dep', path)` to add dependencies for this file\n            t.on('dep', function (dep) {\n                if (!self._transformDeps[file]) self._transformDeps[file] = [];\n                self._transformDeps[file].push(dep);\n            });\n            self.emit('transform', t, file);\n            nextTick(cb, null, wrapTransform(t));\n        }\n        else {\n            loadTransform(tr, trOpts, function (err, trs) {\n                if (err) return cb(err);\n                cb(null, wrapTransform(trs));\n            });\n        }\n    }\n    \n    function loadTransform (id, trOpts, cb) {\n        var params = {\n            basedir: path.dirname(file),\n            preserveSymlinks: false\n        };\n        nodeResolve(id, params, function nr (err, res, again) {\n            if (err && again) return cb && cb(err);\n            \n            if (err) {\n                params.basedir = pkg.__dirname;\n                return nodeResolve(id, params, function (e, r) {\n                    nr(e, r, true);\n                });\n            }\n            \n            if (!res) return cb(new Error(\n                'cannot find transform module ' + tr\n                + ' while transforming ' + file\n            ));\n            \n            var r = require(res);\n            if (typeof r !== 'function') {\n                return cb(new Error(\n                    'Unexpected ' + typeof r + ' exported by the '\n                    + JSON.stringify(res) + ' package. '\n                    + 'Expected a transform function.'\n                ));\n            }\n            \n            var trs = r(file, trOpts);\n            // allow transforms to `stream.emit('dep', path)` to add dependencies for this file\n            trs.on('dep', function (dep) {\n                if (!self._transformDeps[file]) self._transformDeps[file] = [];\n                self._transformDeps[file].push(dep);\n            });\n            self.emit('transform', trs, file);\n            cb(null, trs);\n        });\n    }\n};\n\nDeps.prototype.walk = function (id, parent, cb) {\n    var self = this;\n    var opts = self.options;\n    this.pending ++;\n    \n    var rec = {};\n    var input;\n    if (typeof id === 'object') {\n        rec = xtend(id);\n        if (rec.entry === false) delete rec.entry;\n        id = rec.file || rec.id;\n        input = true;\n        this.inputPending ++;\n    }\n    \n    self.resolve(id, parent, function (err, file, pkg, fakePath) {\n        // this is checked early because parent.modules is also modified\n        // by this function.\n        var builtin = has(parent.modules, id);\n\n        if (rec.expose) {\n            // Set options.expose to make the resolved pathname available to the\n            // caller. They may or may not have requested it, but it's harmless\n            // to set this if they didn't.\n            self.options.expose[rec.expose] =\n                self.options.modules[rec.expose] = file;\n        }\n        if (pkg && !self._emittedPkg[pkg.__dirname]) {\n            self._emittedPkg[pkg.__dirname] = true;\n            self.emit('package', pkg);\n        }\n        \n        if (opts.postFilter && !opts.postFilter(id, file, pkg)) {\n            if (--self.pending === 0) self.push(null);\n            if (input) --self.inputPending;\n            return cb && cb(null, undefined);\n        }\n        if (err && rec.source) {\n            file = rec.file;\n            \n            var ts = self.getTransforms(file, pkg);\n            ts.on('error', function (err) {\n                self.emit('error', err);\n            });\n            ts.pipe(concat(function (body) {\n                rec.source = body.toString('utf8');\n                fromSource(file, rec.source, pkg);\n            }));\n            return ts.end(rec.source);\n        }\n        if (err && self.options.ignoreMissing) {\n            if (--self.pending === 0) self.push(null);\n            if (input) --self.inputPending;\n            self.emit('missing', id, parent);\n            return cb && cb(null, undefined);\n        }\n        if (err) {\n            var message = 'Can\\'t walk dependency graph: ' + err.message;\n            message += '\\n    required by ' + parent.filename;\n            err.message = message;\n            return self.emit('error', err);\n        }\n        if (self.visited[file]) {\n            if (-- self.pending === 0) self.push(null);\n            if (input) --self.inputPending;\n            return cb && cb(null, file);\n        }\n        self.visited[file] = true;\n        \n        if (rec.source) {\n            var ts = self.getTransforms(file, pkg);\n            ts.on('error', function (err) {\n                self.emit('error', err);\n            });\n            ts.pipe(concat(function (body) {\n                rec.source = body.toString('utf8');\n                fromSource(file, rec.source, pkg);\n            }));\n            return ts.end(rec.source);\n        }\n        \n        var c = self.cache && self.cache[file];\n        if (c) return fromDeps(file, c.source, c.package, fakePath, Object.keys(c.deps));\n        \n        self.persistentCache(file, id, pkg, persistentCacheFallback, function (err, c) {\n            self.emit('file', file, id);\n            if (err) {\n                self.emit('error', err);\n                return;\n            }\n            fromDeps(file, c.source, c.package, fakePath, Object.keys(c.deps));\n        });\n\n        function persistentCacheFallback (dataAsString, cb) {\n            var stream = dataAsString ? toStream(dataAsString) : self.readFile(file, id, pkg).on('error', cb);\n            stream\n                .pipe(self.getTransforms(fakePath || file, pkg, {\n                    builtin: builtin,\n                    inNodeModules: parent.inNodeModules\n                }))\n                .on('error', cb)\n                .pipe(concat(function (body) {\n                    var src = body.toString('utf8');\n                    try { var deps = getDeps(file, src); }\n                    catch (err) { cb(err); }\n                    if (deps) {\n                        cb(null, {\n                            source: src,\n                            package: pkg,\n                            deps: deps.reduce(function (deps, dep) {\n                                deps[dep] = true;\n                                return deps;\n                            }, {})\n                        });\n                    }\n                }));\n        }\n    });\n\n    function getDeps (file, src) {\n        var deps = rec.noparse ? [] : self.parseDeps(file, src);\n        // dependencies emitted by transforms\n        if (self._transformDeps[file]) deps = deps.concat(self._transformDeps[file]);\n        return deps;\n    }\n\n    function fromSource (file, src, pkg, fakePath) {\n        var deps = getDeps(file, src);\n        if (deps) fromDeps(file, src, pkg, fakePath, deps);\n    }\n    \n    function fromDeps (file, src, pkg, fakePath, deps) {\n        var p = deps.length;\n        var resolved = {};\n        \n        if (input) --self.inputPending;\n        \n        (function resolve () {\n            if (self.inputPending > 0) return setTimeout(resolve);\n            deps.forEach(function (id) {\n                if (opts.filter && !opts.filter(id)) {\n                    resolved[id] = false;\n                    if (--p === 0) done();\n                    return;\n                }\n                var isTopLevel = self._isTopLevel(fakePath || file);\n                var current = {\n                    id: file,\n                    filename: file,\n                    basedir: path.dirname(file),\n                    paths: self.paths,\n                    package: pkg,\n                    inNodeModules: parent.inNodeModules || !isTopLevel\n                };\n                self.walk(id, current, function (err, r) {\n                    resolved[id] = r;\n                    if (--p === 0) done();\n                });\n            });\n            if (deps.length === 0) done();\n        })();\n        \n        function done () {\n            if (!rec.id) rec.id = file;\n            if (!rec.source) rec.source = src;\n            if (!rec.deps) rec.deps = resolved;\n            if (!rec.file) rec.file = file;\n            \n            if (self.entries.indexOf(file) >= 0) {\n                rec.entry = true;\n            }\n            self.push(rec);\n            \n            if (cb) cb(null, file);\n            if (-- self.pending === 0) self.push(null);\n        }\n    }\n};\n\nDeps.prototype.parseDeps = function (file, src, cb) {\n    var self = this;\n    if (this.options.noParse === true) return [];\n    if (/\\.json$/.test(file)) return [];\n    \n    if (Array.isArray(this.options.noParse)\n    && this.options.noParse.indexOf(file) >= 0) {\n        return [];\n    }\n    \n    try { var deps = self.detective(src) }\n    catch (ex) {\n        var message = ex && ex.message ? ex.message : ex;\n        throw new Error(\n            'Parsing file ' + file + ': ' + message\n        );\n    }\n    return deps;\n};\n\nDeps.prototype.lookupPackage = function (file, cb) {\n    var self = this;\n    \n    var cached = this.pkgCache[file];\n    if (cached) return nextTick(cb, null, cached);\n    if (cached === false) return nextTick(cb, null, undefined);\n    \n    var dirs = parents(file ? path.dirname(file) : self.basedir);\n    \n    (function next () {\n        if (dirs.length === 0) {\n            self.pkgCache[file] = false;\n            return cb(null, undefined);\n        }\n        var dir = dirs.shift();\n        if (dir.split(/[\\\\\\/]/).slice(-1)[0] === 'node_modules') {\n            return cb(null, undefined);\n        }\n        \n        var pkgfile = path.join(dir, 'package.json');\n        \n        var cached = self.pkgCache[pkgfile];\n        if (cached) return nextTick(cb, null, cached);\n        else if (cached === false) return next();\n        \n        var pcached = self.pkgFileCachePending[pkgfile];\n        if (pcached) return pcached.push(onpkg);\n        pcached = self.pkgFileCachePending[pkgfile] = [];\n        \n        fs.readFile(pkgfile, function (err, src) {\n            if (err) return onpkg();\n            try { var pkg = JSON.parse(src) }\n            catch (err) {\n                return onpkg(new Error([\n                    err + ' while parsing json file ' + pkgfile\n                ].join('')));\n            }\n            pkg.__dirname = dir;\n            \n            self.pkgCache[pkgfile] = pkg;\n            self.pkgCache[file] = pkg;\n            onpkg(null, pkg);\n        });\n        \n        function onpkg (err, pkg) {\n            if (self.pkgFileCachePending[pkgfile]) {\n                var fns = self.pkgFileCachePending[pkgfile];\n                delete self.pkgFileCachePending[pkgfile];\n                fns.forEach(function (f) { f(err, pkg) });\n            }\n            if (err) cb(err);\n            else if (pkg && typeof pkg === 'object') cb(null, pkg);\n            else {\n                self.pkgCache[pkgfile] = false;\n                next();\n            }\n        }\n    })();\n};\n \nfunction getTransforms (pkg, opts) {\n    var trx = [];\n    if (opts.transformKey) {\n        var n = pkg;\n        var keys = opts.transformKey;\n        for (var i = 0; i < keys.length; i++) {\n            if (n && typeof n === 'object') n = n[keys[i]];\n            else break;\n        }\n        if (i === keys.length) {\n            trx = [].concat(n).filter(Boolean);\n        }\n    }\n    return trx.concat(opts.globalTransform || []);\n}\n\nfunction nextTick (cb) {\n    var args = [].slice.call(arguments, 1);\n    process.nextTick(function () { cb.apply(null, args) });\n}\n\nfunction xhas (obj) {\n    if (!obj) return false;\n    for (var i = 1; i < arguments.length; i++) {\n        var key = arguments[i];\n        if (!has(obj, key)) return false;\n        obj = obj[key];\n    }\n    return true;\n}\n\nfunction toStream (dataAsString) {\n    var tr = through();\n    tr.push(dataAsString);\n    tr.push(null);\n    return tr;\n}\n\nfunction has (obj, key) {\n    return obj && Object.prototype.hasOwnProperty.call(obj, key);\n}\n\nfunction wrapTransform (tr) {\n    if (typeof tr.read === 'function') return tr;\n    var input = through(), output = through();\n    input.pipe(tr).pipe(output);\n    var wrapper = duplexer(input, output);\n    tr.on('error', function (err) { wrapper.emit('error', err) });\n    return wrapper;\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/index.js',
          'importMap': {
            'browser-resolve': '/home/xyz/Development/webtorrent/node_modules/browser-resolve/index.js',
            'cached-path-relative': '/home/xyz/Development/webtorrent/node_modules/cached-path-relative/lib/index.js',
            'concat-stream': '/home/xyz/Development/webtorrent/node_modules/concat-stream/index.js',
            'defined': '/home/xyz/Development/webtorrent/node_modules/defined/index.js',
            'detective': '/home/xyz/Development/webtorrent/node_modules/detective/index.js',
            'duplexer2': '/home/xyz/Development/webtorrent/node_modules/duplexer2/index.js',
            'fs': 'fs',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'parents': '/home/xyz/Development/webtorrent/node_modules/parents/index.js',
            'path': 'path',
            'readable-stream': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/readable.js',
            'resolve': '/home/xyz/Development/webtorrent/node_modules/resolve/index.js',
            'stream-combiner2': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/index.js',
            'through2': '/home/xyz/Development/webtorrent/node_modules/through2/through2.js',
            'xtend': '/home/xyz/Development/webtorrent/node_modules/xtend/immutable.js',
          },
          'packageName': 'module-deps',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/index.js',
          'type': 'js',
        },
        'sesCompat': {
          'dynamicRequires': [
            {
              'node': {
                'loc': {
                  'end': {
                    'column': 32,
                    'line': 306,
                  },
                  'start': {
                    'column': 20,
                    'line': 306,
                  },
                },
              },
            },
          ],
          'primordialMutations': [],
          'strictModeViolations': [],
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_duplex.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_duplex.js',
          'importMap': {
            './_stream_readable': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_readable.js',
            './_stream_writable': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_writable.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_duplex.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_passthrough.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_passthrough.js',
          'importMap': {
            './_stream_transform': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_transform.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_passthrough.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_readable.js': {
        'builtin': [
          'events.EventEmitter',
          'util',
          'util.debuglog',
        ],
        'globals': {
          'process.stderr': 'read',
          'process.stdout': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar destroyImpl = require('./internal/streams/destroy');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_readable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/BufferList': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/BufferList.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'events': 'events',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'isarray': '/home/xyz/Development/webtorrent/node_modules/isarray/index.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/safe-buffer/index.js',
            'string_decoder/': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/string_decoder/lib/string_decoder.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_transform.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_transform.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_duplex.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_transform.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_writable.js': {
        'globals': {
          'process.browser': 'read',
          'process.version.slice': 'read',
          'setImmediate': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_writable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/safe-buffer/index.js',
            'util-deprecate': '/home/xyz/Development/webtorrent/node_modules/util-deprecate/node.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_writable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/BufferList.js': {
        'builtin': [
          'util',
          'util.inspect',
          'util.inspect.custom',
        ],
        'moduleRecord': {
          'content': "'use strict';\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = require('safe-buffer').Buffer;\nvar util = require('util');\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/safe-buffer/index.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/destroy.js': {
        'moduleRecord': {
          'content': "'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'importMap': {
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/stream.js': {
        'builtin': [
          'stream',
        ],
        'moduleRecord': {
          'content': "module.exports = require('stream');\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/stream.js',
          'importMap': {
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/internal/streams/stream.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/readable.js': {
        'builtin': [
          'stream',
          'stream.Readable',
          'stream.Writable',
          'stream.Duplex',
          'stream.Transform',
          'stream.PassThrough',
        ],
        'globals': {
          'process.env.READABLE_STREAM': 'read',
        },
        'moduleRecord': {
          'content': "var Stream = require('stream');\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n  exports = module.exports = Stream.Readable;\n  exports.Readable = Stream.Readable;\n  exports.Writable = Stream.Writable;\n  exports.Duplex = Stream.Duplex;\n  exports.Transform = Stream.Transform;\n  exports.PassThrough = Stream.PassThrough;\n  exports.Stream = Stream;\n} else {\n  exports = module.exports = require('./lib/_stream_readable.js');\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = require('./lib/_stream_writable.js');\n  exports.Duplex = require('./lib/_stream_duplex.js');\n  exports.Transform = require('./lib/_stream_transform.js');\n  exports.PassThrough = require('./lib/_stream_passthrough.js');\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/readable.js',
          'importMap': {
            './lib/_stream_duplex.js': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_duplex.js',
            './lib/_stream_passthrough.js': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_passthrough.js',
            './lib/_stream_readable.js': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_readable.js',
            './lib/_stream_transform.js': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_transform.js',
            './lib/_stream_writable.js': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/lib/_stream_writable.js',
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/readable-stream/readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/safe-buffer/index.js': {
        'builtin': [
          'buffer.Buffer',
          'buffer',
          'buffer.SlowBuffer',
        ],
        'moduleRecord': {
          'content': "/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/safe-buffer/index.js',
          'importMap': {
            'buffer': 'buffer',
          },
          'packageName': 'safe-buffer',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/safe-buffer/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/string_decoder/lib/string_decoder.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/string_decoder/lib/string_decoder.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/safe-buffer/index.js',
          },
          'packageName': 'string_decoder',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/module-deps/node_modules/string_decoder/lib/string_decoder.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/package-json-versionify/index.js': {
        'moduleRecord': {
          'content': "'use strict'\nconst browserifyPackageJSON = require('browserify-package-json')\n\nmodule.exports = function (filename, options) {\n  return browserifyPackageJSON(filename, Object.assign(options || {}, { only: 'version' }))\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/package-json-versionify/index.js',
          'importMap': {
            'browserify-package-json': '/home/xyz/Development/webtorrent/node_modules/browserify-package-json/index.js',
          },
          'packageName': 'package-json-versionify',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/package-json-versionify/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/parents/index.js': {
        'globals': {
          'process.cwd': 'read',
          'process.platform': 'read',
        },
        'moduleRecord': {
          'content': "var pathPlatform = require('path-platform');\n\nmodule.exports = function (cwd, opts) {\n    if (cwd === undefined) cwd = process.cwd();\n    if (!opts) opts = {};\n    var platform = opts.platform || process.platform;\n    \n    var isWindows = /^win/.test(platform);\n    var path = isWindows ? pathPlatform.win32 : pathPlatform;\n    var normalize = !isWindows ? path.normalize :\n        path.normalize('c:') === 'c:.' ? fixNormalize(path.normalize) :\n        path.normalize;\n    var sep = isWindows ? /[\\\\\\/]/ : '/';\n    var init = isWindows ? '' : '/';\n    \n    var join = function (x, y) {\n        var ps = [ x, y ].filter(function (p) {\n            return p && typeof p === 'string'\n        });\n\n        return normalize(ps.join(isWindows ? '\\\\' : '/'));\n    };\n    \n    var res = normalize(cwd)\n        .split(sep)\n        .reduce(function (acc,dir,ix) {\n            return acc.concat(join(acc[ix], dir))\n        }, [init])\n        .slice(1)\n        .reverse()\n    ;\n    if (res[0] === res[1]) return [ res[0] ];\n    if (isWindows && /^\\\\/.test(cwd)) {\n        return res.slice(0,-1).map(function (d) {\n            var ch = d.charAt(0)\n            return ch === '\\\\' ? d :\n              ch === '.' ? '\\\\' + d.slice(1) :\n              '\\\\' + d\n        });\n    }\n    return res;\n\n    function fixNormalize(fn) {\n      return function(p) {\n        return fn(p).replace(/:\\.$/, ':')\n      }\n    }\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/parents/index.js',
          'importMap': {
            'path-platform': '/home/xyz/Development/webtorrent/node_modules/path-platform/path.js',
          },
          'packageName': 'parents',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/parents/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/path-is-absolute/index.js': {
        'globals': {
          'process.platform': 'read',
        },
        'moduleRecord': {
          'content': "'use strict';\n\nfunction posix(path) {\n\treturn path.charAt(0) === '/';\n}\n\nfunction win32(path) {\n\t// https://github.com/nodejs/node/blob/b3fcc245fb25539909ef1d5eaa01dbf92e168633/lib/path.js#L56\n\tvar splitDeviceRe = /^([a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/]+[^\\\\\\/]+)?([\\\\\\/])?([\\s\\S]*?)$/;\n\tvar result = splitDeviceRe.exec(path);\n\tvar device = result[1] || '';\n\tvar isUnc = Boolean(device && device.charAt(1) !== ':');\n\n\t// UNC paths are always absolute\n\treturn Boolean(result[2] || isUnc);\n}\n\nmodule.exports = process.platform === 'win32' ? win32 : posix;\nmodule.exports.posix = posix;\nmodule.exports.win32 = win32;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/path-is-absolute/index.js',
          'importMap': {},
          'packageName': 'path-is-absolute',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/path-is-absolute/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/path-parse/index.js': {
        'globals': {
          'process.platform': 'read',
        },
        'moduleRecord': {
          'content': "'use strict';\n\nvar isWindows = process.platform === 'win32';\n\n// Regex to split a windows path into three parts: [*, device, slash,\n// tail] windows-only\nvar splitDeviceRe =\n    /^([a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/]+[^\\\\\\/]+)?([\\\\\\/])?([\\s\\S]*?)$/;\n\n// Regex to split the tail part of the above into [*, dir, basename, ext]\nvar splitTailRe =\n    /^([\\s\\S]*?)((?:\\.{1,2}|[^\\\\\\/]+?|)(\\.[^.\\/\\\\]*|))(?:[\\\\\\/]*)$/;\n\nvar win32 = {};\n\n// Function to split a filename into [root, dir, basename, ext]\nfunction win32SplitPath(filename) {\n  // Separate device+slash from tail\n  var result = splitDeviceRe.exec(filename),\n      device = (result[1] || '') + (result[2] || ''),\n      tail = result[3] || '';\n  // Split the tail into dir, basename and extension\n  var result2 = splitTailRe.exec(tail),\n      dir = result2[1],\n      basename = result2[2],\n      ext = result2[3];\n  return [device, dir, basename, ext];\n}\n\nwin32.parse = function(pathString) {\n  if (typeof pathString !== 'string') {\n    throw new TypeError(\n        \"Parameter 'pathString' must be a string, not \" + typeof pathString\n    );\n  }\n  var allParts = win32SplitPath(pathString);\n  if (!allParts || allParts.length !== 4) {\n    throw new TypeError(\"Invalid path '\" + pathString + \"'\");\n  }\n  return {\n    root: allParts[0],\n    dir: allParts[0] + allParts[1].slice(0, -1),\n    base: allParts[2],\n    ext: allParts[3],\n    name: allParts[2].slice(0, allParts[2].length - allParts[3].length)\n  };\n};\n\n\n\n// Split a filename into [root, dir, basename, ext], unix version\n// 'root' is just a slash, or nothing.\nvar splitPathRe =\n    /^(\\/?|)([\\s\\S]*?)((?:\\.{1,2}|[^\\/]+?|)(\\.[^.\\/]*|))(?:[\\/]*)$/;\nvar posix = {};\n\n\nfunction posixSplitPath(filename) {\n  return splitPathRe.exec(filename).slice(1);\n}\n\n\nposix.parse = function(pathString) {\n  if (typeof pathString !== 'string') {\n    throw new TypeError(\n        \"Parameter 'pathString' must be a string, not \" + typeof pathString\n    );\n  }\n  var allParts = posixSplitPath(pathString);\n  if (!allParts || allParts.length !== 4) {\n    throw new TypeError(\"Invalid path '\" + pathString + \"'\");\n  }\n  allParts[1] = allParts[1] || '';\n  allParts[2] = allParts[2] || '';\n  allParts[3] = allParts[3] || '';\n\n  return {\n    root: allParts[0],\n    dir: allParts[0] + allParts[1].slice(0, -1),\n    base: allParts[2],\n    ext: allParts[3],\n    name: allParts[2].slice(0, allParts[2].length - allParts[3].length)\n  };\n};\n\n\nif (isWindows)\n  module.exports = win32.parse;\nelse /* posix */\n  module.exports = posix.parse;\n\nmodule.exports.posix = posix.parse;\nmodule.exports.win32 = win32.parse;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/path-parse/index.js',
          'importMap': {},
          'packageName': 'path-parse',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/path-parse/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/path-platform/path.js': {
        'builtin': [
          'util.isString',
          'util.isObject',
          'path.posix',
          'path',
        ],
        'globals': {
          'process.cwd': 'read',
          'process.env': 'read',
          'process.platform': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\nvar isWindows = process.platform === 'win32';\nvar util = require('util');\n\nvar _path = require('path');\n\n// we are new enough we already have this from the system, just export the\n// system then\nif (_path.posix) {\n  module.exports = _path;\n  return;\n}\n\n// resolves . and .. elements in a path array with directory names there\n// must be no slashes or device names (c:\\) in the array\n// (so also no leading and trailing slashes - it does not distinguish\n// relative and absolute paths)\nfunction normalizeArray(parts, allowAboveRoot) {\n  var res = [];\n  for (var i = 0; i < parts.length; i++) {\n    var p = parts[i];\n\n    // ignore empty parts\n    if (!p || p === '.')\n      continue;\n\n    if (p === '..') {\n      if (res.length && res[res.length - 1] !== '..') {\n        res.pop();\n      } else if (allowAboveRoot) {\n        res.push('..');\n      }\n    } else {\n      res.push(p);\n    }\n  }\n\n  return res;\n}\n\n// Regex to split a windows path into three parts: [*, device, slash,\n// tail] windows-only\nvar splitDeviceRe =\n    /^([a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/]+[^\\\\\\/]+)?([\\\\\\/])?([\\s\\S]*?)$/;\n\n// Regex to split the tail part of the above into [*, dir, basename, ext]\nvar splitTailRe =\n    /^([\\s\\S]*?)((?:\\.{1,2}|[^\\\\\\/]+?|)(\\.[^.\\/\\\\]*|))(?:[\\\\\\/]*)$/;\n\nvar win32 = {};\n\n// Function to split a filename into [root, dir, basename, ext]\nfunction win32SplitPath(filename) {\n  // Separate device+slash from tail\n  var result = splitDeviceRe.exec(filename),\n      device = (result[1] || '') + (result[2] || ''),\n      tail = result[3] || '';\n  // Split the tail into dir, basename and extension\n  var result2 = splitTailRe.exec(tail),\n      dir = result2[1],\n      basename = result2[2],\n      ext = result2[3];\n  return [device, dir, basename, ext];\n}\n\nvar normalizeUNCRoot = function(device) {\n  return '\\\\\\\\' + device.replace(/^[\\\\\\/]+/, '').replace(/[\\\\\\/]+/g, '\\\\');\n};\n\n// path.resolve([from ...], to)\nwin32.resolve = function() {\n  var resolvedDevice = '',\n      resolvedTail = '',\n      resolvedAbsolute = false;\n\n  for (var i = arguments.length - 1; i >= -1; i--) {\n    var path;\n    if (i >= 0) {\n      path = arguments[i];\n    } else if (!resolvedDevice) {\n      path = process.cwd();\n    } else {\n      // Windows has the concept of drive-specific current working\n      // directories. If we've resolved a drive letter but not yet an\n      // absolute path, get cwd for that drive. We're sure the device is not\n      // an unc path at this points, because unc paths are always absolute.\n      path = process.env['=' + resolvedDevice];\n      // Verify that a drive-local cwd was found and that it actually points\n      // to our drive. If not, default to the drive's root.\n      if (!path || path.substr(0, 3).toLowerCase() !==\n          resolvedDevice.toLowerCase() + '\\\\') {\n        path = resolvedDevice + '\\\\';\n      }\n    }\n\n    // Skip empty and invalid entries\n    if (!util.isString(path)) {\n      throw new TypeError('Arguments to path.resolve must be strings');\n    } else if (!path) {\n      continue;\n    }\n\n    var result = splitDeviceRe.exec(path),\n        device = result[1] || '',\n        isUnc = device && device.charAt(1) !== ':',\n        isAbsolute = win32.isAbsolute(path),\n        tail = result[3];\n\n    if (device &&\n        resolvedDevice &&\n        device.toLowerCase() !== resolvedDevice.toLowerCase()) {\n      // This path points to another device so it is not applicable\n      continue;\n    }\n\n    if (!resolvedDevice) {\n      resolvedDevice = device;\n    }\n    if (!resolvedAbsolute) {\n      resolvedTail = tail + '\\\\' + resolvedTail;\n      resolvedAbsolute = isAbsolute;\n    }\n\n    if (resolvedDevice && resolvedAbsolute) {\n      break;\n    }\n  }\n\n  // Convert slashes to backslashes when `resolvedDevice` points to an UNC\n  // root. Also squash multiple slashes into a single one where appropriate.\n  if (isUnc) {\n    resolvedDevice = normalizeUNCRoot(resolvedDevice);\n  }\n\n  // At this point the path should be resolved to a full absolute path,\n  // but handle relative paths to be safe (might happen when process.cwd()\n  // fails)\n\n  // Normalize the tail path\n  resolvedTail = normalizeArray(resolvedTail.split(/[\\\\\\/]+/),\n                                !resolvedAbsolute).join('\\\\');\n\n  // If device is a drive letter, we'll normalize to lower case.\n  if (resolvedDevice && resolvedDevice.charAt(1) === ':') {\n    resolvedDevice = resolvedDevice[0].toLowerCase() +\n        resolvedDevice.substr(1);\n  }\n\n  return (resolvedDevice + (resolvedAbsolute ? '\\\\' : '') + resolvedTail) ||\n         '.';\n};\n\n\nwin32.normalize = function(path) {\n  var result = splitDeviceRe.exec(path),\n      device = result[1] || '',\n      isUnc = device && device.charAt(1) !== ':',\n      isAbsolute = win32.isAbsolute(path),\n      tail = result[3],\n      trailingSlash = /[\\\\\\/]$/.test(tail);\n\n  // If device is a drive letter, we'll normalize to lower case.\n  if (device && device.charAt(1) === ':') {\n    device = device[0].toLowerCase() + device.substr(1);\n  }\n\n  // Normalize the tail path\n  tail = normalizeArray(tail.split(/[\\\\\\/]+/), !isAbsolute).join('\\\\');\n\n  if (!tail && !isAbsolute) {\n    tail = '.';\n  }\n  if (tail && trailingSlash) {\n    tail += '\\\\';\n  }\n\n  // Convert slashes to backslashes when `device` points to an UNC root.\n  // Also squash multiple slashes into a single one where appropriate.\n  if (isUnc) {\n    device = normalizeUNCRoot(device);\n  }\n\n  return device + (isAbsolute ? '\\\\' : '') + tail;\n};\n\n\nwin32.isAbsolute = function(path) {\n  var result = splitDeviceRe.exec(path),\n      device = result[1] || '',\n      isUnc = !!device && device.charAt(1) !== ':';\n  // UNC paths are always absolute\n  return !!result[2] || isUnc;\n};\n\nwin32.join = function() {\n  function f(p) {\n    if (!util.isString(p)) {\n      throw new TypeError('Arguments to path.join must be strings');\n    }\n    return p;\n  }\n\n  var paths = Array.prototype.filter.call(arguments, f);\n  var joined = paths.join('\\\\');\n\n  // Make sure that the joined path doesn't start with two slashes, because\n  // normalize() will mistake it for an UNC path then.\n  //\n  // This step is skipped when it is very clear that the user actually\n  // intended to point at an UNC path. This is assumed when the first\n  // non-empty string arguments starts with exactly two slashes followed by\n  // at least one more non-slash character.\n  //\n  // Note that for normalize() to treat a path as an UNC path it needs to\n  // have at least 2 components, so we don't filter for that here.\n  // This means that the user can use join to construct UNC paths from\n  // a server name and a share name; for example:\n  //   path.join('//server', 'share') -> '\\\\\\\\server\\\\share\\')\n  if (!/^[\\\\\\/]{2}[^\\\\\\/]/.test(paths[0])) {\n    joined = joined.replace(/^[\\\\\\/]{2,}/, '\\\\');\n  }\n\n  return win32.normalize(joined);\n};\n\n\n// path.relative(from, to)\n// it will solve the relative path from 'from' to 'to', for instance:\n// from = 'C:\\\\orandea\\\\test\\\\aaa'\n// to = 'C:\\\\orandea\\\\impl\\\\bbb'\n// The output of the function should be: '..\\\\..\\\\impl\\\\bbb'\nwin32.relative = function(from, to) {\n  from = win32.resolve(from);\n  to = win32.resolve(to);\n\n  // windows is not case sensitive\n  var lowerFrom = from.toLowerCase();\n  var lowerTo = to.toLowerCase();\n\n  function trim(arr) {\n    var start = 0;\n    for (; start < arr.length; start++) {\n      if (arr[start] !== '') break;\n    }\n\n    var end = arr.length - 1;\n    for (; end >= 0; end--) {\n      if (arr[end] !== '') break;\n    }\n\n    if (start > end) return [];\n    return arr.slice(start, end + 1);\n  }\n\n  var toParts = trim(to.split('\\\\'));\n\n  var lowerFromParts = trim(lowerFrom.split('\\\\'));\n  var lowerToParts = trim(lowerTo.split('\\\\'));\n\n  var length = Math.min(lowerFromParts.length, lowerToParts.length);\n  var samePartsLength = length;\n  for (var i = 0; i < length; i++) {\n    if (lowerFromParts[i] !== lowerToParts[i]) {\n      samePartsLength = i;\n      break;\n    }\n  }\n\n  if (samePartsLength == 0) {\n    return to;\n  }\n\n  var outputParts = [];\n  for (var i = samePartsLength; i < lowerFromParts.length; i++) {\n    outputParts.push('..');\n  }\n\n  outputParts = outputParts.concat(toParts.slice(samePartsLength));\n\n  return outputParts.join('\\\\');\n};\n\n\nwin32._makeLong = function(path) {\n  // Note: this will *probably* throw somewhere.\n  if (!util.isString(path))\n    return path;\n\n  if (!path) {\n    return '';\n  }\n\n  var resolvedPath = win32.resolve(path);\n\n  if (/^[a-zA-Z]\\:\\\\/.test(resolvedPath)) {\n    // path is local filesystem path, which needs to be converted\n    // to long UNC path.\n    return '\\\\\\\\?\\\\' + resolvedPath;\n  } else if (/^\\\\\\\\[^?.]/.test(resolvedPath)) {\n    // path is network UNC path, which needs to be converted\n    // to long UNC path.\n    return '\\\\\\\\?\\\\UNC\\\\' + resolvedPath.substring(2);\n  }\n\n  return path;\n};\n\n\nwin32.dirname = function(path) {\n  var result = win32SplitPath(path),\n      root = result[0],\n      dir = result[1];\n\n  if (!root && !dir) {\n    // No dirname whatsoever\n    return '.';\n  }\n\n  if (dir) {\n    // It has a dirname, strip trailing slash\n    dir = dir.substr(0, dir.length - 1);\n  }\n\n  return root + dir;\n};\n\n\nwin32.basename = function(path, ext) {\n  var f = win32SplitPath(path)[2];\n  // TODO: make this comparison case-insensitive on windows?\n  if (ext && f.substr(-1 * ext.length) === ext) {\n    f = f.substr(0, f.length - ext.length);\n  }\n  return f;\n};\n\n\nwin32.extname = function(path) {\n  return win32SplitPath(path)[3];\n};\n\n\nwin32.format = function(pathObject) {\n  if (!util.isObject(pathObject)) {\n    throw new TypeError(\n        \"Parameter 'pathObject' must be an object, not \" + typeof pathObject\n    );\n  }\n\n  var root = pathObject.root || '';\n\n  if (!util.isString(root)) {\n    throw new TypeError(\n        \"'pathObject.root' must be a string or undefined, not \" +\n        typeof pathObject.root\n    );\n  }\n\n  var dir = pathObject.dir;\n  var base = pathObject.base || '';\n  if (dir.slice(dir.length - 1, dir.length) === win32.sep) {\n    return dir + base;\n  }\n\n  if (dir) {\n    return dir + win32.sep + base;\n  }\n\n  return base;\n};\n\n\nwin32.parse = function(pathString) {\n  if (!util.isString(pathString)) {\n    throw new TypeError(\n        \"Parameter 'pathString' must be a string, not \" + typeof pathString\n    );\n  }\n  var allParts = win32SplitPath(pathString);\n  if (!allParts || allParts.length !== 4) {\n    throw new TypeError(\"Invalid path '\" + pathString + \"'\");\n  }\n  return {\n    root: allParts[0],\n    dir: allParts[0] + allParts[1].slice(0, allParts[1].length - 1),\n    base: allParts[2],\n    ext: allParts[3],\n    name: allParts[2].slice(0, allParts[2].length - allParts[3].length)\n  };\n};\n\n\nwin32.sep = '\\\\';\nwin32.delimiter = ';';\n\n\n// Split a filename into [root, dir, basename, ext], unix version\n// 'root' is just a slash, or nothing.\nvar splitPathRe =\n    /^(\\/?|)([\\s\\S]*?)((?:\\.{1,2}|[^\\/]+?|)(\\.[^.\\/]*|))(?:[\\/]*)$/;\nvar posix = {};\n\n\nfunction posixSplitPath(filename) {\n  return splitPathRe.exec(filename).slice(1);\n}\n\n\n// path.resolve([from ...], to)\n// posix version\nposix.resolve = function() {\n  var resolvedPath = '',\n      resolvedAbsolute = false;\n\n  for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {\n    var path = (i >= 0) ? arguments[i] : process.cwd();\n\n    // Skip empty and invalid entries\n    if (!util.isString(path)) {\n      throw new TypeError('Arguments to path.resolve must be strings');\n    } else if (!path) {\n      continue;\n    }\n\n    resolvedPath = path + '/' + resolvedPath;\n    resolvedAbsolute = path.charAt(0) === '/';\n  }\n\n  // At this point the path should be resolved to a full absolute path, but\n  // handle relative paths to be safe (might happen when process.cwd() fails)\n\n  // Normalize the path\n  resolvedPath = normalizeArray(resolvedPath.split('/'),\n                                !resolvedAbsolute).join('/');\n\n  return ((resolvedAbsolute ? '/' : '') + resolvedPath) || '.';\n};\n\n// path.normalize(path)\n// posix version\nposix.normalize = function(path) {\n  var isAbsolute = posix.isAbsolute(path),\n      trailingSlash = path.substr(-1) === '/';\n\n  // Normalize the path\n  path = normalizeArray(path.split('/'), !isAbsolute).join('/');\n\n  if (!path && !isAbsolute) {\n    path = '.';\n  }\n  if (path && trailingSlash) {\n    path += '/';\n  }\n\n  return (isAbsolute ? '/' : '') + path;\n};\n\n// posix version\nposix.isAbsolute = function(path) {\n  return path.charAt(0) === '/';\n};\n\n// posix version\nposix.join = function() {\n  var path = '';\n  for (var i = 0; i < arguments.length; i++) {\n    var segment = arguments[i];\n    if (!util.isString(segment)) {\n      throw new TypeError('Arguments to path.join must be strings');\n    }\n    if (segment) {\n      if (!path) {\n        path += segment;\n      } else {\n        path += '/' + segment;\n      }\n    }\n  }\n  return posix.normalize(path);\n};\n\n\n// path.relative(from, to)\n// posix version\nposix.relative = function(from, to) {\n  from = posix.resolve(from).substr(1);\n  to = posix.resolve(to).substr(1);\n\n  function trim(arr) {\n    var start = 0;\n    for (; start < arr.length; start++) {\n      if (arr[start] !== '') break;\n    }\n\n    var end = arr.length - 1;\n    for (; end >= 0; end--) {\n      if (arr[end] !== '') break;\n    }\n\n    if (start > end) return [];\n    return arr.slice(start, end + 1);\n  }\n\n  var fromParts = trim(from.split('/'));\n  var toParts = trim(to.split('/'));\n\n  var length = Math.min(fromParts.length, toParts.length);\n  var samePartsLength = length;\n  for (var i = 0; i < length; i++) {\n    if (fromParts[i] !== toParts[i]) {\n      samePartsLength = i;\n      break;\n    }\n  }\n\n  var outputParts = [];\n  for (var i = samePartsLength; i < fromParts.length; i++) {\n    outputParts.push('..');\n  }\n\n  outputParts = outputParts.concat(toParts.slice(samePartsLength));\n\n  return outputParts.join('/');\n};\n\n\nposix._makeLong = function(path) {\n  return path;\n};\n\n\nposix.dirname = function(path) {\n  var result = posixSplitPath(path),\n      root = result[0],\n      dir = result[1];\n\n  if (!root && !dir) {\n    // No dirname whatsoever\n    return '.';\n  }\n\n  if (dir) {\n    // It has a dirname, strip trailing slash\n    dir = dir.substr(0, dir.length - 1);\n  }\n\n  return root + dir;\n};\n\n\nposix.basename = function(path, ext) {\n  var f = posixSplitPath(path)[2];\n  // TODO: make this comparison case-insensitive on windows?\n  if (ext && f.substr(-1 * ext.length) === ext) {\n    f = f.substr(0, f.length - ext.length);\n  }\n  return f;\n};\n\n\nposix.extname = function(path) {\n  return posixSplitPath(path)[3];\n};\n\n\nposix.format = function(pathObject) {\n  if (!util.isObject(pathObject)) {\n    throw new TypeError(\n        \"Parameter 'pathObject' must be an object, not \" + typeof pathObject\n    );\n  }\n\n  var root = pathObject.root || '';\n\n  if (!util.isString(root)) {\n    throw new TypeError(\n        \"'pathObject.root' must be a string or undefined, not \" +\n        typeof pathObject.root\n    );\n  }\n\n  var dir = pathObject.dir ? pathObject.dir + posix.sep : '';\n  var base = pathObject.base || '';\n  return dir + base;\n};\n\n\nposix.parse = function(pathString) {\n  if (!util.isString(pathString)) {\n    throw new TypeError(\n        \"Parameter 'pathString' must be a string, not \" + typeof pathString\n    );\n  }\n  var allParts = posixSplitPath(pathString);\n  if (!allParts || allParts.length !== 4) {\n    throw new TypeError(\"Invalid path '\" + pathString + \"'\");\n  }\n  allParts[1] = allParts[1] || '';\n  allParts[2] = allParts[2] || '';\n  allParts[3] = allParts[3] || '';\n\n  return {\n    root: allParts[0],\n    dir: allParts[0] + allParts[1].slice(0, allParts[1].length - 1),\n    base: allParts[2],\n    ext: allParts[3],\n    name: allParts[2].slice(0, allParts[2].length - allParts[3].length)\n  };\n};\n\n\nposix.sep = '/';\nposix.delimiter = ':';\n\n\nif (isWindows)\n  module.exports = win32;\nelse /* posix */\n  module.exports = posix;\n\nmodule.exports.posix = posix;\nmodule.exports.win32 = win32;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/path-platform/path.js',
          'importMap': {
            'path': 'path',
            'util': 'util',
          },
          'packageName': 'path-platform',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/path-platform/path.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js': {
        'globals': {
          'process': 'read',
        },
        'moduleRecord': {
          'content': "'use strict';\n\nif (typeof process === 'undefined' ||\n    !process.version ||\n    process.version.indexOf('v0.') === 0 ||\n    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {\n  module.exports = { nextTick: nextTick };\n} else {\n  module.exports = process\n}\n\nfunction nextTick(fn, arg1, arg2, arg3) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('\"callback\" argument must be a function');\n  }\n  var len = arguments.length;\n  var args, i;\n  switch (len) {\n  case 0:\n  case 1:\n    return process.nextTick(fn);\n  case 2:\n    return process.nextTick(function afterTickOne() {\n      fn.call(null, arg1);\n    });\n  case 3:\n    return process.nextTick(function afterTickTwo() {\n      fn.call(null, arg1, arg2);\n    });\n  case 4:\n    return process.nextTick(function afterTickThree() {\n      fn.call(null, arg1, arg2, arg3);\n    });\n  default:\n    args = new Array(len - 1);\n    i = 0;\n    while (i < args.length) {\n      args[i++] = arguments[i];\n    }\n    return process.nextTick(function afterTick() {\n      fn.apply(null, args);\n    });\n  }\n}\n\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          'importMap': {},
          'packageName': 'process-nextick-args',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/index.js': {
        'moduleRecord': {
          'content': "var Readable = require('readable-stream').Readable;\n\nmodule.exports = function (stream) {\n    var opts = stream._readableState;\n    if (typeof stream.read !== 'function') {\n        stream = new Readable(opts).wrap(stream);\n    }\n    \n    var ro = new Readable({ objectMode: opts && opts.objectMode });\n    var waiting = false;\n    \n    stream.on('readable', function () {\n        if (waiting) {\n            waiting = false;\n            ro._read();\n        }\n    });\n    \n    ro._read = function () {\n        var buf, reads = 0;\n        while ((buf = stream.read()) !== null) {\n            ro.push(buf);\n            reads ++;\n        }\n        if (reads === 0) waiting = true;\n    };\n    stream.once('end', function () { ro.push(null) });\n    stream.on('error', function (err) { ro.emit('error', err) });\n    return ro;\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/index.js',
          'importMap': {
            'readable-stream': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/readable.js',
          },
          'packageName': 'read-only-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_duplex.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_duplex.js',
          'importMap': {
            './_stream_readable': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_readable.js',
            './_stream_writable': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_writable.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_duplex.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_passthrough.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_passthrough.js',
          'importMap': {
            './_stream_transform': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_transform.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_passthrough.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_readable.js': {
        'builtin': [
          'events.EventEmitter',
          'util',
          'util.debuglog',
        ],
        'globals': {
          'process.stderr': 'read',
          'process.stdout': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar destroyImpl = require('./internal/streams/destroy');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_readable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/BufferList': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/BufferList.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'events': 'events',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'isarray': '/home/xyz/Development/webtorrent/node_modules/isarray/index.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/safe-buffer/index.js',
            'string_decoder/': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/string_decoder/lib/string_decoder.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_transform.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_transform.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_duplex.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_transform.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_writable.js': {
        'globals': {
          'process.browser': 'read',
          'process.version.slice': 'read',
          'setImmediate': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_writable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/safe-buffer/index.js',
            'util-deprecate': '/home/xyz/Development/webtorrent/node_modules/util-deprecate/node.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_writable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/BufferList.js': {
        'builtin': [
          'util',
          'util.inspect',
          'util.inspect.custom',
        ],
        'moduleRecord': {
          'content': "'use strict';\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = require('safe-buffer').Buffer;\nvar util = require('util');\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/safe-buffer/index.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/destroy.js': {
        'moduleRecord': {
          'content': "'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'importMap': {
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/stream.js': {
        'builtin': [
          'stream',
        ],
        'moduleRecord': {
          'content': "module.exports = require('stream');\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/stream.js',
          'importMap': {
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/internal/streams/stream.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/readable.js': {
        'builtin': [
          'stream',
          'stream.Readable',
          'stream.Writable',
          'stream.Duplex',
          'stream.Transform',
          'stream.PassThrough',
        ],
        'globals': {
          'process.env.READABLE_STREAM': 'read',
        },
        'moduleRecord': {
          'content': "var Stream = require('stream');\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n  exports = module.exports = Stream.Readable;\n  exports.Readable = Stream.Readable;\n  exports.Writable = Stream.Writable;\n  exports.Duplex = Stream.Duplex;\n  exports.Transform = Stream.Transform;\n  exports.PassThrough = Stream.PassThrough;\n  exports.Stream = Stream;\n} else {\n  exports = module.exports = require('./lib/_stream_readable.js');\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = require('./lib/_stream_writable.js');\n  exports.Duplex = require('./lib/_stream_duplex.js');\n  exports.Transform = require('./lib/_stream_transform.js');\n  exports.PassThrough = require('./lib/_stream_passthrough.js');\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/readable.js',
          'importMap': {
            './lib/_stream_duplex.js': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_duplex.js',
            './lib/_stream_passthrough.js': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_passthrough.js',
            './lib/_stream_readable.js': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_readable.js',
            './lib/_stream_transform.js': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_transform.js',
            './lib/_stream_writable.js': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/lib/_stream_writable.js',
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/readable-stream/readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/safe-buffer/index.js': {
        'builtin': [
          'buffer.Buffer',
          'buffer',
          'buffer.SlowBuffer',
        ],
        'moduleRecord': {
          'content': "/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/safe-buffer/index.js',
          'importMap': {
            'buffer': 'buffer',
          },
          'packageName': 'safe-buffer',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/safe-buffer/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/string_decoder/lib/string_decoder.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/string_decoder/lib/string_decoder.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/safe-buffer/index.js',
          },
          'packageName': 'string_decoder',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/read-only-stream/node_modules/string_decoder/lib/string_decoder.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/resolve/index.js': {
        'moduleRecord': {
          'content': "var async = require('./lib/async');\nasync.core = require('./lib/core');\nasync.isCore = require('./lib/is-core');\nasync.sync = require('./lib/sync');\n\nmodule.exports = async;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/resolve/index.js',
          'importMap': {
            './lib/async': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/async.js',
            './lib/core': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/core.js',
            './lib/is-core': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/is-core.js',
            './lib/sync': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/sync.js',
          },
          'packageName': 'resolve',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/resolve/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/resolve/lib/async.js': {
        'builtin': [
          'fs.realpath',
          'fs.realpath.native',
          'fs.stat',
          'fs.readFile',
          'path.join',
          'path.dirname',
          'path.resolve',
          'path.relative',
        ],
        'globals': {
          'process.nextTick': 'read',
          'process.platform': 'read',
        },
        'moduleRecord': {
          'content': "var fs = require('fs');\nvar path = require('path');\nvar caller = require('./caller');\nvar nodeModulesPaths = require('./node-modules-paths');\nvar normalizeOptions = require('./normalize-options');\nvar isCore = require('is-core-module');\n\nvar realpathFS = fs.realpath && typeof fs.realpath.native === 'function' ? fs.realpath.native : fs.realpath;\n\nvar defaultIsFile = function isFile(file, cb) {\n    fs.stat(file, function (err, stat) {\n        if (!err) {\n            return cb(null, stat.isFile() || stat.isFIFO());\n        }\n        if (err.code === 'ENOENT' || err.code === 'ENOTDIR') return cb(null, false);\n        return cb(err);\n    });\n};\n\nvar defaultIsDir = function isDirectory(dir, cb) {\n    fs.stat(dir, function (err, stat) {\n        if (!err) {\n            return cb(null, stat.isDirectory());\n        }\n        if (err.code === 'ENOENT' || err.code === 'ENOTDIR') return cb(null, false);\n        return cb(err);\n    });\n};\n\nvar defaultRealpath = function realpath(x, cb) {\n    realpathFS(x, function (realpathErr, realPath) {\n        if (realpathErr && realpathErr.code !== 'ENOENT') cb(realpathErr);\n        else cb(null, realpathErr ? x : realPath);\n    });\n};\n\nvar maybeRealpath = function maybeRealpath(realpath, x, opts, cb) {\n    if (opts && opts.preserveSymlinks === false) {\n        realpath(x, cb);\n    } else {\n        cb(null, x);\n    }\n};\n\nvar getPackageCandidates = function getPackageCandidates(x, start, opts) {\n    var dirs = nodeModulesPaths(start, opts, x);\n    for (var i = 0; i < dirs.length; i++) {\n        dirs[i] = path.join(dirs[i], x);\n    }\n    return dirs;\n};\n\nmodule.exports = function resolve(x, options, callback) {\n    var cb = callback;\n    var opts = options;\n    if (typeof options === 'function') {\n        cb = opts;\n        opts = {};\n    }\n    if (typeof x !== 'string') {\n        var err = new TypeError('Path must be a string.');\n        return process.nextTick(function () {\n            cb(err);\n        });\n    }\n\n    opts = normalizeOptions(x, opts);\n\n    var isFile = opts.isFile || defaultIsFile;\n    var isDirectory = opts.isDirectory || defaultIsDir;\n    var readFile = opts.readFile || fs.readFile;\n    var realpath = opts.realpath || defaultRealpath;\n    var packageIterator = opts.packageIterator;\n\n    var extensions = opts.extensions || ['.js'];\n    var includeCoreModules = opts.includeCoreModules !== false;\n    var basedir = opts.basedir || path.dirname(caller());\n    var parent = opts.filename || basedir;\n\n    opts.paths = opts.paths || [];\n\n    // ensure that `basedir` is an absolute path at this point, resolving against the process' current working directory\n    var absoluteStart = path.resolve(basedir);\n\n    maybeRealpath(\n        realpath,\n        absoluteStart,\n        opts,\n        function (err, realStart) {\n            if (err) cb(err);\n            else init(realStart);\n        }\n    );\n\n    var res;\n    function init(basedir) {\n        if ((/^(?:\\.\\.?(?:\\/|$)|\\/|([A-Za-z]:)?[/\\\\])/).test(x)) {\n            res = path.resolve(basedir, x);\n            if (x === '.' || x === '..' || x.slice(-1) === '/') res += '/';\n            if ((/\\/$/).test(x) && res === basedir) {\n                loadAsDirectory(res, opts.package, onfile);\n            } else loadAsFile(res, opts.package, onfile);\n        } else if (includeCoreModules && isCore(x)) {\n            return cb(null, x);\n        } else loadNodeModules(x, basedir, function (err, n, pkg) {\n            if (err) cb(err);\n            else if (n) {\n                return maybeRealpath(realpath, n, opts, function (err, realN) {\n                    if (err) {\n                        cb(err);\n                    } else {\n                        cb(null, realN, pkg);\n                    }\n                });\n            } else {\n                var moduleError = new Error(\"Cannot find module '\" + x + \"' from '\" + parent + \"'\");\n                moduleError.code = 'MODULE_NOT_FOUND';\n                cb(moduleError);\n            }\n        });\n    }\n\n    function onfile(err, m, pkg) {\n        if (err) cb(err);\n        else if (m) cb(null, m, pkg);\n        else loadAsDirectory(res, function (err, d, pkg) {\n            if (err) cb(err);\n            else if (d) {\n                maybeRealpath(realpath, d, opts, function (err, realD) {\n                    if (err) {\n                        cb(err);\n                    } else {\n                        cb(null, realD, pkg);\n                    }\n                });\n            } else {\n                var moduleError = new Error(\"Cannot find module '\" + x + \"' from '\" + parent + \"'\");\n                moduleError.code = 'MODULE_NOT_FOUND';\n                cb(moduleError);\n            }\n        });\n    }\n\n    function loadAsFile(x, thePackage, callback) {\n        var loadAsFilePackage = thePackage;\n        var cb = callback;\n        if (typeof loadAsFilePackage === 'function') {\n            cb = loadAsFilePackage;\n            loadAsFilePackage = undefined;\n        }\n\n        var exts = [''].concat(extensions);\n        load(exts, x, loadAsFilePackage);\n\n        function load(exts, x, loadPackage) {\n            if (exts.length === 0) return cb(null, undefined, loadPackage);\n            var file = x + exts[0];\n\n            var pkg = loadPackage;\n            if (pkg) onpkg(null, pkg);\n            else loadpkg(path.dirname(file), onpkg);\n\n            function onpkg(err, pkg_, dir) {\n                pkg = pkg_;\n                if (err) return cb(err);\n                if (dir && pkg && opts.pathFilter) {\n                    var rfile = path.relative(dir, file);\n                    var rel = rfile.slice(0, rfile.length - exts[0].length);\n                    var r = opts.pathFilter(pkg, x, rel);\n                    if (r) return load(\n                        [''].concat(extensions.slice()),\n                        path.resolve(dir, r),\n                        pkg\n                    );\n                }\n                isFile(file, onex);\n            }\n            function onex(err, ex) {\n                if (err) return cb(err);\n                if (ex) return cb(null, file, pkg);\n                load(exts.slice(1), x, pkg);\n            }\n        }\n    }\n\n    function loadpkg(dir, cb) {\n        if (dir === '' || dir === '/') return cb(null);\n        if (process.platform === 'win32' && (/^\\w:[/\\\\]*$/).test(dir)) {\n            return cb(null);\n        }\n        if ((/[/\\\\]node_modules[/\\\\]*$/).test(dir)) return cb(null);\n\n        maybeRealpath(realpath, dir, opts, function (unwrapErr, pkgdir) {\n            if (unwrapErr) return loadpkg(path.dirname(dir), cb);\n            var pkgfile = path.join(pkgdir, 'package.json');\n            isFile(pkgfile, function (err, ex) {\n                // on err, ex is false\n                if (!ex) return loadpkg(path.dirname(dir), cb);\n\n                readFile(pkgfile, function (err, body) {\n                    if (err) cb(err);\n                    try { var pkg = JSON.parse(body); } catch (jsonErr) {}\n\n                    if (pkg && opts.packageFilter) {\n                        pkg = opts.packageFilter(pkg, pkgfile);\n                    }\n                    cb(null, pkg, dir);\n                });\n            });\n        });\n    }\n\n    function loadAsDirectory(x, loadAsDirectoryPackage, callback) {\n        var cb = callback;\n        var fpkg = loadAsDirectoryPackage;\n        if (typeof fpkg === 'function') {\n            cb = fpkg;\n            fpkg = opts.package;\n        }\n\n        maybeRealpath(realpath, x, opts, function (unwrapErr, pkgdir) {\n            if (unwrapErr) return cb(unwrapErr);\n            var pkgfile = path.join(pkgdir, 'package.json');\n            isFile(pkgfile, function (err, ex) {\n                if (err) return cb(err);\n                if (!ex) return loadAsFile(path.join(x, 'index'), fpkg, cb);\n\n                readFile(pkgfile, function (err, body) {\n                    if (err) return cb(err);\n                    try {\n                        var pkg = JSON.parse(body);\n                    } catch (jsonErr) {}\n\n                    if (pkg && opts.packageFilter) {\n                        pkg = opts.packageFilter(pkg, pkgfile);\n                    }\n\n                    if (pkg && pkg.main) {\n                        if (typeof pkg.main !== 'string') {\n                            var mainError = new TypeError('package ' + pkg.name + ' `main` must be a string');\n                            mainError.code = 'INVALID_PACKAGE_MAIN';\n                            return cb(mainError);\n                        }\n                        if (pkg.main === '.' || pkg.main === './') {\n                            pkg.main = 'index';\n                        }\n                        loadAsFile(path.resolve(x, pkg.main), pkg, function (err, m, pkg) {\n                            if (err) return cb(err);\n                            if (m) return cb(null, m, pkg);\n                            if (!pkg) return loadAsFile(path.join(x, 'index'), pkg, cb);\n\n                            var dir = path.resolve(x, pkg.main);\n                            loadAsDirectory(dir, pkg, function (err, n, pkg) {\n                                if (err) return cb(err);\n                                if (n) return cb(null, n, pkg);\n                                loadAsFile(path.join(x, 'index'), pkg, cb);\n                            });\n                        });\n                        return;\n                    }\n\n                    loadAsFile(path.join(x, '/index'), pkg, cb);\n                });\n            });\n        });\n    }\n\n    function processDirs(cb, dirs) {\n        if (dirs.length === 0) return cb(null, undefined);\n        var dir = dirs[0];\n\n        isDirectory(path.dirname(dir), isdir);\n\n        function isdir(err, isdir) {\n            if (err) return cb(err);\n            if (!isdir) return processDirs(cb, dirs.slice(1));\n            loadAsFile(dir, opts.package, onfile);\n        }\n\n        function onfile(err, m, pkg) {\n            if (err) return cb(err);\n            if (m) return cb(null, m, pkg);\n            loadAsDirectory(dir, opts.package, ondir);\n        }\n\n        function ondir(err, n, pkg) {\n            if (err) return cb(err);\n            if (n) return cb(null, n, pkg);\n            processDirs(cb, dirs.slice(1));\n        }\n    }\n    function loadNodeModules(x, start, cb) {\n        var thunk = function () { return getPackageCandidates(x, start, opts); };\n        processDirs(\n            cb,\n            packageIterator ? packageIterator(x, start, thunk, opts) : thunk()\n        );\n    }\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/async.js',
          'importMap': {
            './caller': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/caller.js',
            './node-modules-paths': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/node-modules-paths.js',
            './normalize-options': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/normalize-options.js',
            'fs': 'fs',
            'is-core-module': '/home/xyz/Development/webtorrent/node_modules/is-core-module/index.js',
            'path': 'path',
          },
          'packageName': 'resolve',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/async.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/resolve/lib/caller.js': {
        'moduleRecord': {
          'content': 'module.exports = function () {\n    // see https://code.google.com/p/v8/wiki/JavaScriptStackTraceApi\n    var origPrepareStackTrace = Error.prepareStackTrace;\n    Error.prepareStackTrace = function (_, stack) { return stack; };\n    var stack = (new Error()).stack;\n    Error.prepareStackTrace = origPrepareStackTrace;\n    return stack[2].getFileName();\n};\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/caller.js',
          'importMap': {},
          'packageName': 'resolve',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/caller.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/resolve/lib/core.js': {
        'globals': {
          'process.versions': 'read',
        },
        'moduleRecord': {
          'content': "var current = (process.versions && process.versions.node && process.versions.node.split('.')) || [];\n\nfunction specifierIncluded(specifier) {\n    var parts = specifier.split(' ');\n    var op = parts.length > 1 ? parts[0] : '=';\n    var versionParts = (parts.length > 1 ? parts[1] : parts[0]).split('.');\n\n    for (var i = 0; i < 3; ++i) {\n        var cur = parseInt(current[i] || 0, 10);\n        var ver = parseInt(versionParts[i] || 0, 10);\n        if (cur === ver) {\n            continue; // eslint-disable-line no-restricted-syntax, no-continue\n        }\n        if (op === '<') {\n            return cur < ver;\n        } else if (op === '>=') {\n            return cur >= ver;\n        } else {\n            return false;\n        }\n    }\n    return op === '>=';\n}\n\nfunction matchesRange(range) {\n    var specifiers = range.split(/ ?&& ?/);\n    if (specifiers.length === 0) { return false; }\n    for (var i = 0; i < specifiers.length; ++i) {\n        if (!specifierIncluded(specifiers[i])) { return false; }\n    }\n    return true;\n}\n\nfunction versionIncluded(specifierValue) {\n    if (typeof specifierValue === 'boolean') { return specifierValue; }\n    if (specifierValue && typeof specifierValue === 'object') {\n        for (var i = 0; i < specifierValue.length; ++i) {\n            if (matchesRange(specifierValue[i])) { return true; }\n        }\n        return false;\n    }\n    return matchesRange(specifierValue);\n}\n\nvar data = require('./core.json');\n\nvar core = {};\nfor (var mod in data) { // eslint-disable-line no-restricted-syntax\n    if (Object.prototype.hasOwnProperty.call(data, mod)) {\n        core[mod] = versionIncluded(data[mod]);\n    }\n}\nmodule.exports = core;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/core.js',
          'importMap': {
            './core.json': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/core.json',
          },
          'packageName': 'resolve',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/core.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/resolve/lib/core.json': {
        'moduleRecord': {
          'content': 'module.exports={\n    "assert": true,\n    "assert/strict": ">= 15",\n    "async_hooks": ">= 8",\n    "buffer_ieee754": "< 0.9.7",\n    "buffer": true,\n    "child_process": true,\n    "cluster": true,\n    "console": true,\n    "constants": true,\n    "crypto": true,\n    "_debug_agent": ">= 1 && < 8",\n    "_debugger": "< 8",\n    "dgram": true,\n    "diagnostics_channel": ">= 15.1",\n    "dns": true,\n    "dns/promises": ">= 15",\n    "domain": ">= 0.7.12",\n    "events": true,\n    "freelist": "< 6",\n    "fs": true,\n    "fs/promises": [">= 10 && < 10.1", ">= 14"],\n    "_http_agent": ">= 0.11.1",\n    "_http_client": ">= 0.11.1",\n    "_http_common": ">= 0.11.1",\n    "_http_incoming": ">= 0.11.1",\n    "_http_outgoing": ">= 0.11.1",\n    "_http_server": ">= 0.11.1",\n    "http": true,\n    "http2": ">= 8.8",\n    "https": true,\n    "inspector": ">= 8.0.0",\n    "_linklist": "< 8",\n    "module": true,\n    "net": true,\n    "node-inspect/lib/_inspect": ">= 7.6.0 && < 12",\n    "node-inspect/lib/internal/inspect_client": ">= 7.6.0 && < 12",\n    "node-inspect/lib/internal/inspect_repl": ">= 7.6.0 && < 12",\n    "os": true,\n    "path": true,\n    "perf_hooks": ">= 8.5",\n    "process": ">= 1",\n    "punycode": true,\n    "querystring": true,\n    "readline": true,\n    "repl": true,\n    "smalloc": ">= 0.11.5 && < 3",\n    "_stream_duplex": ">= 0.9.4",\n    "_stream_transform": ">= 0.9.4",\n    "_stream_wrap": ">= 1.4.1",\n    "_stream_passthrough": ">= 0.9.4",\n    "_stream_readable": ">= 0.9.4",\n    "_stream_writable": ">= 0.9.4",\n    "stream": true,\n    "stream/promises": ">= 15",\n    "string_decoder": true,\n    "sys": [">= 0.6 && < 0.7", ">= 0.8"],\n    "timers": true,\n    "timers/promises": ">= 15",\n    "_tls_common": ">= 0.11.13",\n    "_tls_legacy": ">= 0.11.3 && < 10",\n    "_tls_wrap": ">= 0.11.3",\n    "tls": true,\n    "trace_events": ">= 10",\n    "tty": true,\n    "url": true,\n    "util": true,\n    "v8/tools/arguments": ">= 10 && < 12",\n    "v8/tools/codemap": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n    "v8/tools/consarray": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n    "v8/tools/csvparser": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n    "v8/tools/logreader": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n    "v8/tools/profile_view": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n    "v8/tools/splaytree": [">= 4.4.0 && < 5", ">= 5.2.0 && < 12"],\n    "v8": ">= 1",\n    "vm": true,\n    "wasi": ">= 13.4 && < 13.5",\n    "worker_threads": ">= 11.7",\n    "zlib": true\n}\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/core.json',
          'importMap': {},
          'packageName': 'resolve',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/core.json',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/resolve/lib/is-core.js': {
        'moduleRecord': {
          'content': "var isCoreModule = require('is-core-module');\n\nmodule.exports = function isCore(x) {\n    return isCoreModule(x);\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/is-core.js',
          'importMap': {
            'is-core-module': '/home/xyz/Development/webtorrent/node_modules/is-core-module/index.js',
          },
          'packageName': 'resolve',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/is-core.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/resolve/lib/node-modules-paths.js': {
        'builtin': [
          'path.parse',
          'path.resolve',
        ],
        'moduleRecord': {
          'content': "var path = require('path');\nvar parse = path.parse || require('path-parse');\n\nvar getNodeModulesDirs = function getNodeModulesDirs(absoluteStart, modules) {\n    var prefix = '/';\n    if ((/^([A-Za-z]:)/).test(absoluteStart)) {\n        prefix = '';\n    } else if ((/^\\\\\\\\/).test(absoluteStart)) {\n        prefix = '\\\\\\\\';\n    }\n\n    var paths = [absoluteStart];\n    var parsed = parse(absoluteStart);\n    while (parsed.dir !== paths[paths.length - 1]) {\n        paths.push(parsed.dir);\n        parsed = parse(parsed.dir);\n    }\n\n    return paths.reduce(function (dirs, aPath) {\n        return dirs.concat(modules.map(function (moduleDir) {\n            return path.resolve(prefix, aPath, moduleDir);\n        }));\n    }, []);\n};\n\nmodule.exports = function nodeModulesPaths(start, opts, request) {\n    var modules = opts && opts.moduleDirectory\n        ? [].concat(opts.moduleDirectory)\n        : ['node_modules'];\n\n    if (opts && typeof opts.paths === 'function') {\n        return opts.paths(\n            request,\n            start,\n            function () { return getNodeModulesDirs(start, modules); },\n            opts\n        );\n    }\n\n    var dirs = getNodeModulesDirs(start, modules);\n    return opts && opts.paths ? dirs.concat(opts.paths) : dirs;\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/node-modules-paths.js',
          'importMap': {
            'path': 'path',
            'path-parse': '/home/xyz/Development/webtorrent/node_modules/path-parse/index.js',
          },
          'packageName': 'resolve',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/node-modules-paths.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/resolve/lib/normalize-options.js': {
        'moduleRecord': {
          'content': "module.exports = function (x, opts) {\n    /**\n     * This file is purposefully a passthrough. It's expected that third-party\n     * environments will override it at runtime in order to inject special logic\n     * into `resolve` (by manipulating the options). One such example is the PnP\n     * code path in Yarn.\n     */\n\n    return opts || {};\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/normalize-options.js',
          'importMap': {},
          'packageName': 'resolve',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/normalize-options.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/resolve/lib/sync.js': {
        'builtin': [
          'fs.realpathSync',
          'fs.realpathSync.native',
          'fs.statSync',
          'fs.readFileSync',
          'path.join',
          'path.dirname',
          'path.resolve',
          'path.relative',
        ],
        'globals': {
          'process.platform': 'read',
        },
        'moduleRecord': {
          'content': "var isCore = require('is-core-module');\nvar fs = require('fs');\nvar path = require('path');\nvar caller = require('./caller');\nvar nodeModulesPaths = require('./node-modules-paths');\nvar normalizeOptions = require('./normalize-options');\n\nvar realpathFS = fs.realpathSync && typeof fs.realpathSync.native === 'function' ? fs.realpathSync.native : fs.realpathSync;\n\nvar defaultIsFile = function isFile(file) {\n    try {\n        var stat = fs.statSync(file);\n    } catch (e) {\n        if (e && (e.code === 'ENOENT' || e.code === 'ENOTDIR')) return false;\n        throw e;\n    }\n    return stat.isFile() || stat.isFIFO();\n};\n\nvar defaultIsDir = function isDirectory(dir) {\n    try {\n        var stat = fs.statSync(dir);\n    } catch (e) {\n        if (e && (e.code === 'ENOENT' || e.code === 'ENOTDIR')) return false;\n        throw e;\n    }\n    return stat.isDirectory();\n};\n\nvar defaultRealpathSync = function realpathSync(x) {\n    try {\n        return realpathFS(x);\n    } catch (realpathErr) {\n        if (realpathErr.code !== 'ENOENT') {\n            throw realpathErr;\n        }\n    }\n    return x;\n};\n\nvar maybeRealpathSync = function maybeRealpathSync(realpathSync, x, opts) {\n    if (opts && opts.preserveSymlinks === false) {\n        return realpathSync(x);\n    }\n    return x;\n};\n\nvar getPackageCandidates = function getPackageCandidates(x, start, opts) {\n    var dirs = nodeModulesPaths(start, opts, x);\n    for (var i = 0; i < dirs.length; i++) {\n        dirs[i] = path.join(dirs[i], x);\n    }\n    return dirs;\n};\n\nmodule.exports = function resolveSync(x, options) {\n    if (typeof x !== 'string') {\n        throw new TypeError('Path must be a string.');\n    }\n    var opts = normalizeOptions(x, options);\n\n    var isFile = opts.isFile || defaultIsFile;\n    var readFileSync = opts.readFileSync || fs.readFileSync;\n    var isDirectory = opts.isDirectory || defaultIsDir;\n    var realpathSync = opts.realpathSync || defaultRealpathSync;\n    var packageIterator = opts.packageIterator;\n\n    var extensions = opts.extensions || ['.js'];\n    var includeCoreModules = opts.includeCoreModules !== false;\n    var basedir = opts.basedir || path.dirname(caller());\n    var parent = opts.filename || basedir;\n\n    opts.paths = opts.paths || [];\n\n    // ensure that `basedir` is an absolute path at this point, resolving against the process' current working directory\n    var absoluteStart = maybeRealpathSync(realpathSync, path.resolve(basedir), opts);\n\n    if ((/^(?:\\.\\.?(?:\\/|$)|\\/|([A-Za-z]:)?[/\\\\])/).test(x)) {\n        var res = path.resolve(absoluteStart, x);\n        if (x === '.' || x === '..' || x.slice(-1) === '/') res += '/';\n        var m = loadAsFileSync(res) || loadAsDirectorySync(res);\n        if (m) return maybeRealpathSync(realpathSync, m, opts);\n    } else if (includeCoreModules && isCore(x)) {\n        return x;\n    } else {\n        var n = loadNodeModulesSync(x, absoluteStart);\n        if (n) return maybeRealpathSync(realpathSync, n, opts);\n    }\n\n    var err = new Error(\"Cannot find module '\" + x + \"' from '\" + parent + \"'\");\n    err.code = 'MODULE_NOT_FOUND';\n    throw err;\n\n    function loadAsFileSync(x) {\n        var pkg = loadpkg(path.dirname(x));\n\n        if (pkg && pkg.dir && pkg.pkg && opts.pathFilter) {\n            var rfile = path.relative(pkg.dir, x);\n            var r = opts.pathFilter(pkg.pkg, x, rfile);\n            if (r) {\n                x = path.resolve(pkg.dir, r); // eslint-disable-line no-param-reassign\n            }\n        }\n\n        if (isFile(x)) {\n            return x;\n        }\n\n        for (var i = 0; i < extensions.length; i++) {\n            var file = x + extensions[i];\n            if (isFile(file)) {\n                return file;\n            }\n        }\n    }\n\n    function loadpkg(dir) {\n        if (dir === '' || dir === '/') return;\n        if (process.platform === 'win32' && (/^\\w:[/\\\\]*$/).test(dir)) {\n            return;\n        }\n        if ((/[/\\\\]node_modules[/\\\\]*$/).test(dir)) return;\n\n        var pkgfile = path.join(maybeRealpathSync(realpathSync, dir, opts), 'package.json');\n\n        if (!isFile(pkgfile)) {\n            return loadpkg(path.dirname(dir));\n        }\n\n        var body = readFileSync(pkgfile);\n\n        try {\n            var pkg = JSON.parse(body);\n        } catch (jsonErr) {}\n\n        if (pkg && opts.packageFilter) {\n            // v2 will pass pkgfile\n            pkg = opts.packageFilter(pkg, /*pkgfile,*/ dir); // eslint-disable-line spaced-comment\n        }\n\n        return { pkg: pkg, dir: dir };\n    }\n\n    function loadAsDirectorySync(x) {\n        var pkgfile = path.join(maybeRealpathSync(realpathSync, x, opts), '/package.json');\n        if (isFile(pkgfile)) {\n            try {\n                var body = readFileSync(pkgfile, 'UTF8');\n                var pkg = JSON.parse(body);\n            } catch (e) {}\n\n            if (pkg && opts.packageFilter) {\n                // v2 will pass pkgfile\n                pkg = opts.packageFilter(pkg, /*pkgfile,*/ x); // eslint-disable-line spaced-comment\n            }\n\n            if (pkg && pkg.main) {\n                if (typeof pkg.main !== 'string') {\n                    var mainError = new TypeError('package ' + pkg.name + ' `main` must be a string');\n                    mainError.code = 'INVALID_PACKAGE_MAIN';\n                    throw mainError;\n                }\n                if (pkg.main === '.' || pkg.main === './') {\n                    pkg.main = 'index';\n                }\n                try {\n                    var m = loadAsFileSync(path.resolve(x, pkg.main));\n                    if (m) return m;\n                    var n = loadAsDirectorySync(path.resolve(x, pkg.main));\n                    if (n) return n;\n                } catch (e) {}\n            }\n        }\n\n        return loadAsFileSync(path.join(x, '/index'));\n    }\n\n    function loadNodeModulesSync(x, start) {\n        var thunk = function () { return getPackageCandidates(x, start, opts); };\n        var dirs = packageIterator ? packageIterator(x, start, thunk, opts) : thunk();\n\n        for (var i = 0; i < dirs.length; i++) {\n            var dir = dirs[i];\n            if (isDirectory(path.dirname(dir))) {\n                var m = loadAsFileSync(dir);\n                if (m) return m;\n                var n = loadAsDirectorySync(dir);\n                if (n) return n;\n            }\n        }\n    }\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/sync.js',
          'importMap': {
            './caller': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/caller.js',
            './node-modules-paths': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/node-modules-paths.js',
            './normalize-options': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/normalize-options.js',
            'fs': 'fs',
            'is-core-module': '/home/xyz/Development/webtorrent/node_modules/is-core-module/index.js',
            'path': 'path',
          },
          'packageName': 'resolve',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/resolve/lib/sync.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/safe-buffer/index.js': {
        'builtin': [
          'buffer.Buffer',
          'buffer',
          'buffer.SlowBuffer',
        ],
        'moduleRecord': {
          'content': "/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\n/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.prototype = Object.create(Buffer.prototype)\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/safe-buffer/index.js',
          'importMap': {
            'buffer': 'buffer',
          },
          'packageName': 'safe-buffer',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/safe-buffer/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/shasum-object/index.js': {
        'builtin': [
          'crypto.createHash',
        ],
        'globals': {
          'Buffer.isBuffer': 'read',
        },
        'moduleRecord': {
          'content': "var createHash = require('crypto').createHash\nvar stringify = require('fast-safe-stringify')\n\nmodule.exports = function shasum (input, hash, digest) {\n  if (!hash) hash = 'sha1'\n  if (!digest) digest = 'hex'\n  if (typeof input !== 'string' && !Buffer.isBuffer(input)) input = stringify.stable(input)\n\n  return createHash(hash)\n    .update(input, typeof input === 'string' ? 'utf8' : undefined)\n    .digest(digest)\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/shasum-object/index.js',
          'importMap': {
            'crypto': 'crypto',
            'fast-safe-stringify': '/home/xyz/Development/webtorrent/node_modules/fast-safe-stringify/index.js',
          },
          'packageName': 'shasum-object',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/shasum-object/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/source-map/lib/array-set.js': {
        'moduleRecord': {
          'content': "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\nvar has = Object.prototype.hasOwnProperty;\nvar hasNativeMap = typeof Map !== \"undefined\";\n\n/**\n * A data structure which is a combination of an array and a set. Adding a new\n * member is O(1), testing for membership is O(1), and finding the index of an\n * element is O(1). Removing elements from the set is not supported. Only\n * strings are supported for membership.\n */\nfunction ArraySet() {\n  this._array = [];\n  this._set = hasNativeMap ? new Map() : Object.create(null);\n}\n\n/**\n * Static method for creating ArraySet instances from an existing array.\n */\nArraySet.fromArray = function ArraySet_fromArray(aArray, aAllowDuplicates) {\n  var set = new ArraySet();\n  for (var i = 0, len = aArray.length; i < len; i++) {\n    set.add(aArray[i], aAllowDuplicates);\n  }\n  return set;\n};\n\n/**\n * Return how many unique items are in this ArraySet. If duplicates have been\n * added, than those do not count towards the size.\n *\n * @returns Number\n */\nArraySet.prototype.size = function ArraySet_size() {\n  return hasNativeMap ? this._set.size : Object.getOwnPropertyNames(this._set).length;\n};\n\n/**\n * Add the given string to this set.\n *\n * @param String aStr\n */\nArraySet.prototype.add = function ArraySet_add(aStr, aAllowDuplicates) {\n  var sStr = hasNativeMap ? aStr : util.toSetString(aStr);\n  var isDuplicate = hasNativeMap ? this.has(aStr) : has.call(this._set, sStr);\n  var idx = this._array.length;\n  if (!isDuplicate || aAllowDuplicates) {\n    this._array.push(aStr);\n  }\n  if (!isDuplicate) {\n    if (hasNativeMap) {\n      this._set.set(aStr, idx);\n    } else {\n      this._set[sStr] = idx;\n    }\n  }\n};\n\n/**\n * Is the given string a member of this set?\n *\n * @param String aStr\n */\nArraySet.prototype.has = function ArraySet_has(aStr) {\n  if (hasNativeMap) {\n    return this._set.has(aStr);\n  } else {\n    var sStr = util.toSetString(aStr);\n    return has.call(this._set, sStr);\n  }\n};\n\n/**\n * What is the index of the given string in the array?\n *\n * @param String aStr\n */\nArraySet.prototype.indexOf = function ArraySet_indexOf(aStr) {\n  if (hasNativeMap) {\n    var idx = this._set.get(aStr);\n    if (idx >= 0) {\n        return idx;\n    }\n  } else {\n    var sStr = util.toSetString(aStr);\n    if (has.call(this._set, sStr)) {\n      return this._set[sStr];\n    }\n  }\n\n  throw new Error('\"' + aStr + '\" is not in the set.');\n};\n\n/**\n * What is the element at the given index?\n *\n * @param Number aIdx\n */\nArraySet.prototype.at = function ArraySet_at(aIdx) {\n  if (aIdx >= 0 && aIdx < this._array.length) {\n    return this._array[aIdx];\n  }\n  throw new Error('No element indexed by ' + aIdx);\n};\n\n/**\n * Returns the array representation of this set (which has the proper indices\n * indicated by indexOf). Note that this is a copy of the internal array used\n * for storing the members so that no one can mess with internal state.\n */\nArraySet.prototype.toArray = function ArraySet_toArray() {\n  return this._array.slice();\n};\n\nexports.ArraySet = ArraySet;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/array-set.js',
          'importMap': {
            './util': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/util.js',
          },
          'packageName': 'source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/array-set.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/source-map/lib/base64-vlq.js': {
        'moduleRecord': {
          'content': "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n *\n * Based on the Base 64 VLQ implementation in Closure Compiler:\n * https://code.google.com/p/closure-compiler/source/browse/trunk/src/com/google/debugging/sourcemap/Base64VLQ.java\n *\n * Copyright 2011 The Closure Compiler Authors. All rights reserved.\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are\n * met:\n *\n *  * Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above\n *    copyright notice, this list of conditions and the following\n *    disclaimer in the documentation and/or other materials provided\n *    with the distribution.\n *  * Neither the name of Google Inc. nor the names of its\n *    contributors may be used to endorse or promote products derived\n *    from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\nvar base64 = require('./base64');\n\n// A single base 64 digit can contain 6 bits of data. For the base 64 variable\n// length quantities we use in the source map spec, the first bit is the sign,\n// the next four bits are the actual value, and the 6th bit is the\n// continuation bit. The continuation bit tells us whether there are more\n// digits in this value following this digit.\n//\n//   Continuation\n//   |    Sign\n//   |    |\n//   V    V\n//   101011\n\nvar VLQ_BASE_SHIFT = 5;\n\n// binary: 100000\nvar VLQ_BASE = 1 << VLQ_BASE_SHIFT;\n\n// binary: 011111\nvar VLQ_BASE_MASK = VLQ_BASE - 1;\n\n// binary: 100000\nvar VLQ_CONTINUATION_BIT = VLQ_BASE;\n\n/**\n * Converts from a two-complement value to a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   1 becomes 2 (10 binary), -1 becomes 3 (11 binary)\n *   2 becomes 4 (100 binary), -2 becomes 5 (101 binary)\n */\nfunction toVLQSigned(aValue) {\n  return aValue < 0\n    ? ((-aValue) << 1) + 1\n    : (aValue << 1) + 0;\n}\n\n/**\n * Converts to a two-complement value from a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   2 (10 binary) becomes 1, 3 (11 binary) becomes -1\n *   4 (100 binary) becomes 2, 5 (101 binary) becomes -2\n */\nfunction fromVLQSigned(aValue) {\n  var isNegative = (aValue & 1) === 1;\n  var shifted = aValue >> 1;\n  return isNegative\n    ? -shifted\n    : shifted;\n}\n\n/**\n * Returns the base 64 VLQ encoded value.\n */\nexports.encode = function base64VLQ_encode(aValue) {\n  var encoded = \"\";\n  var digit;\n\n  var vlq = toVLQSigned(aValue);\n\n  do {\n    digit = vlq & VLQ_BASE_MASK;\n    vlq >>>= VLQ_BASE_SHIFT;\n    if (vlq > 0) {\n      // There are still more digits in this value, so we must make sure the\n      // continuation bit is marked.\n      digit |= VLQ_CONTINUATION_BIT;\n    }\n    encoded += base64.encode(digit);\n  } while (vlq > 0);\n\n  return encoded;\n};\n\n/**\n * Decodes the next base 64 VLQ value from the given string and returns the\n * value and the rest of the string via the out parameter.\n */\nexports.decode = function base64VLQ_decode(aStr, aIndex, aOutParam) {\n  var strLen = aStr.length;\n  var result = 0;\n  var shift = 0;\n  var continuation, digit;\n\n  do {\n    if (aIndex >= strLen) {\n      throw new Error(\"Expected more digits in base 64 VLQ value.\");\n    }\n\n    digit = base64.decode(aStr.charCodeAt(aIndex++));\n    if (digit === -1) {\n      throw new Error(\"Invalid base64 digit: \" + aStr.charAt(aIndex - 1));\n    }\n\n    continuation = !!(digit & VLQ_CONTINUATION_BIT);\n    digit &= VLQ_BASE_MASK;\n    result = result + (digit << shift);\n    shift += VLQ_BASE_SHIFT;\n  } while (continuation);\n\n  aOutParam.value = fromVLQSigned(result);\n  aOutParam.rest = aIndex;\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/base64-vlq.js',
          'importMap': {
            './base64': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/base64.js',
          },
          'packageName': 'source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/base64-vlq.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/source-map/lib/base64.js': {
        'moduleRecord': {
          'content': "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar intToCharMap = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'.split('');\n\n/**\n * Encode an integer in the range of 0 to 63 to a single base 64 digit.\n */\nexports.encode = function (number) {\n  if (0 <= number && number < intToCharMap.length) {\n    return intToCharMap[number];\n  }\n  throw new TypeError(\"Must be between 0 and 63: \" + number);\n};\n\n/**\n * Decode a single base 64 character code digit to an integer. Returns -1 on\n * failure.\n */\nexports.decode = function (charCode) {\n  var bigA = 65;     // 'A'\n  var bigZ = 90;     // 'Z'\n\n  var littleA = 97;  // 'a'\n  var littleZ = 122; // 'z'\n\n  var zero = 48;     // '0'\n  var nine = 57;     // '9'\n\n  var plus = 43;     // '+'\n  var slash = 47;    // '/'\n\n  var littleOffset = 26;\n  var numberOffset = 52;\n\n  // 0 - 25: ABCDEFGHIJKLMNOPQRSTUVWXYZ\n  if (bigA <= charCode && charCode <= bigZ) {\n    return (charCode - bigA);\n  }\n\n  // 26 - 51: abcdefghijklmnopqrstuvwxyz\n  if (littleA <= charCode && charCode <= littleZ) {\n    return (charCode - littleA + littleOffset);\n  }\n\n  // 52 - 61: 0123456789\n  if (zero <= charCode && charCode <= nine) {\n    return (charCode - zero + numberOffset);\n  }\n\n  // 62: +\n  if (charCode == plus) {\n    return 62;\n  }\n\n  // 63: /\n  if (charCode == slash) {\n    return 63;\n  }\n\n  // Invalid base64 digit.\n  return -1;\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/base64.js',
          'importMap': {},
          'packageName': 'source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/base64.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/source-map/lib/binary-search.js': {
        'moduleRecord': {
          'content': "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nexports.GREATEST_LOWER_BOUND = 1;\nexports.LEAST_UPPER_BOUND = 2;\n\n/**\n * Recursive implementation of binary search.\n *\n * @param aLow Indices here and lower do not contain the needle.\n * @param aHigh Indices here and higher do not contain the needle.\n * @param aNeedle The element being searched for.\n * @param aHaystack The non-empty array being searched.\n * @param aCompare Function which takes two elements and returns -1, 0, or 1.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n */\nfunction recursiveSearch(aLow, aHigh, aNeedle, aHaystack, aCompare, aBias) {\n  // This function terminates when one of the following is true:\n  //\n  //   1. We find the exact element we are looking for.\n  //\n  //   2. We did not find the exact element, but we can return the index of\n  //      the next-closest element.\n  //\n  //   3. We did not find the exact element, and there is no next-closest\n  //      element than the one we are searching for, so we return -1.\n  var mid = Math.floor((aHigh - aLow) / 2) + aLow;\n  var cmp = aCompare(aNeedle, aHaystack[mid], true);\n  if (cmp === 0) {\n    // Found the element we are looking for.\n    return mid;\n  }\n  else if (cmp > 0) {\n    // Our needle is greater than aHaystack[mid].\n    if (aHigh - mid > 1) {\n      // The element is in the upper half.\n      return recursiveSearch(mid, aHigh, aNeedle, aHaystack, aCompare, aBias);\n    }\n\n    // The exact needle element was not found in this haystack. Determine if\n    // we are in termination case (3) or (2) and return the appropriate thing.\n    if (aBias == exports.LEAST_UPPER_BOUND) {\n      return aHigh < aHaystack.length ? aHigh : -1;\n    } else {\n      return mid;\n    }\n  }\n  else {\n    // Our needle is less than aHaystack[mid].\n    if (mid - aLow > 1) {\n      // The element is in the lower half.\n      return recursiveSearch(aLow, mid, aNeedle, aHaystack, aCompare, aBias);\n    }\n\n    // we are in termination case (3) or (2) and return the appropriate thing.\n    if (aBias == exports.LEAST_UPPER_BOUND) {\n      return mid;\n    } else {\n      return aLow < 0 ? -1 : aLow;\n    }\n  }\n}\n\n/**\n * This is an implementation of binary search which will always try and return\n * the index of the closest element if there is no exact hit. This is because\n * mappings between original and generated line/col pairs are single points,\n * and there is an implicit region between each of them, so a miss just means\n * that you aren't on the very start of a region.\n *\n * @param aNeedle The element you are looking for.\n * @param aHaystack The array that is being searched.\n * @param aCompare A function which takes the needle and an element in the\n *     array and returns -1, 0, or 1 depending on whether the needle is less\n *     than, equal to, or greater than the element, respectively.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'binarySearch.GREATEST_LOWER_BOUND'.\n */\nexports.search = function search(aNeedle, aHaystack, aCompare, aBias) {\n  if (aHaystack.length === 0) {\n    return -1;\n  }\n\n  var index = recursiveSearch(-1, aHaystack.length, aNeedle, aHaystack,\n                              aCompare, aBias || exports.GREATEST_LOWER_BOUND);\n  if (index < 0) {\n    return -1;\n  }\n\n  // We have found either the exact element, or the next-closest element than\n  // the one we are searching for. However, there may be more than one such\n  // element. Make sure we always return the smallest of these.\n  while (index - 1 >= 0) {\n    if (aCompare(aHaystack[index], aHaystack[index - 1], true) !== 0) {\n      break;\n    }\n    --index;\n  }\n\n  return index;\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/binary-search.js',
          'importMap': {},
          'packageName': 'source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/binary-search.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/source-map/lib/mapping-list.js': {
        'moduleRecord': {
          'content': "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2014 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\n\n/**\n * Determine whether mappingB is after mappingA with respect to generated\n * position.\n */\nfunction generatedPositionAfter(mappingA, mappingB) {\n  // Optimized for most common case\n  var lineA = mappingA.generatedLine;\n  var lineB = mappingB.generatedLine;\n  var columnA = mappingA.generatedColumn;\n  var columnB = mappingB.generatedColumn;\n  return lineB > lineA || lineB == lineA && columnB >= columnA ||\n         util.compareByGeneratedPositionsInflated(mappingA, mappingB) <= 0;\n}\n\n/**\n * A data structure to provide a sorted view of accumulated mappings in a\n * performance conscious manner. It trades a neglibable overhead in general\n * case for a large speedup in case of mappings being added in order.\n */\nfunction MappingList() {\n  this._array = [];\n  this._sorted = true;\n  // Serves as infimum\n  this._last = {generatedLine: -1, generatedColumn: 0};\n}\n\n/**\n * Iterate through internal items. This method takes the same arguments that\n * `Array.prototype.forEach` takes.\n *\n * NOTE: The order of the mappings is NOT guaranteed.\n */\nMappingList.prototype.unsortedForEach =\n  function MappingList_forEach(aCallback, aThisArg) {\n    this._array.forEach(aCallback, aThisArg);\n  };\n\n/**\n * Add the given source mapping.\n *\n * @param Object aMapping\n */\nMappingList.prototype.add = function MappingList_add(aMapping) {\n  if (generatedPositionAfter(this._last, aMapping)) {\n    this._last = aMapping;\n    this._array.push(aMapping);\n  } else {\n    this._sorted = false;\n    this._array.push(aMapping);\n  }\n};\n\n/**\n * Returns the flat, sorted array of mappings. The mappings are sorted by\n * generated position.\n *\n * WARNING: This method returns internal data without copying, for\n * performance. The return value must NOT be mutated, and should be treated as\n * an immutable borrow. If you want to take ownership, you must make your own\n * copy.\n */\nMappingList.prototype.toArray = function MappingList_toArray() {\n  if (!this._sorted) {\n    this._array.sort(util.compareByGeneratedPositionsInflated);\n    this._sorted = true;\n  }\n  return this._array;\n};\n\nexports.MappingList = MappingList;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/mapping-list.js',
          'importMap': {
            './util': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/util.js',
          },
          'packageName': 'source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/mapping-list.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/source-map/lib/quick-sort.js': {
        'moduleRecord': {
          'content': "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n// It turns out that some (most?) JavaScript engines don't self-host\n// `Array.prototype.sort`. This makes sense because C++ will likely remain\n// faster than JS when doing raw CPU-intensive sorting. However, when using a\n// custom comparator function, calling back and forth between the VM's C++ and\n// JIT'd JS is rather slow *and* loses JIT type information, resulting in\n// worse generated code for the comparator function than would be optimal. In\n// fact, when sorting with a comparator, these costs outweigh the benefits of\n// sorting in C++. By using our own JS-implemented Quick Sort (below), we get\n// a ~3500ms mean speed-up in `bench/bench.html`.\n\n/**\n * Swap the elements indexed by `x` and `y` in the array `ary`.\n *\n * @param {Array} ary\n *        The array.\n * @param {Number} x\n *        The index of the first item.\n * @param {Number} y\n *        The index of the second item.\n */\nfunction swap(ary, x, y) {\n  var temp = ary[x];\n  ary[x] = ary[y];\n  ary[y] = temp;\n}\n\n/**\n * Returns a random integer within the range `low .. high` inclusive.\n *\n * @param {Number} low\n *        The lower bound on the range.\n * @param {Number} high\n *        The upper bound on the range.\n */\nfunction randomIntInRange(low, high) {\n  return Math.round(low + (Math.random() * (high - low)));\n}\n\n/**\n * The Quick Sort algorithm.\n *\n * @param {Array} ary\n *        An array to sort.\n * @param {function} comparator\n *        Function to use to compare two items.\n * @param {Number} p\n *        Start index of the array\n * @param {Number} r\n *        End index of the array\n */\nfunction doQuickSort(ary, comparator, p, r) {\n  // If our lower bound is less than our upper bound, we (1) partition the\n  // array into two pieces and (2) recurse on each half. If it is not, this is\n  // the empty array and our base case.\n\n  if (p < r) {\n    // (1) Partitioning.\n    //\n    // The partitioning chooses a pivot between `p` and `r` and moves all\n    // elements that are less than or equal to the pivot to the before it, and\n    // all the elements that are greater than it after it. The effect is that\n    // once partition is done, the pivot is in the exact place it will be when\n    // the array is put in sorted order, and it will not need to be moved\n    // again. This runs in O(n) time.\n\n    // Always choose a random pivot so that an input array which is reverse\n    // sorted does not cause O(n^2) running time.\n    var pivotIndex = randomIntInRange(p, r);\n    var i = p - 1;\n\n    swap(ary, pivotIndex, r);\n    var pivot = ary[r];\n\n    // Immediately after `j` is incremented in this loop, the following hold\n    // true:\n    //\n    //   * Every element in `ary[p .. i]` is less than or equal to the pivot.\n    //\n    //   * Every element in `ary[i+1 .. j-1]` is greater than the pivot.\n    for (var j = p; j < r; j++) {\n      if (comparator(ary[j], pivot) <= 0) {\n        i += 1;\n        swap(ary, i, j);\n      }\n    }\n\n    swap(ary, i + 1, j);\n    var q = i + 1;\n\n    // (2) Recurse on each half.\n\n    doQuickSort(ary, comparator, p, q - 1);\n    doQuickSort(ary, comparator, q + 1, r);\n  }\n}\n\n/**\n * Sort the given array in-place with the given comparator function.\n *\n * @param {Array} ary\n *        An array to sort.\n * @param {function} comparator\n *        Function to use to compare two items.\n */\nexports.quickSort = function (ary, comparator) {\n  doQuickSort(ary, comparator, 0, ary.length - 1);\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/quick-sort.js',
          'importMap': {},
          'packageName': 'source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/quick-sort.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-map-consumer.js': {
        'moduleRecord': {
          'content': "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar util = require('./util');\nvar binarySearch = require('./binary-search');\nvar ArraySet = require('./array-set').ArraySet;\nvar base64VLQ = require('./base64-vlq');\nvar quickSort = require('./quick-sort').quickSort;\n\nfunction SourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  return sourceMap.sections != null\n    ? new IndexedSourceMapConsumer(sourceMap)\n    : new BasicSourceMapConsumer(sourceMap);\n}\n\nSourceMapConsumer.fromSourceMap = function(aSourceMap) {\n  return BasicSourceMapConsumer.fromSourceMap(aSourceMap);\n}\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nSourceMapConsumer.prototype._version = 3;\n\n// `__generatedMappings` and `__originalMappings` are arrays that hold the\n// parsed mapping coordinates from the source map's \"mappings\" attribute. They\n// are lazily instantiated, accessed via the `_generatedMappings` and\n// `_originalMappings` getters respectively, and we only parse the mappings\n// and create these arrays once queried for a source location. We jump through\n// these hoops because there can be many thousands of mappings, and parsing\n// them is expensive, so we only want to do it if we must.\n//\n// Each object in the arrays is of the form:\n//\n//     {\n//       generatedLine: The line number in the generated code,\n//       generatedColumn: The column number in the generated code,\n//       source: The path to the original source file that generated this\n//               chunk of code,\n//       originalLine: The line number in the original source that\n//                     corresponds to this chunk of generated code,\n//       originalColumn: The column number in the original source that\n//                       corresponds to this chunk of generated code,\n//       name: The name of the original symbol which generated this chunk of\n//             code.\n//     }\n//\n// All properties except for `generatedLine` and `generatedColumn` can be\n// `null`.\n//\n// `_generatedMappings` is ordered by the generated positions.\n//\n// `_originalMappings` is ordered by the original positions.\n\nSourceMapConsumer.prototype.__generatedMappings = null;\nObject.defineProperty(SourceMapConsumer.prototype, '_generatedMappings', {\n  get: function () {\n    if (!this.__generatedMappings) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__generatedMappings;\n  }\n});\n\nSourceMapConsumer.prototype.__originalMappings = null;\nObject.defineProperty(SourceMapConsumer.prototype, '_originalMappings', {\n  get: function () {\n    if (!this.__originalMappings) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__originalMappings;\n  }\n});\n\nSourceMapConsumer.prototype._charIsMappingSeparator =\n  function SourceMapConsumer_charIsMappingSeparator(aStr, index) {\n    var c = aStr.charAt(index);\n    return c === \";\" || c === \",\";\n  };\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nSourceMapConsumer.prototype._parseMappings =\n  function SourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    throw new Error(\"Subclasses must implement _parseMappings\");\n  };\n\nSourceMapConsumer.GENERATED_ORDER = 1;\nSourceMapConsumer.ORIGINAL_ORDER = 2;\n\nSourceMapConsumer.GREATEST_LOWER_BOUND = 1;\nSourceMapConsumer.LEAST_UPPER_BOUND = 2;\n\n/**\n * Iterate over each mapping between an original source/line/column and a\n * generated line/column in this source map.\n *\n * @param Function aCallback\n *        The function that is called with each mapping.\n * @param Object aContext\n *        Optional. If specified, this object will be the value of `this` every\n *        time that `aCallback` is called.\n * @param aOrder\n *        Either `SourceMapConsumer.GENERATED_ORDER` or\n *        `SourceMapConsumer.ORIGINAL_ORDER`. Specifies whether you want to\n *        iterate over the mappings sorted by the generated file's line/column\n *        order or the original's source/line/column order, respectively. Defaults to\n *        `SourceMapConsumer.GENERATED_ORDER`.\n */\nSourceMapConsumer.prototype.eachMapping =\n  function SourceMapConsumer_eachMapping(aCallback, aContext, aOrder) {\n    var context = aContext || null;\n    var order = aOrder || SourceMapConsumer.GENERATED_ORDER;\n\n    var mappings;\n    switch (order) {\n    case SourceMapConsumer.GENERATED_ORDER:\n      mappings = this._generatedMappings;\n      break;\n    case SourceMapConsumer.ORIGINAL_ORDER:\n      mappings = this._originalMappings;\n      break;\n    default:\n      throw new Error(\"Unknown order of iteration.\");\n    }\n\n    var sourceRoot = this.sourceRoot;\n    mappings.map(function (mapping) {\n      var source = mapping.source === null ? null : this._sources.at(mapping.source);\n      if (source != null && sourceRoot != null) {\n        source = util.join(sourceRoot, source);\n      }\n      return {\n        source: source,\n        generatedLine: mapping.generatedLine,\n        generatedColumn: mapping.generatedColumn,\n        originalLine: mapping.originalLine,\n        originalColumn: mapping.originalColumn,\n        name: mapping.name === null ? null : this._names.at(mapping.name)\n      };\n    }, this).forEach(aCallback, context);\n  };\n\n/**\n * Returns all generated line and column information for the original source,\n * line, and column provided. If no column is provided, returns all mappings\n * corresponding to a either the line we are searching for or the next\n * closest line that has any mappings. Otherwise, returns all mappings\n * corresponding to the given line and either the column we are searching for\n * or the next closest column that has any offsets.\n *\n * The only argument is an object with the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: Optional. the column number in the original source.\n *\n * and an array of objects is returned, each with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nSourceMapConsumer.prototype.allGeneratedPositionsFor =\n  function SourceMapConsumer_allGeneratedPositionsFor(aArgs) {\n    var line = util.getArg(aArgs, 'line');\n\n    // When there is no exact match, BasicSourceMapConsumer.prototype._findMapping\n    // returns the index of the closest mapping less than the needle. By\n    // setting needle.originalColumn to 0, we thus find the last mapping for\n    // the given line, provided such a mapping exists.\n    var needle = {\n      source: util.getArg(aArgs, 'source'),\n      originalLine: line,\n      originalColumn: util.getArg(aArgs, 'column', 0)\n    };\n\n    if (this.sourceRoot != null) {\n      needle.source = util.relative(this.sourceRoot, needle.source);\n    }\n    if (!this._sources.has(needle.source)) {\n      return [];\n    }\n    needle.source = this._sources.indexOf(needle.source);\n\n    var mappings = [];\n\n    var index = this._findMapping(needle,\n                                  this._originalMappings,\n                                  \"originalLine\",\n                                  \"originalColumn\",\n                                  util.compareByOriginalPositions,\n                                  binarySearch.LEAST_UPPER_BOUND);\n    if (index >= 0) {\n      var mapping = this._originalMappings[index];\n\n      if (aArgs.column === undefined) {\n        var originalLine = mapping.originalLine;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we found. Since\n        // mappings are sorted, this is guaranteed to find all mappings for\n        // the line we found.\n        while (mapping && mapping.originalLine === originalLine) {\n          mappings.push({\n            line: util.getArg(mapping, 'generatedLine', null),\n            column: util.getArg(mapping, 'generatedColumn', null),\n            lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      } else {\n        var originalColumn = mapping.originalColumn;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we were searching for.\n        // Since mappings are sorted, this is guaranteed to find all mappings for\n        // the line we are searching for.\n        while (mapping &&\n               mapping.originalLine === line &&\n               mapping.originalColumn == originalColumn) {\n          mappings.push({\n            line: util.getArg(mapping, 'generatedLine', null),\n            column: util.getArg(mapping, 'generatedColumn', null),\n            lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      }\n    }\n\n    return mappings;\n  };\n\nexports.SourceMapConsumer = SourceMapConsumer;\n\n/**\n * A BasicSourceMapConsumer instance represents a parsed source map which we can\n * query for information about the original file positions by giving it a file\n * position in the generated source.\n *\n * The only parameter is the raw source map (either as a JSON string, or\n * already parsed to an object). According to the spec, source maps have the\n * following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - sources: An array of URLs to the original source files.\n *   - names: An array of identifiers which can be referrenced by individual mappings.\n *   - sourceRoot: Optional. The URL root from which all sources are relative.\n *   - sourcesContent: Optional. An array of contents of the original source files.\n *   - mappings: A string of base64 VLQs which contain the actual mappings.\n *   - file: Optional. The generated file this source map is associated with.\n *\n * Here is an example source map, taken from the source map spec[0]:\n *\n *     {\n *       version : 3,\n *       file: \"out.js\",\n *       sourceRoot : \"\",\n *       sources: [\"foo.js\", \"bar.js\"],\n *       names: [\"src\", \"maps\", \"are\", \"fun\"],\n *       mappings: \"AA,AB;;ABCDE;\"\n *     }\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit?pli=1#\n */\nfunction BasicSourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  var version = util.getArg(sourceMap, 'version');\n  var sources = util.getArg(sourceMap, 'sources');\n  // Sass 3.3 leaves out the 'names' array, so we deviate from the spec (which\n  // requires the array) to play nice here.\n  var names = util.getArg(sourceMap, 'names', []);\n  var sourceRoot = util.getArg(sourceMap, 'sourceRoot', null);\n  var sourcesContent = util.getArg(sourceMap, 'sourcesContent', null);\n  var mappings = util.getArg(sourceMap, 'mappings');\n  var file = util.getArg(sourceMap, 'file', null);\n\n  // Once again, Sass deviates from the spec and supplies the version as a\n  // string rather than a number, so we use loose equality checking here.\n  if (version != this._version) {\n    throw new Error('Unsupported version: ' + version);\n  }\n\n  sources = sources\n    .map(String)\n    // Some source maps produce relative source paths like \"./foo.js\" instead of\n    // \"foo.js\".  Normalize these first so that future comparisons will succeed.\n    // See bugzil.la/1090768.\n    .map(util.normalize)\n    // Always ensure that absolute sources are internally stored relative to\n    // the source root, if the source root is absolute. Not doing this would\n    // be particularly problematic when the source root is a prefix of the\n    // source (valid, but why??). See github issue #199 and bugzil.la/1188982.\n    .map(function (source) {\n      return sourceRoot && util.isAbsolute(sourceRoot) && util.isAbsolute(source)\n        ? util.relative(sourceRoot, source)\n        : source;\n    });\n\n  // Pass `true` below to allow duplicate names and sources. While source maps\n  // are intended to be compressed and deduplicated, the TypeScript compiler\n  // sometimes generates source maps with duplicates in them. See Github issue\n  // #72 and bugzil.la/889492.\n  this._names = ArraySet.fromArray(names.map(String), true);\n  this._sources = ArraySet.fromArray(sources, true);\n\n  this.sourceRoot = sourceRoot;\n  this.sourcesContent = sourcesContent;\n  this._mappings = mappings;\n  this.file = file;\n}\n\nBasicSourceMapConsumer.prototype = Object.create(SourceMapConsumer.prototype);\nBasicSourceMapConsumer.prototype.consumer = SourceMapConsumer;\n\n/**\n * Create a BasicSourceMapConsumer from a SourceMapGenerator.\n *\n * @param SourceMapGenerator aSourceMap\n *        The source map that will be consumed.\n * @returns BasicSourceMapConsumer\n */\nBasicSourceMapConsumer.fromSourceMap =\n  function SourceMapConsumer_fromSourceMap(aSourceMap) {\n    var smc = Object.create(BasicSourceMapConsumer.prototype);\n\n    var names = smc._names = ArraySet.fromArray(aSourceMap._names.toArray(), true);\n    var sources = smc._sources = ArraySet.fromArray(aSourceMap._sources.toArray(), true);\n    smc.sourceRoot = aSourceMap._sourceRoot;\n    smc.sourcesContent = aSourceMap._generateSourcesContent(smc._sources.toArray(),\n                                                            smc.sourceRoot);\n    smc.file = aSourceMap._file;\n\n    // Because we are modifying the entries (by converting string sources and\n    // names to indices into the sources and names ArraySets), we have to make\n    // a copy of the entry or else bad things happen. Shared mutable state\n    // strikes again! See github issue #191.\n\n    var generatedMappings = aSourceMap._mappings.toArray().slice();\n    var destGeneratedMappings = smc.__generatedMappings = [];\n    var destOriginalMappings = smc.__originalMappings = [];\n\n    for (var i = 0, length = generatedMappings.length; i < length; i++) {\n      var srcMapping = generatedMappings[i];\n      var destMapping = new Mapping;\n      destMapping.generatedLine = srcMapping.generatedLine;\n      destMapping.generatedColumn = srcMapping.generatedColumn;\n\n      if (srcMapping.source) {\n        destMapping.source = sources.indexOf(srcMapping.source);\n        destMapping.originalLine = srcMapping.originalLine;\n        destMapping.originalColumn = srcMapping.originalColumn;\n\n        if (srcMapping.name) {\n          destMapping.name = names.indexOf(srcMapping.name);\n        }\n\n        destOriginalMappings.push(destMapping);\n      }\n\n      destGeneratedMappings.push(destMapping);\n    }\n\n    quickSort(smc.__originalMappings, util.compareByOriginalPositions);\n\n    return smc;\n  };\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nBasicSourceMapConsumer.prototype._version = 3;\n\n/**\n * The list of original sources.\n */\nObject.defineProperty(BasicSourceMapConsumer.prototype, 'sources', {\n  get: function () {\n    return this._sources.toArray().map(function (s) {\n      return this.sourceRoot != null ? util.join(this.sourceRoot, s) : s;\n    }, this);\n  }\n});\n\n/**\n * Provide the JIT with a nice shape / hidden class.\n */\nfunction Mapping() {\n  this.generatedLine = 0;\n  this.generatedColumn = 0;\n  this.source = null;\n  this.originalLine = null;\n  this.originalColumn = null;\n  this.name = null;\n}\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nBasicSourceMapConsumer.prototype._parseMappings =\n  function SourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    var generatedLine = 1;\n    var previousGeneratedColumn = 0;\n    var previousOriginalLine = 0;\n    var previousOriginalColumn = 0;\n    var previousSource = 0;\n    var previousName = 0;\n    var length = aStr.length;\n    var index = 0;\n    var cachedSegments = {};\n    var temp = {};\n    var originalMappings = [];\n    var generatedMappings = [];\n    var mapping, str, segment, end, value;\n\n    while (index < length) {\n      if (aStr.charAt(index) === ';') {\n        generatedLine++;\n        index++;\n        previousGeneratedColumn = 0;\n      }\n      else if (aStr.charAt(index) === ',') {\n        index++;\n      }\n      else {\n        mapping = new Mapping();\n        mapping.generatedLine = generatedLine;\n\n        // Because each offset is encoded relative to the previous one,\n        // many segments often have the same encoding. We can exploit this\n        // fact by caching the parsed variable length fields of each segment,\n        // allowing us to avoid a second parse if we encounter the same\n        // segment again.\n        for (end = index; end < length; end++) {\n          if (this._charIsMappingSeparator(aStr, end)) {\n            break;\n          }\n        }\n        str = aStr.slice(index, end);\n\n        segment = cachedSegments[str];\n        if (segment) {\n          index += str.length;\n        } else {\n          segment = [];\n          while (index < end) {\n            base64VLQ.decode(aStr, index, temp);\n            value = temp.value;\n            index = temp.rest;\n            segment.push(value);\n          }\n\n          if (segment.length === 2) {\n            throw new Error('Found a source, but no line and column');\n          }\n\n          if (segment.length === 3) {\n            throw new Error('Found a source and line, but no column');\n          }\n\n          cachedSegments[str] = segment;\n        }\n\n        // Generated column.\n        mapping.generatedColumn = previousGeneratedColumn + segment[0];\n        previousGeneratedColumn = mapping.generatedColumn;\n\n        if (segment.length > 1) {\n          // Original source.\n          mapping.source = previousSource + segment[1];\n          previousSource += segment[1];\n\n          // Original line.\n          mapping.originalLine = previousOriginalLine + segment[2];\n          previousOriginalLine = mapping.originalLine;\n          // Lines are stored 0-based\n          mapping.originalLine += 1;\n\n          // Original column.\n          mapping.originalColumn = previousOriginalColumn + segment[3];\n          previousOriginalColumn = mapping.originalColumn;\n\n          if (segment.length > 4) {\n            // Original name.\n            mapping.name = previousName + segment[4];\n            previousName += segment[4];\n          }\n        }\n\n        generatedMappings.push(mapping);\n        if (typeof mapping.originalLine === 'number') {\n          originalMappings.push(mapping);\n        }\n      }\n    }\n\n    quickSort(generatedMappings, util.compareByGeneratedPositionsDeflated);\n    this.__generatedMappings = generatedMappings;\n\n    quickSort(originalMappings, util.compareByOriginalPositions);\n    this.__originalMappings = originalMappings;\n  };\n\n/**\n * Find the mapping that best matches the hypothetical \"needle\" mapping that\n * we are searching for in the given \"haystack\" of mappings.\n */\nBasicSourceMapConsumer.prototype._findMapping =\n  function SourceMapConsumer_findMapping(aNeedle, aMappings, aLineName,\n                                         aColumnName, aComparator, aBias) {\n    // To return the position we are searching for, we must first find the\n    // mapping for the given position and then return the opposite position it\n    // points to. Because the mappings are sorted, we can use binary search to\n    // find the best mapping.\n\n    if (aNeedle[aLineName] <= 0) {\n      throw new TypeError('Line must be greater than or equal to 1, got '\n                          + aNeedle[aLineName]);\n    }\n    if (aNeedle[aColumnName] < 0) {\n      throw new TypeError('Column must be greater than or equal to 0, got '\n                          + aNeedle[aColumnName]);\n    }\n\n    return binarySearch.search(aNeedle, aMappings, aComparator, aBias);\n  };\n\n/**\n * Compute the last column for each generated mapping. The last column is\n * inclusive.\n */\nBasicSourceMapConsumer.prototype.computeColumnSpans =\n  function SourceMapConsumer_computeColumnSpans() {\n    for (var index = 0; index < this._generatedMappings.length; ++index) {\n      var mapping = this._generatedMappings[index];\n\n      // Mappings do not contain a field for the last generated columnt. We\n      // can come up with an optimistic estimate, however, by assuming that\n      // mappings are contiguous (i.e. given two consecutive mappings, the\n      // first mapping ends where the second one starts).\n      if (index + 1 < this._generatedMappings.length) {\n        var nextMapping = this._generatedMappings[index + 1];\n\n        if (mapping.generatedLine === nextMapping.generatedLine) {\n          mapping.lastGeneratedColumn = nextMapping.generatedColumn - 1;\n          continue;\n        }\n      }\n\n      // The last mapping for each line spans the entire line.\n      mapping.lastGeneratedColumn = Infinity;\n    }\n  };\n\n/**\n * Returns the original source, line, and column information for the generated\n * source's line and column positions provided. The only argument is an object\n * with the following properties:\n *\n *   - line: The line number in the generated source.\n *   - column: The column number in the generated source.\n *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n *\n * and an object is returned with the following properties:\n *\n *   - source: The original source file, or null.\n *   - line: The line number in the original source, or null.\n *   - column: The column number in the original source, or null.\n *   - name: The original identifier, or null.\n */\nBasicSourceMapConsumer.prototype.originalPositionFor =\n  function SourceMapConsumer_originalPositionFor(aArgs) {\n    var needle = {\n      generatedLine: util.getArg(aArgs, 'line'),\n      generatedColumn: util.getArg(aArgs, 'column')\n    };\n\n    var index = this._findMapping(\n      needle,\n      this._generatedMappings,\n      \"generatedLine\",\n      \"generatedColumn\",\n      util.compareByGeneratedPositionsDeflated,\n      util.getArg(aArgs, 'bias', SourceMapConsumer.GREATEST_LOWER_BOUND)\n    );\n\n    if (index >= 0) {\n      var mapping = this._generatedMappings[index];\n\n      if (mapping.generatedLine === needle.generatedLine) {\n        var source = util.getArg(mapping, 'source', null);\n        if (source !== null) {\n          source = this._sources.at(source);\n          if (this.sourceRoot != null) {\n            source = util.join(this.sourceRoot, source);\n          }\n        }\n        var name = util.getArg(mapping, 'name', null);\n        if (name !== null) {\n          name = this._names.at(name);\n        }\n        return {\n          source: source,\n          line: util.getArg(mapping, 'originalLine', null),\n          column: util.getArg(mapping, 'originalColumn', null),\n          name: name\n        };\n      }\n    }\n\n    return {\n      source: null,\n      line: null,\n      column: null,\n      name: null\n    };\n  };\n\n/**\n * Return true if we have the source content for every source in the source\n * map, false otherwise.\n */\nBasicSourceMapConsumer.prototype.hasContentsOfAllSources =\n  function BasicSourceMapConsumer_hasContentsOfAllSources() {\n    if (!this.sourcesContent) {\n      return false;\n    }\n    return this.sourcesContent.length >= this._sources.size() &&\n      !this.sourcesContent.some(function (sc) { return sc == null; });\n  };\n\n/**\n * Returns the original source content. The only argument is the url of the\n * original source file. Returns null if no original source content is\n * available.\n */\nBasicSourceMapConsumer.prototype.sourceContentFor =\n  function SourceMapConsumer_sourceContentFor(aSource, nullOnMissing) {\n    if (!this.sourcesContent) {\n      return null;\n    }\n\n    if (this.sourceRoot != null) {\n      aSource = util.relative(this.sourceRoot, aSource);\n    }\n\n    if (this._sources.has(aSource)) {\n      return this.sourcesContent[this._sources.indexOf(aSource)];\n    }\n\n    var url;\n    if (this.sourceRoot != null\n        && (url = util.urlParse(this.sourceRoot))) {\n      // XXX: file:// URIs and absolute paths lead to unexpected behavior for\n      // many users. We can help them out when they expect file:// URIs to\n      // behave like it would if they were running a local HTTP server. See\n      // https://bugzilla.mozilla.org/show_bug.cgi?id=885597.\n      var fileUriAbsPath = aSource.replace(/^file:\\/\\//, \"\");\n      if (url.scheme == \"file\"\n          && this._sources.has(fileUriAbsPath)) {\n        return this.sourcesContent[this._sources.indexOf(fileUriAbsPath)]\n      }\n\n      if ((!url.path || url.path == \"/\")\n          && this._sources.has(\"/\" + aSource)) {\n        return this.sourcesContent[this._sources.indexOf(\"/\" + aSource)];\n      }\n    }\n\n    // This function is used recursively from\n    // IndexedSourceMapConsumer.prototype.sourceContentFor. In that case, we\n    // don't want to throw if we can't find the source - we just want to\n    // return null, so we provide a flag to exit gracefully.\n    if (nullOnMissing) {\n      return null;\n    }\n    else {\n      throw new Error('\"' + aSource + '\" is not in the SourceMap.');\n    }\n  };\n\n/**\n * Returns the generated line and column information for the original source,\n * line, and column positions provided. The only argument is an object with\n * the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: The column number in the original source.\n *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n *\n * and an object is returned with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nBasicSourceMapConsumer.prototype.generatedPositionFor =\n  function SourceMapConsumer_generatedPositionFor(aArgs) {\n    var source = util.getArg(aArgs, 'source');\n    if (this.sourceRoot != null) {\n      source = util.relative(this.sourceRoot, source);\n    }\n    if (!this._sources.has(source)) {\n      return {\n        line: null,\n        column: null,\n        lastColumn: null\n      };\n    }\n    source = this._sources.indexOf(source);\n\n    var needle = {\n      source: source,\n      originalLine: util.getArg(aArgs, 'line'),\n      originalColumn: util.getArg(aArgs, 'column')\n    };\n\n    var index = this._findMapping(\n      needle,\n      this._originalMappings,\n      \"originalLine\",\n      \"originalColumn\",\n      util.compareByOriginalPositions,\n      util.getArg(aArgs, 'bias', SourceMapConsumer.GREATEST_LOWER_BOUND)\n    );\n\n    if (index >= 0) {\n      var mapping = this._originalMappings[index];\n\n      if (mapping.source === needle.source) {\n        return {\n          line: util.getArg(mapping, 'generatedLine', null),\n          column: util.getArg(mapping, 'generatedColumn', null),\n          lastColumn: util.getArg(mapping, 'lastGeneratedColumn', null)\n        };\n      }\n    }\n\n    return {\n      line: null,\n      column: null,\n      lastColumn: null\n    };\n  };\n\nexports.BasicSourceMapConsumer = BasicSourceMapConsumer;\n\n/**\n * An IndexedSourceMapConsumer instance represents a parsed source map which\n * we can query for information. It differs from BasicSourceMapConsumer in\n * that it takes \"indexed\" source maps (i.e. ones with a \"sections\" field) as\n * input.\n *\n * The only parameter is a raw source map (either as a JSON string, or already\n * parsed to an object). According to the spec for indexed source maps, they\n * have the following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - file: Optional. The generated file this source map is associated with.\n *   - sections: A list of section definitions.\n *\n * Each value under the \"sections\" field has two fields:\n *   - offset: The offset into the original specified at which this section\n *       begins to apply, defined as an object with a \"line\" and \"column\"\n *       field.\n *   - map: A source map definition. This source map could also be indexed,\n *       but doesn't have to be.\n *\n * Instead of the \"map\" field, it's also possible to have a \"url\" field\n * specifying a URL to retrieve a source map from, but that's currently\n * unsupported.\n *\n * Here's an example source map, taken from the source map spec[0], but\n * modified to omit a section which uses the \"url\" field.\n *\n *  {\n *    version : 3,\n *    file: \"app.js\",\n *    sections: [{\n *      offset: {line:100, column:10},\n *      map: {\n *        version : 3,\n *        file: \"section.js\",\n *        sources: [\"foo.js\", \"bar.js\"],\n *        names: [\"src\", \"maps\", \"are\", \"fun\"],\n *        mappings: \"AAAA,E;;ABCDE;\"\n *      }\n *    }],\n *  }\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit#heading=h.535es3xeprgt\n */\nfunction IndexedSourceMapConsumer(aSourceMap) {\n  var sourceMap = aSourceMap;\n  if (typeof aSourceMap === 'string') {\n    sourceMap = JSON.parse(aSourceMap.replace(/^\\)\\]\\}'/, ''));\n  }\n\n  var version = util.getArg(sourceMap, 'version');\n  var sections = util.getArg(sourceMap, 'sections');\n\n  if (version != this._version) {\n    throw new Error('Unsupported version: ' + version);\n  }\n\n  this._sources = new ArraySet();\n  this._names = new ArraySet();\n\n  var lastOffset = {\n    line: -1,\n    column: 0\n  };\n  this._sections = sections.map(function (s) {\n    if (s.url) {\n      // The url field will require support for asynchronicity.\n      // See https://github.com/mozilla/source-map/issues/16\n      throw new Error('Support for url field in sections not implemented.');\n    }\n    var offset = util.getArg(s, 'offset');\n    var offsetLine = util.getArg(offset, 'line');\n    var offsetColumn = util.getArg(offset, 'column');\n\n    if (offsetLine < lastOffset.line ||\n        (offsetLine === lastOffset.line && offsetColumn < lastOffset.column)) {\n      throw new Error('Section offsets must be ordered and non-overlapping.');\n    }\n    lastOffset = offset;\n\n    return {\n      generatedOffset: {\n        // The offset fields are 0-based, but we use 1-based indices when\n        // encoding/decoding from VLQ.\n        generatedLine: offsetLine + 1,\n        generatedColumn: offsetColumn + 1\n      },\n      consumer: new SourceMapConsumer(util.getArg(s, 'map'))\n    }\n  });\n}\n\nIndexedSourceMapConsumer.prototype = Object.create(SourceMapConsumer.prototype);\nIndexedSourceMapConsumer.prototype.constructor = SourceMapConsumer;\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nIndexedSourceMapConsumer.prototype._version = 3;\n\n/**\n * The list of original sources.\n */\nObject.defineProperty(IndexedSourceMapConsumer.prototype, 'sources', {\n  get: function () {\n    var sources = [];\n    for (var i = 0; i < this._sections.length; i++) {\n      for (var j = 0; j < this._sections[i].consumer.sources.length; j++) {\n        sources.push(this._sections[i].consumer.sources[j]);\n      }\n    }\n    return sources;\n  }\n});\n\n/**\n * Returns the original source, line, and column information for the generated\n * source's line and column positions provided. The only argument is an object\n * with the following properties:\n *\n *   - line: The line number in the generated source.\n *   - column: The column number in the generated source.\n *\n * and an object is returned with the following properties:\n *\n *   - source: The original source file, or null.\n *   - line: The line number in the original source, or null.\n *   - column: The column number in the original source, or null.\n *   - name: The original identifier, or null.\n */\nIndexedSourceMapConsumer.prototype.originalPositionFor =\n  function IndexedSourceMapConsumer_originalPositionFor(aArgs) {\n    var needle = {\n      generatedLine: util.getArg(aArgs, 'line'),\n      generatedColumn: util.getArg(aArgs, 'column')\n    };\n\n    // Find the section containing the generated position we're trying to map\n    // to an original position.\n    var sectionIndex = binarySearch.search(needle, this._sections,\n      function(needle, section) {\n        var cmp = needle.generatedLine - section.generatedOffset.generatedLine;\n        if (cmp) {\n          return cmp;\n        }\n\n        return (needle.generatedColumn -\n                section.generatedOffset.generatedColumn);\n      });\n    var section = this._sections[sectionIndex];\n\n    if (!section) {\n      return {\n        source: null,\n        line: null,\n        column: null,\n        name: null\n      };\n    }\n\n    return section.consumer.originalPositionFor({\n      line: needle.generatedLine -\n        (section.generatedOffset.generatedLine - 1),\n      column: needle.generatedColumn -\n        (section.generatedOffset.generatedLine === needle.generatedLine\n         ? section.generatedOffset.generatedColumn - 1\n         : 0),\n      bias: aArgs.bias\n    });\n  };\n\n/**\n * Return true if we have the source content for every source in the source\n * map, false otherwise.\n */\nIndexedSourceMapConsumer.prototype.hasContentsOfAllSources =\n  function IndexedSourceMapConsumer_hasContentsOfAllSources() {\n    return this._sections.every(function (s) {\n      return s.consumer.hasContentsOfAllSources();\n    });\n  };\n\n/**\n * Returns the original source content. The only argument is the url of the\n * original source file. Returns null if no original source content is\n * available.\n */\nIndexedSourceMapConsumer.prototype.sourceContentFor =\n  function IndexedSourceMapConsumer_sourceContentFor(aSource, nullOnMissing) {\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n\n      var content = section.consumer.sourceContentFor(aSource, true);\n      if (content) {\n        return content;\n      }\n    }\n    if (nullOnMissing) {\n      return null;\n    }\n    else {\n      throw new Error('\"' + aSource + '\" is not in the SourceMap.');\n    }\n  };\n\n/**\n * Returns the generated line and column information for the original source,\n * line, and column positions provided. The only argument is an object with\n * the following properties:\n *\n *   - source: The filename of the original source.\n *   - line: The line number in the original source.\n *   - column: The column number in the original source.\n *\n * and an object is returned with the following properties:\n *\n *   - line: The line number in the generated source, or null.\n *   - column: The column number in the generated source, or null.\n */\nIndexedSourceMapConsumer.prototype.generatedPositionFor =\n  function IndexedSourceMapConsumer_generatedPositionFor(aArgs) {\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n\n      // Only consider this section if the requested source is in the list of\n      // sources of the consumer.\n      if (section.consumer.sources.indexOf(util.getArg(aArgs, 'source')) === -1) {\n        continue;\n      }\n      var generatedPosition = section.consumer.generatedPositionFor(aArgs);\n      if (generatedPosition) {\n        var ret = {\n          line: generatedPosition.line +\n            (section.generatedOffset.generatedLine - 1),\n          column: generatedPosition.column +\n            (section.generatedOffset.generatedLine === generatedPosition.line\n             ? section.generatedOffset.generatedColumn - 1\n             : 0)\n        };\n        return ret;\n      }\n    }\n\n    return {\n      line: null,\n      column: null\n    };\n  };\n\n/**\n * Parse the mappings in a string in to a data structure which we can easily\n * query (the ordered arrays in the `this.__generatedMappings` and\n * `this.__originalMappings` properties).\n */\nIndexedSourceMapConsumer.prototype._parseMappings =\n  function IndexedSourceMapConsumer_parseMappings(aStr, aSourceRoot) {\n    this.__generatedMappings = [];\n    this.__originalMappings = [];\n    for (var i = 0; i < this._sections.length; i++) {\n      var section = this._sections[i];\n      var sectionMappings = section.consumer._generatedMappings;\n      for (var j = 0; j < sectionMappings.length; j++) {\n        var mapping = sectionMappings[j];\n\n        var source = section.consumer._sources.at(mapping.source);\n        if (section.consumer.sourceRoot !== null) {\n          source = util.join(section.consumer.sourceRoot, source);\n        }\n        this._sources.add(source);\n        source = this._sources.indexOf(source);\n\n        var name = section.consumer._names.at(mapping.name);\n        this._names.add(name);\n        name = this._names.indexOf(name);\n\n        // The mappings coming from the consumer for the section have\n        // generated positions relative to the start of the section, so we\n        // need to offset them to be relative to the start of the concatenated\n        // generated file.\n        var adjustedMapping = {\n          source: source,\n          generatedLine: mapping.generatedLine +\n            (section.generatedOffset.generatedLine - 1),\n          generatedColumn: mapping.generatedColumn +\n            (section.generatedOffset.generatedLine === mapping.generatedLine\n            ? section.generatedOffset.generatedColumn - 1\n            : 0),\n          originalLine: mapping.originalLine,\n          originalColumn: mapping.originalColumn,\n          name: name\n        };\n\n        this.__generatedMappings.push(adjustedMapping);\n        if (typeof adjustedMapping.originalLine === 'number') {\n          this.__originalMappings.push(adjustedMapping);\n        }\n      }\n    }\n\n    quickSort(this.__generatedMappings, util.compareByGeneratedPositionsDeflated);\n    quickSort(this.__originalMappings, util.compareByOriginalPositions);\n  };\n\nexports.IndexedSourceMapConsumer = IndexedSourceMapConsumer;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-map-consumer.js',
          'importMap': {
            './array-set': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/array-set.js',
            './base64-vlq': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/base64-vlq.js',
            './binary-search': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/binary-search.js',
            './quick-sort': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/quick-sort.js',
            './util': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/util.js',
          },
          'packageName': 'source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-map-consumer.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-map-generator.js': {
        'moduleRecord': {
          'content': "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar base64VLQ = require('./base64-vlq');\nvar util = require('./util');\nvar ArraySet = require('./array-set').ArraySet;\nvar MappingList = require('./mapping-list').MappingList;\n\n/**\n * An instance of the SourceMapGenerator represents a source map which is\n * being built incrementally. You may pass an object with the following\n * properties:\n *\n *   - file: The filename of the generated source.\n *   - sourceRoot: A root for all relative URLs in this source map.\n */\nfunction SourceMapGenerator(aArgs) {\n  if (!aArgs) {\n    aArgs = {};\n  }\n  this._file = util.getArg(aArgs, 'file', null);\n  this._sourceRoot = util.getArg(aArgs, 'sourceRoot', null);\n  this._skipValidation = util.getArg(aArgs, 'skipValidation', false);\n  this._sources = new ArraySet();\n  this._names = new ArraySet();\n  this._mappings = new MappingList();\n  this._sourcesContents = null;\n}\n\nSourceMapGenerator.prototype._version = 3;\n\n/**\n * Creates a new SourceMapGenerator based on a SourceMapConsumer\n *\n * @param aSourceMapConsumer The SourceMap.\n */\nSourceMapGenerator.fromSourceMap =\n  function SourceMapGenerator_fromSourceMap(aSourceMapConsumer) {\n    var sourceRoot = aSourceMapConsumer.sourceRoot;\n    var generator = new SourceMapGenerator({\n      file: aSourceMapConsumer.file,\n      sourceRoot: sourceRoot\n    });\n    aSourceMapConsumer.eachMapping(function (mapping) {\n      var newMapping = {\n        generated: {\n          line: mapping.generatedLine,\n          column: mapping.generatedColumn\n        }\n      };\n\n      if (mapping.source != null) {\n        newMapping.source = mapping.source;\n        if (sourceRoot != null) {\n          newMapping.source = util.relative(sourceRoot, newMapping.source);\n        }\n\n        newMapping.original = {\n          line: mapping.originalLine,\n          column: mapping.originalColumn\n        };\n\n        if (mapping.name != null) {\n          newMapping.name = mapping.name;\n        }\n      }\n\n      generator.addMapping(newMapping);\n    });\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        generator.setSourceContent(sourceFile, content);\n      }\n    });\n    return generator;\n  };\n\n/**\n * Add a single mapping from original source line and column to the generated\n * source's line and column for this source map being created. The mapping\n * object should have the following properties:\n *\n *   - generated: An object with the generated line and column positions.\n *   - original: An object with the original line and column positions.\n *   - source: The original source file (relative to the sourceRoot).\n *   - name: An optional original token name for this mapping.\n */\nSourceMapGenerator.prototype.addMapping =\n  function SourceMapGenerator_addMapping(aArgs) {\n    var generated = util.getArg(aArgs, 'generated');\n    var original = util.getArg(aArgs, 'original', null);\n    var source = util.getArg(aArgs, 'source', null);\n    var name = util.getArg(aArgs, 'name', null);\n\n    if (!this._skipValidation) {\n      this._validateMapping(generated, original, source, name);\n    }\n\n    if (source != null) {\n      source = String(source);\n      if (!this._sources.has(source)) {\n        this._sources.add(source);\n      }\n    }\n\n    if (name != null) {\n      name = String(name);\n      if (!this._names.has(name)) {\n        this._names.add(name);\n      }\n    }\n\n    this._mappings.add({\n      generatedLine: generated.line,\n      generatedColumn: generated.column,\n      originalLine: original != null && original.line,\n      originalColumn: original != null && original.column,\n      source: source,\n      name: name\n    });\n  };\n\n/**\n * Set the source content for a source file.\n */\nSourceMapGenerator.prototype.setSourceContent =\n  function SourceMapGenerator_setSourceContent(aSourceFile, aSourceContent) {\n    var source = aSourceFile;\n    if (this._sourceRoot != null) {\n      source = util.relative(this._sourceRoot, source);\n    }\n\n    if (aSourceContent != null) {\n      // Add the source content to the _sourcesContents map.\n      // Create a new _sourcesContents map if the property is null.\n      if (!this._sourcesContents) {\n        this._sourcesContents = Object.create(null);\n      }\n      this._sourcesContents[util.toSetString(source)] = aSourceContent;\n    } else if (this._sourcesContents) {\n      // Remove the source file from the _sourcesContents map.\n      // If the _sourcesContents map is empty, set the property to null.\n      delete this._sourcesContents[util.toSetString(source)];\n      if (Object.keys(this._sourcesContents).length === 0) {\n        this._sourcesContents = null;\n      }\n    }\n  };\n\n/**\n * Applies the mappings of a sub-source-map for a specific source file to the\n * source map being generated. Each mapping to the supplied source file is\n * rewritten using the supplied source map. Note: The resolution for the\n * resulting mappings is the minimium of this map and the supplied map.\n *\n * @param aSourceMapConsumer The source map to be applied.\n * @param aSourceFile Optional. The filename of the source file.\n *        If omitted, SourceMapConsumer's file property will be used.\n * @param aSourceMapPath Optional. The dirname of the path to the source map\n *        to be applied. If relative, it is relative to the SourceMapConsumer.\n *        This parameter is needed when the two source maps aren't in the same\n *        directory, and the source map to be applied contains relative source\n *        paths. If so, those relative source paths need to be rewritten\n *        relative to the SourceMapGenerator.\n */\nSourceMapGenerator.prototype.applySourceMap =\n  function SourceMapGenerator_applySourceMap(aSourceMapConsumer, aSourceFile, aSourceMapPath) {\n    var sourceFile = aSourceFile;\n    // If aSourceFile is omitted, we will use the file property of the SourceMap\n    if (aSourceFile == null) {\n      if (aSourceMapConsumer.file == null) {\n        throw new Error(\n          'SourceMapGenerator.prototype.applySourceMap requires either an explicit source file, ' +\n          'or the source map\\'s \"file\" property. Both were omitted.'\n        );\n      }\n      sourceFile = aSourceMapConsumer.file;\n    }\n    var sourceRoot = this._sourceRoot;\n    // Make \"sourceFile\" relative if an absolute Url is passed.\n    if (sourceRoot != null) {\n      sourceFile = util.relative(sourceRoot, sourceFile);\n    }\n    // Applying the SourceMap can add and remove items from the sources and\n    // the names array.\n    var newSources = new ArraySet();\n    var newNames = new ArraySet();\n\n    // Find mappings for the \"sourceFile\"\n    this._mappings.unsortedForEach(function (mapping) {\n      if (mapping.source === sourceFile && mapping.originalLine != null) {\n        // Check if it can be mapped by the source map, then update the mapping.\n        var original = aSourceMapConsumer.originalPositionFor({\n          line: mapping.originalLine,\n          column: mapping.originalColumn\n        });\n        if (original.source != null) {\n          // Copy mapping\n          mapping.source = original.source;\n          if (aSourceMapPath != null) {\n            mapping.source = util.join(aSourceMapPath, mapping.source)\n          }\n          if (sourceRoot != null) {\n            mapping.source = util.relative(sourceRoot, mapping.source);\n          }\n          mapping.originalLine = original.line;\n          mapping.originalColumn = original.column;\n          if (original.name != null) {\n            mapping.name = original.name;\n          }\n        }\n      }\n\n      var source = mapping.source;\n      if (source != null && !newSources.has(source)) {\n        newSources.add(source);\n      }\n\n      var name = mapping.name;\n      if (name != null && !newNames.has(name)) {\n        newNames.add(name);\n      }\n\n    }, this);\n    this._sources = newSources;\n    this._names = newNames;\n\n    // Copy sourcesContents of applied map.\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        if (aSourceMapPath != null) {\n          sourceFile = util.join(aSourceMapPath, sourceFile);\n        }\n        if (sourceRoot != null) {\n          sourceFile = util.relative(sourceRoot, sourceFile);\n        }\n        this.setSourceContent(sourceFile, content);\n      }\n    }, this);\n  };\n\n/**\n * A mapping can have one of the three levels of data:\n *\n *   1. Just the generated position.\n *   2. The Generated position, original position, and original source.\n *   3. Generated and original position, original source, as well as a name\n *      token.\n *\n * To maintain consistency, we validate that any new mapping being added falls\n * in to one of these categories.\n */\nSourceMapGenerator.prototype._validateMapping =\n  function SourceMapGenerator_validateMapping(aGenerated, aOriginal, aSource,\n                                              aName) {\n    // When aOriginal is truthy but has empty values for .line and .column,\n    // it is most likely a programmer error. In this case we throw a very\n    // specific error message to try to guide them the right way.\n    // For example: https://github.com/Polymer/polymer-bundler/pull/519\n    if (aOriginal && typeof aOriginal.line !== 'number' && typeof aOriginal.column !== 'number') {\n        throw new Error(\n            'original.line and original.column are not numbers -- you probably meant to omit ' +\n            'the original mapping entirely and only map the generated position. If so, pass ' +\n            'null for the original mapping instead of an object with empty or null values.'\n        );\n    }\n\n    if (aGenerated && 'line' in aGenerated && 'column' in aGenerated\n        && aGenerated.line > 0 && aGenerated.column >= 0\n        && !aOriginal && !aSource && !aName) {\n      // Case 1.\n      return;\n    }\n    else if (aGenerated && 'line' in aGenerated && 'column' in aGenerated\n             && aOriginal && 'line' in aOriginal && 'column' in aOriginal\n             && aGenerated.line > 0 && aGenerated.column >= 0\n             && aOriginal.line > 0 && aOriginal.column >= 0\n             && aSource) {\n      // Cases 2 and 3.\n      return;\n    }\n    else {\n      throw new Error('Invalid mapping: ' + JSON.stringify({\n        generated: aGenerated,\n        source: aSource,\n        original: aOriginal,\n        name: aName\n      }));\n    }\n  };\n\n/**\n * Serialize the accumulated mappings in to the stream of base 64 VLQs\n * specified by the source map format.\n */\nSourceMapGenerator.prototype._serializeMappings =\n  function SourceMapGenerator_serializeMappings() {\n    var previousGeneratedColumn = 0;\n    var previousGeneratedLine = 1;\n    var previousOriginalColumn = 0;\n    var previousOriginalLine = 0;\n    var previousName = 0;\n    var previousSource = 0;\n    var result = '';\n    var next;\n    var mapping;\n    var nameIdx;\n    var sourceIdx;\n\n    var mappings = this._mappings.toArray();\n    for (var i = 0, len = mappings.length; i < len; i++) {\n      mapping = mappings[i];\n      next = ''\n\n      if (mapping.generatedLine !== previousGeneratedLine) {\n        previousGeneratedColumn = 0;\n        while (mapping.generatedLine !== previousGeneratedLine) {\n          next += ';';\n          previousGeneratedLine++;\n        }\n      }\n      else {\n        if (i > 0) {\n          if (!util.compareByGeneratedPositionsInflated(mapping, mappings[i - 1])) {\n            continue;\n          }\n          next += ',';\n        }\n      }\n\n      next += base64VLQ.encode(mapping.generatedColumn\n                                 - previousGeneratedColumn);\n      previousGeneratedColumn = mapping.generatedColumn;\n\n      if (mapping.source != null) {\n        sourceIdx = this._sources.indexOf(mapping.source);\n        next += base64VLQ.encode(sourceIdx - previousSource);\n        previousSource = sourceIdx;\n\n        // lines are stored 0-based in SourceMap spec version 3\n        next += base64VLQ.encode(mapping.originalLine - 1\n                                   - previousOriginalLine);\n        previousOriginalLine = mapping.originalLine - 1;\n\n        next += base64VLQ.encode(mapping.originalColumn\n                                   - previousOriginalColumn);\n        previousOriginalColumn = mapping.originalColumn;\n\n        if (mapping.name != null) {\n          nameIdx = this._names.indexOf(mapping.name);\n          next += base64VLQ.encode(nameIdx - previousName);\n          previousName = nameIdx;\n        }\n      }\n\n      result += next;\n    }\n\n    return result;\n  };\n\nSourceMapGenerator.prototype._generateSourcesContent =\n  function SourceMapGenerator_generateSourcesContent(aSources, aSourceRoot) {\n    return aSources.map(function (source) {\n      if (!this._sourcesContents) {\n        return null;\n      }\n      if (aSourceRoot != null) {\n        source = util.relative(aSourceRoot, source);\n      }\n      var key = util.toSetString(source);\n      return Object.prototype.hasOwnProperty.call(this._sourcesContents, key)\n        ? this._sourcesContents[key]\n        : null;\n    }, this);\n  };\n\n/**\n * Externalize the source map.\n */\nSourceMapGenerator.prototype.toJSON =\n  function SourceMapGenerator_toJSON() {\n    var map = {\n      version: this._version,\n      sources: this._sources.toArray(),\n      names: this._names.toArray(),\n      mappings: this._serializeMappings()\n    };\n    if (this._file != null) {\n      map.file = this._file;\n    }\n    if (this._sourceRoot != null) {\n      map.sourceRoot = this._sourceRoot;\n    }\n    if (this._sourcesContents) {\n      map.sourcesContent = this._generateSourcesContent(map.sources, map.sourceRoot);\n    }\n\n    return map;\n  };\n\n/**\n * Render the source map being generated to a string.\n */\nSourceMapGenerator.prototype.toString =\n  function SourceMapGenerator_toString() {\n    return JSON.stringify(this.toJSON());\n  };\n\nexports.SourceMapGenerator = SourceMapGenerator;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-map-generator.js',
          'importMap': {
            './array-set': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/array-set.js',
            './base64-vlq': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/base64-vlq.js',
            './mapping-list': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/mapping-list.js',
            './util': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/util.js',
          },
          'packageName': 'source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-map-generator.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-node.js': {
        'moduleRecord': {
          'content': "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nvar SourceMapGenerator = require('./source-map-generator').SourceMapGenerator;\nvar util = require('./util');\n\n// Matches a Windows-style `\\r\\n` newline or a `\\n` newline used by all other\n// operating systems these days (capturing the result).\nvar REGEX_NEWLINE = /(\\r?\\n)/;\n\n// Newline character code for charCodeAt() comparisons\nvar NEWLINE_CODE = 10;\n\n// Private symbol for identifying `SourceNode`s when multiple versions of\n// the source-map library are loaded. This MUST NOT CHANGE across\n// versions!\nvar isSourceNode = \"$$$isSourceNode$$$\";\n\n/**\n * SourceNodes provide a way to abstract over interpolating/concatenating\n * snippets of generated JavaScript source code while maintaining the line and\n * column information associated with the original source code.\n *\n * @param aLine The original line number.\n * @param aColumn The original column number.\n * @param aSource The original source's filename.\n * @param aChunks Optional. An array of strings which are snippets of\n *        generated JS, or other SourceNodes.\n * @param aName The original identifier.\n */\nfunction SourceNode(aLine, aColumn, aSource, aChunks, aName) {\n  this.children = [];\n  this.sourceContents = {};\n  this.line = aLine == null ? null : aLine;\n  this.column = aColumn == null ? null : aColumn;\n  this.source = aSource == null ? null : aSource;\n  this.name = aName == null ? null : aName;\n  this[isSourceNode] = true;\n  if (aChunks != null) this.add(aChunks);\n}\n\n/**\n * Creates a SourceNode from generated code and a SourceMapConsumer.\n *\n * @param aGeneratedCode The generated code\n * @param aSourceMapConsumer The SourceMap for the generated code\n * @param aRelativePath Optional. The path that relative sources in the\n *        SourceMapConsumer should be relative to.\n */\nSourceNode.fromStringWithSourceMap =\n  function SourceNode_fromStringWithSourceMap(aGeneratedCode, aSourceMapConsumer, aRelativePath) {\n    // The SourceNode we want to fill with the generated code\n    // and the SourceMap\n    var node = new SourceNode();\n\n    // All even indices of this array are one line of the generated code,\n    // while all odd indices are the newlines between two adjacent lines\n    // (since `REGEX_NEWLINE` captures its match).\n    // Processed fragments are accessed by calling `shiftNextLine`.\n    var remainingLines = aGeneratedCode.split(REGEX_NEWLINE);\n    var remainingLinesIndex = 0;\n    var shiftNextLine = function() {\n      var lineContents = getNextLine();\n      // The last line of a file might not have a newline.\n      var newLine = getNextLine() || \"\";\n      return lineContents + newLine;\n\n      function getNextLine() {\n        return remainingLinesIndex < remainingLines.length ?\n            remainingLines[remainingLinesIndex++] : undefined;\n      }\n    };\n\n    // We need to remember the position of \"remainingLines\"\n    var lastGeneratedLine = 1, lastGeneratedColumn = 0;\n\n    // The generate SourceNodes we need a code range.\n    // To extract it current and last mapping is used.\n    // Here we store the last mapping.\n    var lastMapping = null;\n\n    aSourceMapConsumer.eachMapping(function (mapping) {\n      if (lastMapping !== null) {\n        // We add the code from \"lastMapping\" to \"mapping\":\n        // First check if there is a new line in between.\n        if (lastGeneratedLine < mapping.generatedLine) {\n          // Associate first line with \"lastMapping\"\n          addMappingWithCode(lastMapping, shiftNextLine());\n          lastGeneratedLine++;\n          lastGeneratedColumn = 0;\n          // The remaining code is added without mapping\n        } else {\n          // There is no new line in between.\n          // Associate the code between \"lastGeneratedColumn\" and\n          // \"mapping.generatedColumn\" with \"lastMapping\"\n          var nextLine = remainingLines[remainingLinesIndex];\n          var code = nextLine.substr(0, mapping.generatedColumn -\n                                        lastGeneratedColumn);\n          remainingLines[remainingLinesIndex] = nextLine.substr(mapping.generatedColumn -\n                                              lastGeneratedColumn);\n          lastGeneratedColumn = mapping.generatedColumn;\n          addMappingWithCode(lastMapping, code);\n          // No more remaining code, continue\n          lastMapping = mapping;\n          return;\n        }\n      }\n      // We add the generated code until the first mapping\n      // to the SourceNode without any mapping.\n      // Each line is added as separate string.\n      while (lastGeneratedLine < mapping.generatedLine) {\n        node.add(shiftNextLine());\n        lastGeneratedLine++;\n      }\n      if (lastGeneratedColumn < mapping.generatedColumn) {\n        var nextLine = remainingLines[remainingLinesIndex];\n        node.add(nextLine.substr(0, mapping.generatedColumn));\n        remainingLines[remainingLinesIndex] = nextLine.substr(mapping.generatedColumn);\n        lastGeneratedColumn = mapping.generatedColumn;\n      }\n      lastMapping = mapping;\n    }, this);\n    // We have processed all mappings.\n    if (remainingLinesIndex < remainingLines.length) {\n      if (lastMapping) {\n        // Associate the remaining code in the current line with \"lastMapping\"\n        addMappingWithCode(lastMapping, shiftNextLine());\n      }\n      // and add the remaining lines without any mapping\n      node.add(remainingLines.splice(remainingLinesIndex).join(\"\"));\n    }\n\n    // Copy sourcesContent into SourceNode\n    aSourceMapConsumer.sources.forEach(function (sourceFile) {\n      var content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        if (aRelativePath != null) {\n          sourceFile = util.join(aRelativePath, sourceFile);\n        }\n        node.setSourceContent(sourceFile, content);\n      }\n    });\n\n    return node;\n\n    function addMappingWithCode(mapping, code) {\n      if (mapping === null || mapping.source === undefined) {\n        node.add(code);\n      } else {\n        var source = aRelativePath\n          ? util.join(aRelativePath, mapping.source)\n          : mapping.source;\n        node.add(new SourceNode(mapping.originalLine,\n                                mapping.originalColumn,\n                                source,\n                                code,\n                                mapping.name));\n      }\n    }\n  };\n\n/**\n * Add a chunk of generated JS to this source node.\n *\n * @param aChunk A string snippet of generated JS code, another instance of\n *        SourceNode, or an array where each member is one of those things.\n */\nSourceNode.prototype.add = function SourceNode_add(aChunk) {\n  if (Array.isArray(aChunk)) {\n    aChunk.forEach(function (chunk) {\n      this.add(chunk);\n    }, this);\n  }\n  else if (aChunk[isSourceNode] || typeof aChunk === \"string\") {\n    if (aChunk) {\n      this.children.push(aChunk);\n    }\n  }\n  else {\n    throw new TypeError(\n      \"Expected a SourceNode, string, or an array of SourceNodes and strings. Got \" + aChunk\n    );\n  }\n  return this;\n};\n\n/**\n * Add a chunk of generated JS to the beginning of this source node.\n *\n * @param aChunk A string snippet of generated JS code, another instance of\n *        SourceNode, or an array where each member is one of those things.\n */\nSourceNode.prototype.prepend = function SourceNode_prepend(aChunk) {\n  if (Array.isArray(aChunk)) {\n    for (var i = aChunk.length-1; i >= 0; i--) {\n      this.prepend(aChunk[i]);\n    }\n  }\n  else if (aChunk[isSourceNode] || typeof aChunk === \"string\") {\n    this.children.unshift(aChunk);\n  }\n  else {\n    throw new TypeError(\n      \"Expected a SourceNode, string, or an array of SourceNodes and strings. Got \" + aChunk\n    );\n  }\n  return this;\n};\n\n/**\n * Walk over the tree of JS snippets in this node and its children. The\n * walking function is called once for each snippet of JS and is passed that\n * snippet and the its original associated source's line/column location.\n *\n * @param aFn The traversal function.\n */\nSourceNode.prototype.walk = function SourceNode_walk(aFn) {\n  var chunk;\n  for (var i = 0, len = this.children.length; i < len; i++) {\n    chunk = this.children[i];\n    if (chunk[isSourceNode]) {\n      chunk.walk(aFn);\n    }\n    else {\n      if (chunk !== '') {\n        aFn(chunk, { source: this.source,\n                     line: this.line,\n                     column: this.column,\n                     name: this.name });\n      }\n    }\n  }\n};\n\n/**\n * Like `String.prototype.join` except for SourceNodes. Inserts `aStr` between\n * each of `this.children`.\n *\n * @param aSep The separator.\n */\nSourceNode.prototype.join = function SourceNode_join(aSep) {\n  var newChildren;\n  var i;\n  var len = this.children.length;\n  if (len > 0) {\n    newChildren = [];\n    for (i = 0; i < len-1; i++) {\n      newChildren.push(this.children[i]);\n      newChildren.push(aSep);\n    }\n    newChildren.push(this.children[i]);\n    this.children = newChildren;\n  }\n  return this;\n};\n\n/**\n * Call String.prototype.replace on the very right-most source snippet. Useful\n * for trimming whitespace from the end of a source node, etc.\n *\n * @param aPattern The pattern to replace.\n * @param aReplacement The thing to replace the pattern with.\n */\nSourceNode.prototype.replaceRight = function SourceNode_replaceRight(aPattern, aReplacement) {\n  var lastChild = this.children[this.children.length - 1];\n  if (lastChild[isSourceNode]) {\n    lastChild.replaceRight(aPattern, aReplacement);\n  }\n  else if (typeof lastChild === 'string') {\n    this.children[this.children.length - 1] = lastChild.replace(aPattern, aReplacement);\n  }\n  else {\n    this.children.push(''.replace(aPattern, aReplacement));\n  }\n  return this;\n};\n\n/**\n * Set the source content for a source file. This will be added to the SourceMapGenerator\n * in the sourcesContent field.\n *\n * @param aSourceFile The filename of the source file\n * @param aSourceContent The content of the source file\n */\nSourceNode.prototype.setSourceContent =\n  function SourceNode_setSourceContent(aSourceFile, aSourceContent) {\n    this.sourceContents[util.toSetString(aSourceFile)] = aSourceContent;\n  };\n\n/**\n * Walk over the tree of SourceNodes. The walking function is called for each\n * source file content and is passed the filename and source content.\n *\n * @param aFn The traversal function.\n */\nSourceNode.prototype.walkSourceContents =\n  function SourceNode_walkSourceContents(aFn) {\n    for (var i = 0, len = this.children.length; i < len; i++) {\n      if (this.children[i][isSourceNode]) {\n        this.children[i].walkSourceContents(aFn);\n      }\n    }\n\n    var sources = Object.keys(this.sourceContents);\n    for (var i = 0, len = sources.length; i < len; i++) {\n      aFn(util.fromSetString(sources[i]), this.sourceContents[sources[i]]);\n    }\n  };\n\n/**\n * Return the string representation of this source node. Walks over the tree\n * and concatenates all the various snippets together to one string.\n */\nSourceNode.prototype.toString = function SourceNode_toString() {\n  var str = \"\";\n  this.walk(function (chunk) {\n    str += chunk;\n  });\n  return str;\n};\n\n/**\n * Returns the string representation of this source node along with a source\n * map.\n */\nSourceNode.prototype.toStringWithSourceMap = function SourceNode_toStringWithSourceMap(aArgs) {\n  var generated = {\n    code: \"\",\n    line: 1,\n    column: 0\n  };\n  var map = new SourceMapGenerator(aArgs);\n  var sourceMappingActive = false;\n  var lastOriginalSource = null;\n  var lastOriginalLine = null;\n  var lastOriginalColumn = null;\n  var lastOriginalName = null;\n  this.walk(function (chunk, original) {\n    generated.code += chunk;\n    if (original.source !== null\n        && original.line !== null\n        && original.column !== null) {\n      if(lastOriginalSource !== original.source\n         || lastOriginalLine !== original.line\n         || lastOriginalColumn !== original.column\n         || lastOriginalName !== original.name) {\n        map.addMapping({\n          source: original.source,\n          original: {\n            line: original.line,\n            column: original.column\n          },\n          generated: {\n            line: generated.line,\n            column: generated.column\n          },\n          name: original.name\n        });\n      }\n      lastOriginalSource = original.source;\n      lastOriginalLine = original.line;\n      lastOriginalColumn = original.column;\n      lastOriginalName = original.name;\n      sourceMappingActive = true;\n    } else if (sourceMappingActive) {\n      map.addMapping({\n        generated: {\n          line: generated.line,\n          column: generated.column\n        }\n      });\n      lastOriginalSource = null;\n      sourceMappingActive = false;\n    }\n    for (var idx = 0, length = chunk.length; idx < length; idx++) {\n      if (chunk.charCodeAt(idx) === NEWLINE_CODE) {\n        generated.line++;\n        generated.column = 0;\n        // Mappings end at eol\n        if (idx + 1 === length) {\n          lastOriginalSource = null;\n          sourceMappingActive = false;\n        } else if (sourceMappingActive) {\n          map.addMapping({\n            source: original.source,\n            original: {\n              line: original.line,\n              column: original.column\n            },\n            generated: {\n              line: generated.line,\n              column: generated.column\n            },\n            name: original.name\n          });\n        }\n      } else {\n        generated.column++;\n      }\n    }\n  });\n  this.walkSourceContents(function (sourceFile, sourceContent) {\n    map.setSourceContent(sourceFile, sourceContent);\n  });\n\n  return { code: generated.code, map: map };\n};\n\nexports.SourceNode = SourceNode;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-node.js',
          'importMap': {
            './source-map-generator': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-map-generator.js',
            './util': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/util.js',
          },
          'packageName': 'source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-node.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/source-map/lib/util.js': {
        'moduleRecord': {
          'content': "/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n/**\n * This is a helper function for getting values from parameter/options\n * objects.\n *\n * @param args The object we are extracting values from\n * @param name The name of the property we are getting.\n * @param defaultValue An optional value to return if the property is missing\n * from the object. If this is not specified and the property is missing, an\n * error will be thrown.\n */\nfunction getArg(aArgs, aName, aDefaultValue) {\n  if (aName in aArgs) {\n    return aArgs[aName];\n  } else if (arguments.length === 3) {\n    return aDefaultValue;\n  } else {\n    throw new Error('\"' + aName + '\" is a required argument.');\n  }\n}\nexports.getArg = getArg;\n\nvar urlRegexp = /^(?:([\\w+\\-.]+):)?\\/\\/(?:(\\w+:\\w+)@)?([\\w.]*)(?::(\\d+))?(\\S*)$/;\nvar dataUrlRegexp = /^data:.+\\,.+$/;\n\nfunction urlParse(aUrl) {\n  var match = aUrl.match(urlRegexp);\n  if (!match) {\n    return null;\n  }\n  return {\n    scheme: match[1],\n    auth: match[2],\n    host: match[3],\n    port: match[4],\n    path: match[5]\n  };\n}\nexports.urlParse = urlParse;\n\nfunction urlGenerate(aParsedUrl) {\n  var url = '';\n  if (aParsedUrl.scheme) {\n    url += aParsedUrl.scheme + ':';\n  }\n  url += '//';\n  if (aParsedUrl.auth) {\n    url += aParsedUrl.auth + '@';\n  }\n  if (aParsedUrl.host) {\n    url += aParsedUrl.host;\n  }\n  if (aParsedUrl.port) {\n    url += \":\" + aParsedUrl.port\n  }\n  if (aParsedUrl.path) {\n    url += aParsedUrl.path;\n  }\n  return url;\n}\nexports.urlGenerate = urlGenerate;\n\n/**\n * Normalizes a path, or the path portion of a URL:\n *\n * - Replaces consecutive slashes with one slash.\n * - Removes unnecessary '.' parts.\n * - Removes unnecessary '<dir>/..' parts.\n *\n * Based on code in the Node.js 'path' core module.\n *\n * @param aPath The path or url to normalize.\n */\nfunction normalize(aPath) {\n  var path = aPath;\n  var url = urlParse(aPath);\n  if (url) {\n    if (!url.path) {\n      return aPath;\n    }\n    path = url.path;\n  }\n  var isAbsolute = exports.isAbsolute(path);\n\n  var parts = path.split(/\\/+/);\n  for (var part, up = 0, i = parts.length - 1; i >= 0; i--) {\n    part = parts[i];\n    if (part === '.') {\n      parts.splice(i, 1);\n    } else if (part === '..') {\n      up++;\n    } else if (up > 0) {\n      if (part === '') {\n        // The first part is blank if the path is absolute. Trying to go\n        // above the root is a no-op. Therefore we can remove all '..' parts\n        // directly after the root.\n        parts.splice(i + 1, up);\n        up = 0;\n      } else {\n        parts.splice(i, 2);\n        up--;\n      }\n    }\n  }\n  path = parts.join('/');\n\n  if (path === '') {\n    path = isAbsolute ? '/' : '.';\n  }\n\n  if (url) {\n    url.path = path;\n    return urlGenerate(url);\n  }\n  return path;\n}\nexports.normalize = normalize;\n\n/**\n * Joins two paths/URLs.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be joined with the root.\n *\n * - If aPath is a URL or a data URI, aPath is returned, unless aPath is a\n *   scheme-relative URL: Then the scheme of aRoot, if any, is prepended\n *   first.\n * - Otherwise aPath is a path. If aRoot is a URL, then its path portion\n *   is updated with the result and aRoot is returned. Otherwise the result\n *   is returned.\n *   - If aPath is absolute, the result is aPath.\n *   - Otherwise the two paths are joined with a slash.\n * - Joining for example 'http://' and 'www.example.com' is also supported.\n */\nfunction join(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n  if (aPath === \"\") {\n    aPath = \".\";\n  }\n  var aPathUrl = urlParse(aPath);\n  var aRootUrl = urlParse(aRoot);\n  if (aRootUrl) {\n    aRoot = aRootUrl.path || '/';\n  }\n\n  // `join(foo, '//www.example.org')`\n  if (aPathUrl && !aPathUrl.scheme) {\n    if (aRootUrl) {\n      aPathUrl.scheme = aRootUrl.scheme;\n    }\n    return urlGenerate(aPathUrl);\n  }\n\n  if (aPathUrl || aPath.match(dataUrlRegexp)) {\n    return aPath;\n  }\n\n  // `join('http://', 'www.example.com')`\n  if (aRootUrl && !aRootUrl.host && !aRootUrl.path) {\n    aRootUrl.host = aPath;\n    return urlGenerate(aRootUrl);\n  }\n\n  var joined = aPath.charAt(0) === '/'\n    ? aPath\n    : normalize(aRoot.replace(/\\/+$/, '') + '/' + aPath);\n\n  if (aRootUrl) {\n    aRootUrl.path = joined;\n    return urlGenerate(aRootUrl);\n  }\n  return joined;\n}\nexports.join = join;\n\nexports.isAbsolute = function (aPath) {\n  return aPath.charAt(0) === '/' || !!aPath.match(urlRegexp);\n};\n\n/**\n * Make a path relative to a URL or another path.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be made relative to aRoot.\n */\nfunction relative(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n\n  aRoot = aRoot.replace(/\\/$/, '');\n\n  // It is possible for the path to be above the root. In this case, simply\n  // checking whether the root is a prefix of the path won't work. Instead, we\n  // need to remove components from the root one by one, until either we find\n  // a prefix that fits, or we run out of components to remove.\n  var level = 0;\n  while (aPath.indexOf(aRoot + '/') !== 0) {\n    var index = aRoot.lastIndexOf(\"/\");\n    if (index < 0) {\n      return aPath;\n    }\n\n    // If the only part of the root that is left is the scheme (i.e. http://,\n    // file:///, etc.), one or more slashes (/), or simply nothing at all, we\n    // have exhausted all components, so the path is not relative to the root.\n    aRoot = aRoot.slice(0, index);\n    if (aRoot.match(/^([^\\/]+:\\/)?\\/*$/)) {\n      return aPath;\n    }\n\n    ++level;\n  }\n\n  // Make sure we add a \"../\" for each component we removed from the root.\n  return Array(level + 1).join(\"../\") + aPath.substr(aRoot.length + 1);\n}\nexports.relative = relative;\n\nvar supportsNullProto = (function () {\n  var obj = Object.create(null);\n  return !('__proto__' in obj);\n}());\n\nfunction identity (s) {\n  return s;\n}\n\n/**\n * Because behavior goes wacky when you set `__proto__` on objects, we\n * have to prefix all the strings in our set with an arbitrary character.\n *\n * See https://github.com/mozilla/source-map/pull/31 and\n * https://github.com/mozilla/source-map/issues/30\n *\n * @param String aStr\n */\nfunction toSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return '$' + aStr;\n  }\n\n  return aStr;\n}\nexports.toSetString = supportsNullProto ? identity : toSetString;\n\nfunction fromSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return aStr.slice(1);\n  }\n\n  return aStr;\n}\nexports.fromSetString = supportsNullProto ? identity : fromSetString;\n\nfunction isProtoString(s) {\n  if (!s) {\n    return false;\n  }\n\n  var length = s.length;\n\n  if (length < 9 /* \"__proto__\".length */) {\n    return false;\n  }\n\n  if (s.charCodeAt(length - 1) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 2) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 3) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 4) !== 116 /* 't' */ ||\n      s.charCodeAt(length - 5) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 6) !== 114 /* 'r' */ ||\n      s.charCodeAt(length - 7) !== 112 /* 'p' */ ||\n      s.charCodeAt(length - 8) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 9) !== 95  /* '_' */) {\n    return false;\n  }\n\n  for (var i = length - 10; i >= 0; i--) {\n    if (s.charCodeAt(i) !== 36 /* '$' */) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * Comparator between two mappings where the original positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same original source/line/column, but different generated\n * line and column the same. Useful when searching for a mapping with a\n * stubbed out mapping.\n */\nfunction compareByOriginalPositions(mappingA, mappingB, onlyCompareOriginal) {\n  var cmp = mappingA.source - mappingB.source;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0 || onlyCompareOriginal) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return mappingA.name - mappingB.name;\n}\nexports.compareByOriginalPositions = compareByOriginalPositions;\n\n/**\n * Comparator between two mappings with deflated source and name indices where\n * the generated positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same generated line and column, but different\n * source/name/original line and column the same. Useful when searching for a\n * mapping with a stubbed out mapping.\n */\nfunction compareByGeneratedPositionsDeflated(mappingA, mappingB, onlyCompareGenerated) {\n  var cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0 || onlyCompareGenerated) {\n    return cmp;\n  }\n\n  cmp = mappingA.source - mappingB.source;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return mappingA.name - mappingB.name;\n}\nexports.compareByGeneratedPositionsDeflated = compareByGeneratedPositionsDeflated;\n\nfunction strcmp(aStr1, aStr2) {\n  if (aStr1 === aStr2) {\n    return 0;\n  }\n\n  if (aStr1 > aStr2) {\n    return 1;\n  }\n\n  return -1;\n}\n\n/**\n * Comparator between two mappings with inflated source and name strings where\n * the generated positions are compared.\n */\nfunction compareByGeneratedPositionsInflated(mappingA, mappingB) {\n  var cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = strcmp(mappingA.source, mappingB.source);\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return strcmp(mappingA.name, mappingB.name);\n}\nexports.compareByGeneratedPositionsInflated = compareByGeneratedPositionsInflated;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/util.js',
          'importMap': {},
          'packageName': 'source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/util.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/source-map/source-map.js': {
        'moduleRecord': {
          'content': "/*\n * Copyright 2009-2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE.txt or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\nexports.SourceMapGenerator = require('./lib/source-map-generator').SourceMapGenerator;\nexports.SourceMapConsumer = require('./lib/source-map-consumer').SourceMapConsumer;\nexports.SourceNode = require('./lib/source-node').SourceNode;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/source-map/source-map.js',
          'importMap': {
            './lib/source-map-consumer': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-map-consumer.js',
            './lib/source-map-generator': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-map-generator.js',
            './lib/source-node': '/home/xyz/Development/webtorrent/node_modules/source-map/lib/source-node.js',
          },
          'packageName': 'source-map',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/source-map/source-map.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/index.js': {
        'moduleRecord': {
          'content': "var PassThrough = require('readable-stream').PassThrough\nvar Readable = require('readable-stream').Readable\nvar duplexer = require('duplexer2')\n\nmodule.exports = function () {\n  var streams\n  if(arguments.length == 1 && Array.isArray(arguments[0])) {\n    streams = arguments[0]\n  } else {\n    streams = [].slice.call(arguments)\n  }\n  return combine(streams)\n}\n\nmodule.exports.obj = function () {\n  var streams\n  if(arguments.length == 1 && Array.isArray(arguments[0])) {\n    streams = arguments[0]\n  } else {\n    streams = [].slice.call(arguments)\n  }\n  return combine(streams, { objectMode: true })\n}\n\n  \nfunction combine (streams, opts) {\n\n  for (var i = 0; i < streams.length; i++)\n    streams[i] = wrap(streams[i], opts)\n\n  if(streams.length == 0)\n    return new PassThrough(opts)\n  else if(streams.length == 1)\n    return streams[0]\n\n  var first = streams[0]\n    , last = streams[streams.length - 1]\n    , thepipe = duplexer(opts, first, last)\n\n  //pipe all the streams together\n\n  function recurse (streams) {\n    if(streams.length < 2)\n      return\n    streams[0].pipe(streams[1])\n    recurse(streams.slice(1))\n  }\n\n  recurse(streams)\n\n  function onerror () {\n    var args = [].slice.call(arguments)\n    args.unshift('error')\n    thepipe.emit.apply(thepipe, args)\n  }\n\n  //es.duplex already reemits the error from the first and last stream.\n  //add a listener for the inner streams in the pipeline.\n  for(var i = 1; i < streams.length - 1; i ++)\n    streams[i].on('error', onerror)\n\n  return thepipe\n}\n\nfunction wrap (tr, opts) {\n  if (typeof tr.read === 'function') return tr\n  return new Readable(opts).wrap(tr)\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/index.js',
          'importMap': {
            'duplexer2': '/home/xyz/Development/webtorrent/node_modules/duplexer2/index.js',
            'readable-stream': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/readable.js',
          },
          'packageName': 'stream-combiner2',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_duplex.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_duplex.js',
          'importMap': {
            './_stream_readable': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_readable.js',
            './_stream_writable': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_writable.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_duplex.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_passthrough.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_passthrough.js',
          'importMap': {
            './_stream_transform': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_transform.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_passthrough.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_readable.js': {
        'builtin': [
          'events.EventEmitter',
          'util',
          'util.debuglog',
        ],
        'globals': {
          'process.stderr': 'read',
          'process.stdout': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar destroyImpl = require('./internal/streams/destroy');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_readable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/BufferList': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/BufferList.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'events': 'events',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'isarray': '/home/xyz/Development/webtorrent/node_modules/isarray/index.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/safe-buffer/index.js',
            'string_decoder/': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/string_decoder/lib/string_decoder.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_transform.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_transform.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_duplex.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_transform.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_writable.js': {
        'globals': {
          'process.browser': 'read',
          'process.version.slice': 'read',
          'setImmediate': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_writable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/safe-buffer/index.js',
            'util-deprecate': '/home/xyz/Development/webtorrent/node_modules/util-deprecate/node.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_writable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/BufferList.js': {
        'builtin': [
          'util',
          'util.inspect',
          'util.inspect.custom',
        ],
        'moduleRecord': {
          'content': "'use strict';\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = require('safe-buffer').Buffer;\nvar util = require('util');\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/safe-buffer/index.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/destroy.js': {
        'moduleRecord': {
          'content': "'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'importMap': {
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/stream.js': {
        'builtin': [
          'stream',
        ],
        'moduleRecord': {
          'content': "module.exports = require('stream');\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/stream.js',
          'importMap': {
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/internal/streams/stream.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/readable.js': {
        'builtin': [
          'stream',
          'stream.Readable',
          'stream.Writable',
          'stream.Duplex',
          'stream.Transform',
          'stream.PassThrough',
        ],
        'globals': {
          'process.env.READABLE_STREAM': 'read',
        },
        'moduleRecord': {
          'content': "var Stream = require('stream');\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n  exports = module.exports = Stream.Readable;\n  exports.Readable = Stream.Readable;\n  exports.Writable = Stream.Writable;\n  exports.Duplex = Stream.Duplex;\n  exports.Transform = Stream.Transform;\n  exports.PassThrough = Stream.PassThrough;\n  exports.Stream = Stream;\n} else {\n  exports = module.exports = require('./lib/_stream_readable.js');\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = require('./lib/_stream_writable.js');\n  exports.Duplex = require('./lib/_stream_duplex.js');\n  exports.Transform = require('./lib/_stream_transform.js');\n  exports.PassThrough = require('./lib/_stream_passthrough.js');\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/readable.js',
          'importMap': {
            './lib/_stream_duplex.js': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_duplex.js',
            './lib/_stream_passthrough.js': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_passthrough.js',
            './lib/_stream_readable.js': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_readable.js',
            './lib/_stream_transform.js': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_transform.js',
            './lib/_stream_writable.js': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/lib/_stream_writable.js',
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/readable-stream/readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/safe-buffer/index.js': {
        'builtin': [
          'buffer.Buffer',
          'buffer',
          'buffer.SlowBuffer',
        ],
        'moduleRecord': {
          'content': "/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/safe-buffer/index.js',
          'importMap': {
            'buffer': 'buffer',
          },
          'packageName': 'safe-buffer',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/safe-buffer/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/string_decoder/lib/string_decoder.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/string_decoder/lib/string_decoder.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/safe-buffer/index.js',
          },
          'packageName': 'string_decoder',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-combiner2/node_modules/string_decoder/lib/string_decoder.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/index.js': {
        'globals': {
          'process.nextTick': 'read',
          'setImmediate': 'read',
        },
        'moduleRecord': {
          'content': "var Duplex = require('readable-stream').Duplex;\nvar PassThrough = require('readable-stream').PassThrough;\nvar Readable = require('readable-stream').Readable;\nvar inherits = require('inherits');\n\nvar nextTick = typeof setImmediate !== 'undefined'\n    ? setImmediate : process.nextTick\n;\n\nmodule.exports = Pipeline;\ninherits(Pipeline, Duplex);\n\nmodule.exports.obj = function (streams, opts) {\n    if (!opts && !Array.isArray(streams)) {\n        opts = streams;\n        streams = [];\n    }\n    if (!streams) streams = [];\n    if (!opts) opts = {};\n    opts.objectMode = true;\n    return new Pipeline(streams, opts);\n};\n\nfunction Pipeline (streams, opts) {\n    if (!(this instanceof Pipeline)) return new Pipeline(streams, opts);\n    if (!opts && !Array.isArray(streams)) {\n        opts = streams;\n        streams = [];\n    }\n    if (!streams) streams = [];\n    if (!opts) opts = {};\n    Duplex.call(this, opts);\n    \n    var self = this;\n    this._options = opts;\n    this._wrapOptions = { objectMode: opts.objectMode !== false };\n    this._streams = [];\n    \n    this.splice.apply(this, [ 0, 0 ].concat(streams));\n    \n    this.once('finish', function () {\n        self._notEmpty();\n        self._streams[0].end();\n    });\n}\n\nPipeline.prototype._read = function () {\n    var self = this;\n    this._notEmpty();\n    \n    var r = this._streams[this._streams.length-1];\n    var buf, reads = 0;\n    while ((buf = r.read()) !== null) {\n        Duplex.prototype.push.call(this, buf);\n        reads ++;\n    }\n    if (reads === 0) {\n        var onreadable = function () {\n            r.removeListener('readable', onreadable);\n            self.removeListener('_mutate', onreadable);\n            self._read()\n        };\n        r.once('readable', onreadable);\n        self.once('_mutate', onreadable);\n    }\n};\n\nPipeline.prototype._write = function (buf, enc, next) {\n    this._notEmpty();\n    this._streams[0]._write(buf, enc, next);\n};\n\nPipeline.prototype._notEmpty = function () {\n    var self = this;\n    if (this._streams.length > 0) return;\n    var stream = new PassThrough(this._options);\n    stream.once('end', function () {\n        var ix = self._streams.indexOf(stream);\n        if (ix >= 0 && ix === self._streams.length - 1) {\n            Duplex.prototype.push.call(self, null);\n        }\n    });\n    this._streams.push(stream);\n    this.length = this._streams.length;\n};\n\nPipeline.prototype.push = function (stream) {\n    var args = [ this._streams.length, 0 ].concat([].slice.call(arguments));\n    this.splice.apply(this, args);\n    return this._streams.length;\n};\n\nPipeline.prototype.pop = function () {\n    return this.splice(this._streams.length-1,1)[0];\n};\n\nPipeline.prototype.shift = function () {\n    return this.splice(0,1)[0];\n};\n\nPipeline.prototype.unshift = function () {\n    this.splice.apply(this, [0,0].concat([].slice.call(arguments)));\n    return this._streams.length;\n};\n\nPipeline.prototype.splice = function (start, removeLen) {\n    var self = this;\n    var len = this._streams.length;\n    start = start < 0 ? len - start : start;\n    if (removeLen === undefined) removeLen = len - start;\n    removeLen = Math.max(0, Math.min(len - start, removeLen));\n    \n    for (var i = start; i < start + removeLen; i++) {\n        if (self._streams[i-1]) {\n            self._streams[i-1].unpipe(self._streams[i]);\n        }\n    }\n    if (self._streams[i-1] && self._streams[i]) {\n        self._streams[i-1].unpipe(self._streams[i]);\n    }\n    var end = i;\n    \n    var reps = [], args = arguments;\n    for (var j = 2; j < args.length; j++) (function (stream) {\n        if (Array.isArray(stream)) {\n            stream = new Pipeline(stream, self._options);\n        }\n        stream.on('error', function (err) {\n            err.stream = this;\n            self.emit('error', err);\n        });\n        stream = self._wrapStream(stream);\n        stream.once('end', function () {\n            var ix = self._streams.indexOf(stream);\n            if (ix >= 0 && ix === self._streams.length - 1) {\n                Duplex.prototype.push.call(self, null);\n            }\n        });\n        reps.push(stream);\n    })(arguments[j]);\n    \n    for (var i = 0; i < reps.length - 1; i++) {\n        reps[i].pipe(reps[i+1]);\n    }\n    \n    if (reps.length && self._streams[end]) {\n        reps[reps.length-1].pipe(self._streams[end]);\n    }\n    if (reps[0] && self._streams[start-1]) {\n        self._streams[start-1].pipe(reps[0]);\n    }\n    \n    var sargs = [start,removeLen].concat(reps);\n    var removed = self._streams.splice.apply(self._streams, sargs);\n    \n    for (var i = 0; i < reps.length; i++) {\n        reps[i].read(0);\n    }\n    \n    this.emit('_mutate');\n    this.length = this._streams.length;\n    return removed;\n};\n\nPipeline.prototype.get = function () {\n    if (arguments.length === 0) return undefined;\n    \n    var base = this;\n    for (var i = 0; i < arguments.length; i++) {\n        var index = arguments[i];\n        if (index < 0) {\n            base = base._streams[base._streams.length + index];\n        }\n        else {\n            base = base._streams[index];\n        }\n        if (!base) return undefined;\n    }\n    return base;\n};\n\nPipeline.prototype.indexOf = function (stream) {\n    return this._streams.indexOf(stream);\n};\n\nPipeline.prototype._wrapStream = function (stream) {\n    if (typeof stream.read === 'function') return stream;\n    var w = new Readable(this._wrapOptions).wrap(stream);\n    w._write = function (buf, enc, next) {\n        if (stream.write(buf) === false) {\n            stream.once('drain', next);\n        }\n        else nextTick(next);\n    };\n    return w;\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/index.js',
          'importMap': {
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'readable-stream': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/readable.js',
          },
          'packageName': 'stream-splicer',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_duplex.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_duplex.js',
          'importMap': {
            './_stream_readable': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_readable.js',
            './_stream_writable': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_writable.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_duplex.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_passthrough.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_passthrough.js',
          'importMap': {
            './_stream_transform': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_transform.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_passthrough.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_readable.js': {
        'builtin': [
          'events.EventEmitter',
          'util',
          'util.debuglog',
        ],
        'globals': {
          'process.stderr': 'read',
          'process.stdout': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar destroyImpl = require('./internal/streams/destroy');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_readable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/BufferList': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/BufferList.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'events': 'events',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'isarray': '/home/xyz/Development/webtorrent/node_modules/isarray/index.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/safe-buffer/index.js',
            'string_decoder/': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/string_decoder/lib/string_decoder.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_transform.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_transform.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_duplex.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_transform.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_writable.js': {
        'globals': {
          'process.browser': 'read',
          'process.version.slice': 'read',
          'setImmediate': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_writable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/safe-buffer/index.js',
            'util-deprecate': '/home/xyz/Development/webtorrent/node_modules/util-deprecate/node.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_writable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/BufferList.js': {
        'builtin': [
          'util',
          'util.inspect',
          'util.inspect.custom',
        ],
        'moduleRecord': {
          'content': "'use strict';\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = require('safe-buffer').Buffer;\nvar util = require('util');\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/safe-buffer/index.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/destroy.js': {
        'moduleRecord': {
          'content': "'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'importMap': {
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/stream.js': {
        'builtin': [
          'stream',
        ],
        'moduleRecord': {
          'content': "module.exports = require('stream');\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/stream.js',
          'importMap': {
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/internal/streams/stream.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/readable.js': {
        'builtin': [
          'stream',
          'stream.Readable',
          'stream.Writable',
          'stream.Duplex',
          'stream.Transform',
          'stream.PassThrough',
        ],
        'globals': {
          'process.env.READABLE_STREAM': 'read',
        },
        'moduleRecord': {
          'content': "var Stream = require('stream');\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n  exports = module.exports = Stream.Readable;\n  exports.Readable = Stream.Readable;\n  exports.Writable = Stream.Writable;\n  exports.Duplex = Stream.Duplex;\n  exports.Transform = Stream.Transform;\n  exports.PassThrough = Stream.PassThrough;\n  exports.Stream = Stream;\n} else {\n  exports = module.exports = require('./lib/_stream_readable.js');\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = require('./lib/_stream_writable.js');\n  exports.Duplex = require('./lib/_stream_duplex.js');\n  exports.Transform = require('./lib/_stream_transform.js');\n  exports.PassThrough = require('./lib/_stream_passthrough.js');\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/readable.js',
          'importMap': {
            './lib/_stream_duplex.js': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_duplex.js',
            './lib/_stream_passthrough.js': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_passthrough.js',
            './lib/_stream_readable.js': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_readable.js',
            './lib/_stream_transform.js': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_transform.js',
            './lib/_stream_writable.js': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/lib/_stream_writable.js',
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/readable-stream/readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/safe-buffer/index.js': {
        'builtin': [
          'buffer.Buffer',
          'buffer',
          'buffer.SlowBuffer',
        ],
        'moduleRecord': {
          'content': "/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/safe-buffer/index.js',
          'importMap': {
            'buffer': 'buffer',
          },
          'packageName': 'safe-buffer',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/safe-buffer/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/string_decoder/lib/string_decoder.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/string_decoder/lib/string_decoder.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/safe-buffer/index.js',
          },
          'packageName': 'string_decoder',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/stream-splicer/node_modules/string_decoder/lib/string_decoder.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/syntax-error/index.js': {
        'moduleRecord': {
          'content': "var aparse = require('acorn-node').parse;\nfunction parse (src, opts) {\n    if (!opts) opts = {}\n    return aparse(src, opts);\n}\n\nmodule.exports = function (src, file,opts) {\n    if (typeof src !== 'string') src = String(src);\n    \n    try {\n        eval('throw \"STOP\"; (function () { ' + src + '\\n})()');\n        return;\n    }\n    catch (err) {\n        if (err === 'STOP') return undefined;\n        if (err.constructor.name !== 'SyntaxError') return err;\n        return errorInfo(src, file, opts);\n    }\n};\n\nfunction errorInfo (src, file, opts) {\n    try { parse(src,opts) }\n    catch (err) {\n        return new ParseError(err, src, file);\n    }\n    return undefined;\n}\n\nfunction ParseError (err, src, file) {\n    SyntaxError.call(this);\n    \n    this.message = err.message.replace(/\\s+\\(\\d+:\\d+\\)$/, '');\n    \n    this.line = err.loc.line;\n    this.column = err.loc.column + 1;\n    \n    this.annotated = '\\n'\n        + (file || '(anonymous file)')\n        + ':' + this.line\n        + '\\n'\n        + src.split('\\n')[this.line - 1]\n        + '\\n'\n        + Array(this.column).join(' ') + '^'\n        + '\\n'\n        + 'ParseError: ' + this.message\n    ;\n}\n\nParseError.prototype = Object.create(SyntaxError.prototype);\n\nParseError.prototype.toString = function () {\n    return this.annotated;\n};\n\nParseError.prototype.inspect = function () {\n    return this.annotated;\n};\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/syntax-error/index.js',
          'importMap': {
            'acorn-node': '/home/xyz/Development/webtorrent/node_modules/acorn-node/index.js',
          },
          'packageName': 'syntax-error',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/syntax-error/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through/index.js': {
        'builtin': [
          'stream',
        ],
        'globals': {
          'process.nextTick': 'read',
        },
        'moduleRecord': {
          'content': "var Stream = require('stream')\n\n// through\n//\n// a stream that does nothing but re-emit the input.\n// useful for aggregating a series of changing but not ending streams into one stream)\n\nexports = module.exports = through\nthrough.through = through\n\n//create a readable writable stream.\n\nfunction through (write, end, opts) {\n  write = write || function (data) { this.queue(data) }\n  end = end || function () { this.queue(null) }\n\n  var ended = false, destroyed = false, buffer = [], _ended = false\n  var stream = new Stream()\n  stream.readable = stream.writable = true\n  stream.paused = false\n\n//  stream.autoPause   = !(opts && opts.autoPause   === false)\n  stream.autoDestroy = !(opts && opts.autoDestroy === false)\n\n  stream.write = function (data) {\n    write.call(this, data)\n    return !stream.paused\n  }\n\n  function drain() {\n    while(buffer.length && !stream.paused) {\n      var data = buffer.shift()\n      if(null === data)\n        return stream.emit('end')\n      else\n        stream.emit('data', data)\n    }\n  }\n\n  stream.queue = stream.push = function (data) {\n//    console.error(ended)\n    if(_ended) return stream\n    if(data === null) _ended = true\n    buffer.push(data)\n    drain()\n    return stream\n  }\n\n  //this will be registered as the first 'end' listener\n  //must call destroy next tick, to make sure we're after any\n  //stream piped from here.\n  //this is only a problem if end is not emitted synchronously.\n  //a nicer way to do this is to make sure this is the last listener for 'end'\n\n  stream.on('end', function () {\n    stream.readable = false\n    if(!stream.writable && stream.autoDestroy)\n      process.nextTick(function () {\n        stream.destroy()\n      })\n  })\n\n  function _end () {\n    stream.writable = false\n    end.call(stream)\n    if(!stream.readable && stream.autoDestroy)\n      stream.destroy()\n  }\n\n  stream.end = function (data) {\n    if(ended) return\n    ended = true\n    if(arguments.length) stream.write(data)\n    _end() // will emit or queue\n    return stream\n  }\n\n  stream.destroy = function () {\n    if(destroyed) return\n    destroyed = true\n    ended = true\n    buffer.length = 0\n    stream.writable = stream.readable = false\n    stream.emit('close')\n    return stream\n  }\n\n  stream.pause = function () {\n    if(stream.paused) return\n    stream.paused = true\n    return stream\n  }\n\n  stream.resume = function () {\n    if(stream.paused) {\n      stream.paused = false\n      stream.emit('resume')\n    }\n    drain()\n    //may have become paused again,\n    //as drain emits 'data'.\n    if(!stream.paused)\n      stream.emit('drain')\n    return stream\n  }\n  return stream\n}\n\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/through/index.js',
          'importMap': {
            'stream': 'stream',
          },
          'packageName': 'through',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_duplex.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_duplex.js',
          'importMap': {
            './_stream_readable': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_readable.js',
            './_stream_writable': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_writable.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_duplex.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_passthrough.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_passthrough.js',
          'importMap': {
            './_stream_transform': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_transform.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_passthrough.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_readable.js': {
        'builtin': [
          'events.EventEmitter',
          'util',
          'util.debuglog',
        ],
        'globals': {
          'process.stderr': 'read',
          'process.stdout': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar destroyImpl = require('./internal/streams/destroy');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_readable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/BufferList': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/BufferList.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'events': 'events',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'isarray': '/home/xyz/Development/webtorrent/node_modules/isarray/index.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/safe-buffer/index.js',
            'string_decoder/': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/string_decoder/lib/string_decoder.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_transform.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_transform.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_duplex.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_transform.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_writable.js': {
        'globals': {
          'process.browser': 'read',
          'process.version.slice': 'read',
          'setImmediate': 'read',
        },
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_writable.js',
          'importMap': {
            './_stream_duplex': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_duplex.js',
            './internal/streams/destroy': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/destroy.js',
            './internal/streams/stream': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/stream.js',
            'core-util-is': '/home/xyz/Development/webtorrent/node_modules/core-util-is/lib/util.js',
            'inherits': '/home/xyz/Development/webtorrent/node_modules/inherits/inherits.js',
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/safe-buffer/index.js',
            'util-deprecate': '/home/xyz/Development/webtorrent/node_modules/util-deprecate/node.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_writable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/BufferList.js': {
        'builtin': [
          'util',
          'util.inspect',
          'util.inspect.custom',
        ],
        'moduleRecord': {
          'content': "'use strict';\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = require('safe-buffer').Buffer;\nvar util = require('util');\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/safe-buffer/index.js',
            'util': 'util',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/BufferList.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/destroy.js': {
        'moduleRecord': {
          'content': "'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'importMap': {
            'process-nextick-args': '/home/xyz/Development/webtorrent/node_modules/process-nextick-args/index.js',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/destroy.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/stream.js': {
        'builtin': [
          'stream',
        ],
        'moduleRecord': {
          'content': "module.exports = require('stream');\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/stream.js',
          'importMap': {
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/internal/streams/stream.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/readable.js': {
        'builtin': [
          'stream',
          'stream.Readable',
          'stream.Writable',
          'stream.Duplex',
          'stream.Transform',
          'stream.PassThrough',
        ],
        'globals': {
          'process.env.READABLE_STREAM': 'read',
        },
        'moduleRecord': {
          'content': "var Stream = require('stream');\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n  exports = module.exports = Stream.Readable;\n  exports.Readable = Stream.Readable;\n  exports.Writable = Stream.Writable;\n  exports.Duplex = Stream.Duplex;\n  exports.Transform = Stream.Transform;\n  exports.PassThrough = Stream.PassThrough;\n  exports.Stream = Stream;\n} else {\n  exports = module.exports = require('./lib/_stream_readable.js');\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = require('./lib/_stream_writable.js');\n  exports.Duplex = require('./lib/_stream_duplex.js');\n  exports.Transform = require('./lib/_stream_transform.js');\n  exports.PassThrough = require('./lib/_stream_passthrough.js');\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/readable.js',
          'importMap': {
            './lib/_stream_duplex.js': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_duplex.js',
            './lib/_stream_passthrough.js': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_passthrough.js',
            './lib/_stream_readable.js': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_readable.js',
            './lib/_stream_transform.js': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_transform.js',
            './lib/_stream_writable.js': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/lib/_stream_writable.js',
            'stream': 'stream',
          },
          'packageName': 'readable-stream',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/readable.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/safe-buffer/index.js': {
        'builtin': [
          'buffer.Buffer',
          'buffer',
          'buffer.SlowBuffer',
        ],
        'moduleRecord': {
          'content': "/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/safe-buffer/index.js',
          'importMap': {
            'buffer': 'buffer',
          },
          'packageName': 'safe-buffer',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/safe-buffer/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/string_decoder/lib/string_decoder.js': {
        'moduleRecord': {
          'content': "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/string_decoder/lib/string_decoder.js',
          'importMap': {
            'safe-buffer': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/safe-buffer/index.js',
          },
          'packageName': 'string_decoder',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/string_decoder/lib/string_decoder.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/through2/through2.js': {
        'builtin': [
          'util.inherits',
        ],
        'globals': {
          'process.nextTick': 'read',
        },
        'moduleRecord': {
          'content': "var Transform = require('readable-stream').Transform\n  , inherits  = require('util').inherits\n  , xtend     = require('xtend')\n\nfunction DestroyableTransform(opts) {\n  Transform.call(this, opts)\n  this._destroyed = false\n}\n\ninherits(DestroyableTransform, Transform)\n\nDestroyableTransform.prototype.destroy = function(err) {\n  if (this._destroyed) return\n  this._destroyed = true\n  \n  var self = this\n  process.nextTick(function() {\n    if (err)\n      self.emit('error', err)\n    self.emit('close')\n  })\n}\n\n// a noop _transform function\nfunction noop (chunk, enc, callback) {\n  callback(null, chunk)\n}\n\n\n// create a new export function, used by both the main export and\n// the .ctor export, contains common logic for dealing with arguments\nfunction through2 (construct) {\n  return function (options, transform, flush) {\n    if (typeof options == 'function') {\n      flush     = transform\n      transform = options\n      options   = {}\n    }\n\n    if (typeof transform != 'function')\n      transform = noop\n\n    if (typeof flush != 'function')\n      flush = null\n\n    return construct(options, transform, flush)\n  }\n}\n\n\n// main export, just make me a transform stream!\nmodule.exports = through2(function (options, transform, flush) {\n  var t2 = new DestroyableTransform(options)\n\n  t2._transform = transform\n\n  if (flush)\n    t2._flush = flush\n\n  return t2\n})\n\n\n// make me a reusable prototype that I can `new`, or implicitly `new`\n// with a constructor call\nmodule.exports.ctor = through2(function (options, transform, flush) {\n  function Through2 (override) {\n    if (!(this instanceof Through2))\n      return new Through2(override)\n\n    this.options = xtend(options, override)\n\n    DestroyableTransform.call(this, this.options)\n  }\n\n  inherits(Through2, DestroyableTransform)\n\n  Through2.prototype._transform = transform\n\n  if (flush)\n    Through2.prototype._flush = flush\n\n  return Through2\n})\n\n\nmodule.exports.obj = through2(function (options, transform, flush) {\n  var t2 = new DestroyableTransform(xtend({ objectMode: true, highWaterMark: 16 }, options))\n\n  t2._transform = transform\n\n  if (flush)\n    t2._flush = flush\n\n  return t2\n})\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/through2/through2.js',
          'importMap': {
            'readable-stream': '/home/xyz/Development/webtorrent/node_modules/through2/node_modules/readable-stream/readable.js',
            'util': 'util',
            'xtend': '/home/xyz/Development/webtorrent/node_modules/xtend/immutable.js',
          },
          'packageName': 'through2',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/through2/through2.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/typedarray/index.js': {
        'moduleRecord': {
          'content': "var undefined = (void 0); // Paranoia\n\n// Beyond this value, index getters/setters (i.e. array[0], array[1]) are so slow to\n// create, and consume so much memory, that the browser appears frozen.\nvar MAX_ARRAY_LENGTH = 1e5;\n\n// Approximations of internal ECMAScript conversion functions\nvar ECMAScript = (function() {\n  // Stash a copy in case other scripts modify these\n  var opts = Object.prototype.toString,\n      ophop = Object.prototype.hasOwnProperty;\n\n  return {\n    // Class returns internal [[Class]] property, used to avoid cross-frame instanceof issues:\n    Class: function(v) { return opts.call(v).replace(/^\\[object *|\\]$/g, ''); },\n    HasProperty: function(o, p) { return p in o; },\n    HasOwnProperty: function(o, p) { return ophop.call(o, p); },\n    IsCallable: function(o) { return typeof o === 'function'; },\n    ToInt32: function(v) { return v >> 0; },\n    ToUint32: function(v) { return v >>> 0; }\n  };\n}());\n\n// Snapshot intrinsics\nvar LN2 = Math.LN2,\n    abs = Math.abs,\n    floor = Math.floor,\n    log = Math.log,\n    min = Math.min,\n    pow = Math.pow,\n    round = Math.round;\n\n// ES5: lock down object properties\nfunction configureProperties(obj) {\n  if (getOwnPropNames && defineProp) {\n    var props = getOwnPropNames(obj), i;\n    for (i = 0; i < props.length; i += 1) {\n      defineProp(obj, props[i], {\n        value: obj[props[i]],\n        writable: false,\n        enumerable: false,\n        configurable: false\n      });\n    }\n  }\n}\n\n// emulate ES5 getter/setter API using legacy APIs\n// http://blogs.msdn.com/b/ie/archive/2010/09/07/transitioning-existing-code-to-the-es5-getter-setter-apis.aspx\n// (second clause tests for Object.defineProperty() in IE<9 that only supports extending DOM prototypes, but\n// note that IE<9 does not support __defineGetter__ or __defineSetter__ so it just renders the method harmless)\nvar defineProp\nif (Object.defineProperty && (function() {\n      try {\n        Object.defineProperty({}, 'x', {});\n        return true;\n      } catch (e) {\n        return false;\n      }\n    })()) {\n  defineProp = Object.defineProperty;\n} else {\n  defineProp = function(o, p, desc) {\n    if (!o === Object(o)) throw new TypeError(\"Object.defineProperty called on non-object\");\n    if (ECMAScript.HasProperty(desc, 'get') && Object.prototype.__defineGetter__) { Object.prototype.__defineGetter__.call(o, p, desc.get); }\n    if (ECMAScript.HasProperty(desc, 'set') && Object.prototype.__defineSetter__) { Object.prototype.__defineSetter__.call(o, p, desc.set); }\n    if (ECMAScript.HasProperty(desc, 'value')) { o[p] = desc.value; }\n    return o;\n  };\n}\n\nvar getOwnPropNames = Object.getOwnPropertyNames || function (o) {\n  if (o !== Object(o)) throw new TypeError(\"Object.getOwnPropertyNames called on non-object\");\n  var props = [], p;\n  for (p in o) {\n    if (ECMAScript.HasOwnProperty(o, p)) {\n      props.push(p);\n    }\n  }\n  return props;\n};\n\n// ES5: Make obj[index] an alias for obj._getter(index)/obj._setter(index, value)\n// for index in 0 ... obj.length\nfunction makeArrayAccessors(obj) {\n  if (!defineProp) { return; }\n\n  if (obj.length > MAX_ARRAY_LENGTH) throw new RangeError(\"Array too large for polyfill\");\n\n  function makeArrayAccessor(index) {\n    defineProp(obj, index, {\n      'get': function() { return obj._getter(index); },\n      'set': function(v) { obj._setter(index, v); },\n      enumerable: true,\n      configurable: false\n    });\n  }\n\n  var i;\n  for (i = 0; i < obj.length; i += 1) {\n    makeArrayAccessor(i);\n  }\n}\n\n// Internal conversion functions:\n//    pack<Type>()   - take a number (interpreted as Type), output a byte array\n//    unpack<Type>() - take a byte array, output a Type-like number\n\nfunction as_signed(value, bits) { var s = 32 - bits; return (value << s) >> s; }\nfunction as_unsigned(value, bits) { var s = 32 - bits; return (value << s) >>> s; }\n\nfunction packI8(n) { return [n & 0xff]; }\nfunction unpackI8(bytes) { return as_signed(bytes[0], 8); }\n\nfunction packU8(n) { return [n & 0xff]; }\nfunction unpackU8(bytes) { return as_unsigned(bytes[0], 8); }\n\nfunction packU8Clamped(n) { n = round(Number(n)); return [n < 0 ? 0 : n > 0xff ? 0xff : n & 0xff]; }\n\nfunction packI16(n) { return [(n >> 8) & 0xff, n & 0xff]; }\nfunction unpackI16(bytes) { return as_signed(bytes[0] << 8 | bytes[1], 16); }\n\nfunction packU16(n) { return [(n >> 8) & 0xff, n & 0xff]; }\nfunction unpackU16(bytes) { return as_unsigned(bytes[0] << 8 | bytes[1], 16); }\n\nfunction packI32(n) { return [(n >> 24) & 0xff, (n >> 16) & 0xff, (n >> 8) & 0xff, n & 0xff]; }\nfunction unpackI32(bytes) { return as_signed(bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], 32); }\n\nfunction packU32(n) { return [(n >> 24) & 0xff, (n >> 16) & 0xff, (n >> 8) & 0xff, n & 0xff]; }\nfunction unpackU32(bytes) { return as_unsigned(bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], 32); }\n\nfunction packIEEE754(v, ebits, fbits) {\n\n  var bias = (1 << (ebits - 1)) - 1,\n      s, e, f, ln,\n      i, bits, str, bytes;\n\n  function roundToEven(n) {\n    var w = floor(n), f = n - w;\n    if (f < 0.5)\n      return w;\n    if (f > 0.5)\n      return w + 1;\n    return w % 2 ? w + 1 : w;\n  }\n\n  // Compute sign, exponent, fraction\n  if (v !== v) {\n    // NaN\n    // http://dev.w3.org/2006/webapi/WebIDL/#es-type-mapping\n    e = (1 << ebits) - 1; f = pow(2, fbits - 1); s = 0;\n  } else if (v === Infinity || v === -Infinity) {\n    e = (1 << ebits) - 1; f = 0; s = (v < 0) ? 1 : 0;\n  } else if (v === 0) {\n    e = 0; f = 0; s = (1 / v === -Infinity) ? 1 : 0;\n  } else {\n    s = v < 0;\n    v = abs(v);\n\n    if (v >= pow(2, 1 - bias)) {\n      e = min(floor(log(v) / LN2), 1023);\n      f = roundToEven(v / pow(2, e) * pow(2, fbits));\n      if (f / pow(2, fbits) >= 2) {\n        e = e + 1;\n        f = 1;\n      }\n      if (e > bias) {\n        // Overflow\n        e = (1 << ebits) - 1;\n        f = 0;\n      } else {\n        // Normalized\n        e = e + bias;\n        f = f - pow(2, fbits);\n      }\n    } else {\n      // Denormalized\n      e = 0;\n      f = roundToEven(v / pow(2, 1 - bias - fbits));\n    }\n  }\n\n  // Pack sign, exponent, fraction\n  bits = [];\n  for (i = fbits; i; i -= 1) { bits.push(f % 2 ? 1 : 0); f = floor(f / 2); }\n  for (i = ebits; i; i -= 1) { bits.push(e % 2 ? 1 : 0); e = floor(e / 2); }\n  bits.push(s ? 1 : 0);\n  bits.reverse();\n  str = bits.join('');\n\n  // Bits to bytes\n  bytes = [];\n  while (str.length) {\n    bytes.push(parseInt(str.substring(0, 8), 2));\n    str = str.substring(8);\n  }\n  return bytes;\n}\n\nfunction unpackIEEE754(bytes, ebits, fbits) {\n\n  // Bytes to bits\n  var bits = [], i, j, b, str,\n      bias, s, e, f;\n\n  for (i = bytes.length; i; i -= 1) {\n    b = bytes[i - 1];\n    for (j = 8; j; j -= 1) {\n      bits.push(b % 2 ? 1 : 0); b = b >> 1;\n    }\n  }\n  bits.reverse();\n  str = bits.join('');\n\n  // Unpack sign, exponent, fraction\n  bias = (1 << (ebits - 1)) - 1;\n  s = parseInt(str.substring(0, 1), 2) ? -1 : 1;\n  e = parseInt(str.substring(1, 1 + ebits), 2);\n  f = parseInt(str.substring(1 + ebits), 2);\n\n  // Produce number\n  if (e === (1 << ebits) - 1) {\n    return f !== 0 ? NaN : s * Infinity;\n  } else if (e > 0) {\n    // Normalized\n    return s * pow(2, e - bias) * (1 + f / pow(2, fbits));\n  } else if (f !== 0) {\n    // Denormalized\n    return s * pow(2, -(bias - 1)) * (f / pow(2, fbits));\n  } else {\n    return s < 0 ? -0 : 0;\n  }\n}\n\nfunction unpackF64(b) { return unpackIEEE754(b, 11, 52); }\nfunction packF64(v) { return packIEEE754(v, 11, 52); }\nfunction unpackF32(b) { return unpackIEEE754(b, 8, 23); }\nfunction packF32(v) { return packIEEE754(v, 8, 23); }\n\n\n//\n// 3 The ArrayBuffer Type\n//\n\n(function() {\n\n  /** @constructor */\n  var ArrayBuffer = function ArrayBuffer(length) {\n    length = ECMAScript.ToInt32(length);\n    if (length < 0) throw new RangeError('ArrayBuffer size is not a small enough positive integer');\n\n    this.byteLength = length;\n    this._bytes = [];\n    this._bytes.length = length;\n\n    var i;\n    for (i = 0; i < this.byteLength; i += 1) {\n      this._bytes[i] = 0;\n    }\n\n    configureProperties(this);\n  };\n\n  exports.ArrayBuffer = exports.ArrayBuffer || ArrayBuffer;\n\n  //\n  // 4 The ArrayBufferView Type\n  //\n\n  // NOTE: this constructor is not exported\n  /** @constructor */\n  var ArrayBufferView = function ArrayBufferView() {\n    //this.buffer = null;\n    //this.byteOffset = 0;\n    //this.byteLength = 0;\n  };\n\n  //\n  // 5 The Typed Array View Types\n  //\n\n  function makeConstructor(bytesPerElement, pack, unpack) {\n    // Each TypedArray type requires a distinct constructor instance with\n    // identical logic, which this produces.\n\n    var ctor;\n    ctor = function(buffer, byteOffset, length) {\n      var array, sequence, i, s;\n\n      if (!arguments.length || typeof arguments[0] === 'number') {\n        // Constructor(unsigned long length)\n        this.length = ECMAScript.ToInt32(arguments[0]);\n        if (length < 0) throw new RangeError('ArrayBufferView size is not a small enough positive integer');\n\n        this.byteLength = this.length * this.BYTES_PER_ELEMENT;\n        this.buffer = new ArrayBuffer(this.byteLength);\n        this.byteOffset = 0;\n      } else if (typeof arguments[0] === 'object' && arguments[0].constructor === ctor) {\n        // Constructor(TypedArray array)\n        array = arguments[0];\n\n        this.length = array.length;\n        this.byteLength = this.length * this.BYTES_PER_ELEMENT;\n        this.buffer = new ArrayBuffer(this.byteLength);\n        this.byteOffset = 0;\n\n        for (i = 0; i < this.length; i += 1) {\n          this._setter(i, array._getter(i));\n        }\n      } else if (typeof arguments[0] === 'object' &&\n                 !(arguments[0] instanceof ArrayBuffer || ECMAScript.Class(arguments[0]) === 'ArrayBuffer')) {\n        // Constructor(sequence<type> array)\n        sequence = arguments[0];\n\n        this.length = ECMAScript.ToUint32(sequence.length);\n        this.byteLength = this.length * this.BYTES_PER_ELEMENT;\n        this.buffer = new ArrayBuffer(this.byteLength);\n        this.byteOffset = 0;\n\n        for (i = 0; i < this.length; i += 1) {\n          s = sequence[i];\n          this._setter(i, Number(s));\n        }\n      } else if (typeof arguments[0] === 'object' &&\n                 (arguments[0] instanceof ArrayBuffer || ECMAScript.Class(arguments[0]) === 'ArrayBuffer')) {\n        // Constructor(ArrayBuffer buffer,\n        //             optional unsigned long byteOffset, optional unsigned long length)\n        this.buffer = buffer;\n\n        this.byteOffset = ECMAScript.ToUint32(byteOffset);\n        if (this.byteOffset > this.buffer.byteLength) {\n          throw new RangeError(\"byteOffset out of range\");\n        }\n\n        if (this.byteOffset % this.BYTES_PER_ELEMENT) {\n          // The given byteOffset must be a multiple of the element\n          // size of the specific type, otherwise an exception is raised.\n          throw new RangeError(\"ArrayBuffer length minus the byteOffset is not a multiple of the element size.\");\n        }\n\n        if (arguments.length < 3) {\n          this.byteLength = this.buffer.byteLength - this.byteOffset;\n\n          if (this.byteLength % this.BYTES_PER_ELEMENT) {\n            throw new RangeError(\"length of buffer minus byteOffset not a multiple of the element size\");\n          }\n          this.length = this.byteLength / this.BYTES_PER_ELEMENT;\n        } else {\n          this.length = ECMAScript.ToUint32(length);\n          this.byteLength = this.length * this.BYTES_PER_ELEMENT;\n        }\n\n        if ((this.byteOffset + this.byteLength) > this.buffer.byteLength) {\n          throw new RangeError(\"byteOffset and length reference an area beyond the end of the buffer\");\n        }\n      } else {\n        throw new TypeError(\"Unexpected argument type(s)\");\n      }\n\n      this.constructor = ctor;\n\n      configureProperties(this);\n      makeArrayAccessors(this);\n    };\n\n    ctor.prototype = new ArrayBufferView();\n    ctor.prototype.BYTES_PER_ELEMENT = bytesPerElement;\n    ctor.prototype._pack = pack;\n    ctor.prototype._unpack = unpack;\n    ctor.BYTES_PER_ELEMENT = bytesPerElement;\n\n    // getter type (unsigned long index);\n    ctor.prototype._getter = function(index) {\n      if (arguments.length < 1) throw new SyntaxError(\"Not enough arguments\");\n\n      index = ECMAScript.ToUint32(index);\n      if (index >= this.length) {\n        return undefined;\n      }\n\n      var bytes = [], i, o;\n      for (i = 0, o = this.byteOffset + index * this.BYTES_PER_ELEMENT;\n           i < this.BYTES_PER_ELEMENT;\n           i += 1, o += 1) {\n        bytes.push(this.buffer._bytes[o]);\n      }\n      return this._unpack(bytes);\n    };\n\n    // NONSTANDARD: convenience alias for getter: type get(unsigned long index);\n    ctor.prototype.get = ctor.prototype._getter;\n\n    // setter void (unsigned long index, type value);\n    ctor.prototype._setter = function(index, value) {\n      if (arguments.length < 2) throw new SyntaxError(\"Not enough arguments\");\n\n      index = ECMAScript.ToUint32(index);\n      if (index >= this.length) {\n        return undefined;\n      }\n\n      var bytes = this._pack(value), i, o;\n      for (i = 0, o = this.byteOffset + index * this.BYTES_PER_ELEMENT;\n           i < this.BYTES_PER_ELEMENT;\n           i += 1, o += 1) {\n        this.buffer._bytes[o] = bytes[i];\n      }\n    };\n\n    // void set(TypedArray array, optional unsigned long offset);\n    // void set(sequence<type> array, optional unsigned long offset);\n    ctor.prototype.set = function(index, value) {\n      if (arguments.length < 1) throw new SyntaxError(\"Not enough arguments\");\n      var array, sequence, offset, len,\n          i, s, d,\n          byteOffset, byteLength, tmp;\n\n      if (typeof arguments[0] === 'object' && arguments[0].constructor === this.constructor) {\n        // void set(TypedArray array, optional unsigned long offset);\n        array = arguments[0];\n        offset = ECMAScript.ToUint32(arguments[1]);\n\n        if (offset + array.length > this.length) {\n          throw new RangeError(\"Offset plus length of array is out of range\");\n        }\n\n        byteOffset = this.byteOffset + offset * this.BYTES_PER_ELEMENT;\n        byteLength = array.length * this.BYTES_PER_ELEMENT;\n\n        if (array.buffer === this.buffer) {\n          tmp = [];\n          for (i = 0, s = array.byteOffset; i < byteLength; i += 1, s += 1) {\n            tmp[i] = array.buffer._bytes[s];\n          }\n          for (i = 0, d = byteOffset; i < byteLength; i += 1, d += 1) {\n            this.buffer._bytes[d] = tmp[i];\n          }\n        } else {\n          for (i = 0, s = array.byteOffset, d = byteOffset;\n               i < byteLength; i += 1, s += 1, d += 1) {\n            this.buffer._bytes[d] = array.buffer._bytes[s];\n          }\n        }\n      } else if (typeof arguments[0] === 'object' && typeof arguments[0].length !== 'undefined') {\n        // void set(sequence<type> array, optional unsigned long offset);\n        sequence = arguments[0];\n        len = ECMAScript.ToUint32(sequence.length);\n        offset = ECMAScript.ToUint32(arguments[1]);\n\n        if (offset + len > this.length) {\n          throw new RangeError(\"Offset plus length of array is out of range\");\n        }\n\n        for (i = 0; i < len; i += 1) {\n          s = sequence[i];\n          this._setter(offset + i, Number(s));\n        }\n      } else {\n        throw new TypeError(\"Unexpected argument type(s)\");\n      }\n    };\n\n    // TypedArray subarray(long begin, optional long end);\n    ctor.prototype.subarray = function(start, end) {\n      function clamp(v, min, max) { return v < min ? min : v > max ? max : v; }\n\n      start = ECMAScript.ToInt32(start);\n      end = ECMAScript.ToInt32(end);\n\n      if (arguments.length < 1) { start = 0; }\n      if (arguments.length < 2) { end = this.length; }\n\n      if (start < 0) { start = this.length + start; }\n      if (end < 0) { end = this.length + end; }\n\n      start = clamp(start, 0, this.length);\n      end = clamp(end, 0, this.length);\n\n      var len = end - start;\n      if (len < 0) {\n        len = 0;\n      }\n\n      return new this.constructor(\n        this.buffer, this.byteOffset + start * this.BYTES_PER_ELEMENT, len);\n    };\n\n    return ctor;\n  }\n\n  var Int8Array = makeConstructor(1, packI8, unpackI8);\n  var Uint8Array = makeConstructor(1, packU8, unpackU8);\n  var Uint8ClampedArray = makeConstructor(1, packU8Clamped, unpackU8);\n  var Int16Array = makeConstructor(2, packI16, unpackI16);\n  var Uint16Array = makeConstructor(2, packU16, unpackU16);\n  var Int32Array = makeConstructor(4, packI32, unpackI32);\n  var Uint32Array = makeConstructor(4, packU32, unpackU32);\n  var Float32Array = makeConstructor(4, packF32, unpackF32);\n  var Float64Array = makeConstructor(8, packF64, unpackF64);\n\n  exports.Int8Array = exports.Int8Array || Int8Array;\n  exports.Uint8Array = exports.Uint8Array || Uint8Array;\n  exports.Uint8ClampedArray = exports.Uint8ClampedArray || Uint8ClampedArray;\n  exports.Int16Array = exports.Int16Array || Int16Array;\n  exports.Uint16Array = exports.Uint16Array || Uint16Array;\n  exports.Int32Array = exports.Int32Array || Int32Array;\n  exports.Uint32Array = exports.Uint32Array || Uint32Array;\n  exports.Float32Array = exports.Float32Array || Float32Array;\n  exports.Float64Array = exports.Float64Array || Float64Array;\n}());\n\n//\n// 6 The DataView View Type\n//\n\n(function() {\n  function r(array, index) {\n    return ECMAScript.IsCallable(array.get) ? array.get(index) : array[index];\n  }\n\n  var IS_BIG_ENDIAN = (function() {\n    var u16array = new(exports.Uint16Array)([0x1234]),\n        u8array = new(exports.Uint8Array)(u16array.buffer);\n    return r(u8array, 0) === 0x12;\n  }());\n\n  // Constructor(ArrayBuffer buffer,\n  //             optional unsigned long byteOffset,\n  //             optional unsigned long byteLength)\n  /** @constructor */\n  var DataView = function DataView(buffer, byteOffset, byteLength) {\n    if (arguments.length === 0) {\n      buffer = new exports.ArrayBuffer(0);\n    } else if (!(buffer instanceof exports.ArrayBuffer || ECMAScript.Class(buffer) === 'ArrayBuffer')) {\n      throw new TypeError(\"TypeError\");\n    }\n\n    this.buffer = buffer || new exports.ArrayBuffer(0);\n\n    this.byteOffset = ECMAScript.ToUint32(byteOffset);\n    if (this.byteOffset > this.buffer.byteLength) {\n      throw new RangeError(\"byteOffset out of range\");\n    }\n\n    if (arguments.length < 3) {\n      this.byteLength = this.buffer.byteLength - this.byteOffset;\n    } else {\n      this.byteLength = ECMAScript.ToUint32(byteLength);\n    }\n\n    if ((this.byteOffset + this.byteLength) > this.buffer.byteLength) {\n      throw new RangeError(\"byteOffset and length reference an area beyond the end of the buffer\");\n    }\n\n    configureProperties(this);\n  };\n\n  function makeGetter(arrayType) {\n    return function(byteOffset, littleEndian) {\n\n      byteOffset = ECMAScript.ToUint32(byteOffset);\n\n      if (byteOffset + arrayType.BYTES_PER_ELEMENT > this.byteLength) {\n        throw new RangeError(\"Array index out of range\");\n      }\n      byteOffset += this.byteOffset;\n\n      var uint8Array = new exports.Uint8Array(this.buffer, byteOffset, arrayType.BYTES_PER_ELEMENT),\n          bytes = [], i;\n      for (i = 0; i < arrayType.BYTES_PER_ELEMENT; i += 1) {\n        bytes.push(r(uint8Array, i));\n      }\n\n      if (Boolean(littleEndian) === Boolean(IS_BIG_ENDIAN)) {\n        bytes.reverse();\n      }\n\n      return r(new arrayType(new exports.Uint8Array(bytes).buffer), 0);\n    };\n  }\n\n  DataView.prototype.getUint8 = makeGetter(exports.Uint8Array);\n  DataView.prototype.getInt8 = makeGetter(exports.Int8Array);\n  DataView.prototype.getUint16 = makeGetter(exports.Uint16Array);\n  DataView.prototype.getInt16 = makeGetter(exports.Int16Array);\n  DataView.prototype.getUint32 = makeGetter(exports.Uint32Array);\n  DataView.prototype.getInt32 = makeGetter(exports.Int32Array);\n  DataView.prototype.getFloat32 = makeGetter(exports.Float32Array);\n  DataView.prototype.getFloat64 = makeGetter(exports.Float64Array);\n\n  function makeSetter(arrayType) {\n    return function(byteOffset, value, littleEndian) {\n\n      byteOffset = ECMAScript.ToUint32(byteOffset);\n      if (byteOffset + arrayType.BYTES_PER_ELEMENT > this.byteLength) {\n        throw new RangeError(\"Array index out of range\");\n      }\n\n      // Get bytes\n      var typeArray = new arrayType([value]),\n          byteArray = new exports.Uint8Array(typeArray.buffer),\n          bytes = [], i, byteView;\n\n      for (i = 0; i < arrayType.BYTES_PER_ELEMENT; i += 1) {\n        bytes.push(r(byteArray, i));\n      }\n\n      // Flip if necessary\n      if (Boolean(littleEndian) === Boolean(IS_BIG_ENDIAN)) {\n        bytes.reverse();\n      }\n\n      // Write them\n      byteView = new exports.Uint8Array(this.buffer, byteOffset, arrayType.BYTES_PER_ELEMENT);\n      byteView.set(bytes);\n    };\n  }\n\n  DataView.prototype.setUint8 = makeSetter(exports.Uint8Array);\n  DataView.prototype.setInt8 = makeSetter(exports.Int8Array);\n  DataView.prototype.setUint16 = makeSetter(exports.Uint16Array);\n  DataView.prototype.setInt16 = makeSetter(exports.Int16Array);\n  DataView.prototype.setUint32 = makeSetter(exports.Uint32Array);\n  DataView.prototype.setInt32 = makeSetter(exports.Int32Array);\n  DataView.prototype.setFloat32 = makeSetter(exports.Float32Array);\n  DataView.prototype.setFloat64 = makeSetter(exports.Float64Array);\n\n  exports.DataView = exports.DataView || DataView;\n\n}());\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/typedarray/index.js',
          'importMap': {},
          'packageName': 'typedarray',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/typedarray/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/umd/index.js': {
        'moduleRecord': {
          'content': "'use strict';\n\n\nvar templateSTR = \"(function(f){if(typeof exports===\\\"object\\\"&&typeof module!==\\\"undefined\\\"){module.exports=f()}else if(typeof define===\\\"function\\\"&&define.amd){define([],f)}else{var g;if(typeof window!==\\\"undefined\\\"){g=window}else if(typeof global!==\\\"undefined\\\"){g=global}else if(typeof self!==\\\"undefined\\\"){g=self}else{g=this}defineNamespace()}})(function(){source()});\\n\";\n\nfunction template(moduleName, options) {\n  if (typeof options === 'boolean') {\n    options = {commonJS: options};\n  } else if (!options) {\n    options = {};\n  }\n  var str = templateSTR.replace(/defineNamespace\\(\\)/g, compileNamespace(moduleName))\n    .split('source()')\n  str[0] = str[0].trim();\n  //make sure these are undefined so as to not get confused if modules have inner UMD systems\n  str[0] += 'var define,module,exports;';\n  if (options.commonJS) str[0] += 'module={exports:(exports={})};';\n  str[0] += '\\n';\n  if (options.commonJS) str[1] = 'return module.exports;' + str[1];\n  str[1] = '\\n' + str[1];\n  return str;\n}\n\nexports = module.exports = function (name, src, options) {\n  if (typeof options === 'string' && typeof src === 'object') {\n    var tmp = options;\n    options = src;\n    src = tmp;\n  }\n  return exports.prelude(name, options) + src + exports.postlude(name, options);\n};\n\nexports.prelude = function (moduleName, options) {\n  return template(moduleName, options)[0];\n};\nexports.postlude = function (moduleName, options) {\n  return template(moduleName, options)[1];\n};\n\n\nfunction camelCase(name) {\n  name = name.replace(/\\-([a-z])/g, function (_, char) { return char.toUpperCase(); });\n  if (!/^[a-zA-Z_$]$/.test(name[0])) {\n    name = name.substr(1);\n  }\n  var result = name.replace(/[^\\w$]+/g, '')\n  if (!result) {\n    throw new Error('Invalid JavaScript identifier resulted from camel-casing');\n  }\n  return result\n}\n\n\nfunction compileNamespace(name) {\n  var names = name.split('.')\n\n  // No namespaces, yield the best case 'global.NAME = VALUE'\n  if (names.length === 1) {\n    return 'g.' + camelCase(name) + ' = f()';\n\n  // Acceptable case, with reasonable compilation\n  } else if (names.length === 2) {\n    names = names.map(camelCase);\n    return '(g.' + names[0] + ' || (g.' + names[0] + ' = {})).' + names[1] + ' = f()';\n\n  // Worst case, too many namespaces to care about\n  } else {\n    var valueContainer = names.pop()\n    return names.map(compileNamespaceStep)\n                .concat(['g.' + camelCase(valueContainer) + ' = f()'])\n                .join(';');\n  }\n}\n\nfunction compileNamespaceStep(name) {\n  name = camelCase(name);\n  return 'g=(g.' + name + '||(g.' + name + ' = {}))';\n}\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/umd/index.js',
          'importMap': {},
          'packageName': 'umd',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/umd/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/undeclared-identifiers/index.js': {
        'moduleRecord': {
          'content': "var xtend = require('xtend')\nvar acorn = require('acorn-node')\nvar dash = require('dash-ast')\nvar getAssignedIdentifiers = require('get-assigned-identifiers')\n\nfunction visitFunction (node, state, ancestors) {\n  if (node.params.length > 0) {\n    var idents = []\n    for (var i = 0; i < node.params.length; i++) {\n      var sub = getAssignedIdentifiers(node.params[i])\n      for (var j = 0; j < sub.length; j++) idents.push(sub[j])\n    }\n    declareNames(node, idents)\n  }\n  if (node.type === 'FunctionDeclaration') {\n    var parent = getScopeNode(ancestors, 'const')\n    declareNames(parent, [node.id])\n  } else if (node.type === 'FunctionExpression' && node.id) {\n    declareNames(node, [node.id])\n  }\n}\n\nvar scopeVisitor = {\n  VariableDeclaration: function (node, state, ancestors) {\n    var parent = getScopeNode(ancestors, node.kind)\n    for (var i = 0; i < node.declarations.length; i++) {\n      declareNames(parent, getAssignedIdentifiers(node.declarations[i].id))\n    }\n  },\n  FunctionExpression: visitFunction,\n  FunctionDeclaration: visitFunction,\n  ArrowFunctionExpression: visitFunction,\n  ClassDeclaration: function (node, state, ancestors) {\n    var parent = getScopeNode(ancestors, 'const')\n    if (node.id) {\n      declareNames(parent, [node.id])\n    }\n  },\n  ImportDeclaration: function (node, state, ancestors) {\n    declareNames(ancestors[0] /* root */, getAssignedIdentifiers(node))\n  },\n  CatchClause: function (node) {\n    if (node.param) declareNames(node, [node.param])\n  }\n}\n\nvar bindingVisitor = {\n  Identifier: function (node, state, ancestors) {\n    if (!state.identifiers) return\n    var parent = ancestors[ancestors.length - 1]\n    if (parent.type === 'MemberExpression' && parent.property === node) return\n    if (parent.type === 'Property' && !parent.computed && parent.key === node) return\n    if (parent.type === 'MethodDefinition' && !parent.computed && parent.key === node) return\n    if (parent.type === 'LabeledStatement' && parent.label === node) return\n    if (!has(state.undeclared, node.name)) {\n      for (var i = ancestors.length - 1; i >= 0; i--) {\n        if (ancestors[i]._names !== undefined && has(ancestors[i]._names, node.name)) {\n          return\n        }\n      }\n\n      state.undeclared[node.name] = true\n    }\n\n    if (state.wildcard &&\n        !(parent.type === 'MemberExpression' && parent.object === node) &&\n        !(parent.type === 'VariableDeclarator' && parent.id === node) &&\n        !(parent.type === 'AssignmentExpression' && parent.left === node)) {\n      state.undeclaredProps[node.name + '.*'] = true\n    }\n  },\n  MemberExpression: function (node, state) {\n    if (!state.properties) return\n    if (node.object.type === 'Identifier' && has(state.undeclared, node.object.name)) {\n      var prop = !node.computed && node.property.type === 'Identifier'\n        ? node.property.name\n        : node.computed && node.property.type === 'Literal'\n          ? node.property.value\n          : null\n      if (prop) state.undeclaredProps[node.object.name + '.' + prop] = true\n    }\n  }\n}\n\nmodule.exports = function findUndeclared (src, opts) {\n  opts = xtend({\n    identifiers: true,\n    properties: true,\n    wildcard: false\n  }, opts)\n\n  var state = {\n    undeclared: {},\n    undeclaredProps: {},\n    identifiers: opts.identifiers,\n    properties: opts.properties,\n    wildcard: opts.wildcard\n  }\n\n  // Parse if `src` is not already an AST.\n  var ast = typeof src === 'object' && src !== null && typeof src.type === 'string'\n    ? src\n    : acorn.parse(src)\n\n  var parents = []\n  dash(ast, {\n    enter: function (node, parent) {\n      if (parent) parents.push(parent)\n      var visit = scopeVisitor[node.type]\n      if (visit) visit(node, state, parents)\n    },\n    leave: function (node, parent) {\n      var visit = bindingVisitor[node.type]\n      if (visit) visit(node, state, parents)\n      if (parent) parents.pop()\n    }\n  })\n\n  return {\n    identifiers: Object.keys(state.undeclared),\n    properties: Object.keys(state.undeclaredProps)\n  }\n}\n\nfunction getScopeNode (parents, kind) {\n  for (var i = parents.length - 1; i >= 0; i--) {\n    if (parents[i].type === 'FunctionDeclaration' || parents[i].type === 'FunctionExpression' ||\n        parents[i].type === 'ArrowFunctionExpression' || parents[i].type === 'Program') {\n      return parents[i]\n    }\n    if (kind !== 'var' && parents[i].type === 'BlockStatement') {\n      return parents[i]\n    }\n  }\n}\n\nfunction declareNames (node, names) {\n  if (node._names === undefined) {\n    node._names = Object.create(null)\n  }\n  for (var i = 0; i < names.length; i++) {\n    node._names[names[i].name] = true\n  }\n}\n\nfunction has (obj, name) { return Object.prototype.hasOwnProperty.call(obj, name) }\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/undeclared-identifiers/index.js',
          'importMap': {
            'acorn-node': '/home/xyz/Development/webtorrent/node_modules/acorn-node/index.js',
            'dash-ast': '/home/xyz/Development/webtorrent/node_modules/dash-ast/index.js',
            'get-assigned-identifiers': '/home/xyz/Development/webtorrent/node_modules/get-assigned-identifiers/index.js',
            'xtend': '/home/xyz/Development/webtorrent/node_modules/xtend/immutable.js',
          },
          'packageName': 'undeclared-identifiers',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/undeclared-identifiers/index.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/util-deprecate/node.js': {
        'builtin': [
          'util.deprecate',
        ],
        'moduleRecord': {
          'content': "\n/**\n * For Node.js, simply re-export the core `util.deprecate` function.\n */\n\nmodule.exports = require('util').deprecate;\n",
          'file': '/home/xyz/Development/webtorrent/node_modules/util-deprecate/node.js',
          'importMap': {
            'util': 'util',
          },
          'packageName': 'util-deprecate',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/util-deprecate/node.js',
          'type': 'js',
        },
      },
      '/home/xyz/Development/webtorrent/node_modules/xtend/immutable.js': {
        'moduleRecord': {
          'content': 'module.exports = extend\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\nfunction extend() {\n    var target = {}\n\n    for (var i = 0; i < arguments.length; i++) {\n        var source = arguments[i]\n\n        for (var key in source) {\n            if (hasOwnProperty.call(source, key)) {\n                target[key] = source[key]\n            }\n        }\n    }\n\n    return target\n}\n',
          'file': '/home/xyz/Development/webtorrent/node_modules/xtend/immutable.js',
          'importMap': {},
          'packageName': 'xtend',
          'specifier': '/home/xyz/Development/webtorrent/node_modules/xtend/immutable.js',
          'type': 'js',
        },
      },
    },
    'resources': {
      'JSONStream': {
        'globals': {
          'Buffer': true,
        },
        'packages': {
          'jsonparse': true,
          'through': true,
        },
      },
      'acorn': {
        'globals': {
          'BigInt': true,
          'define': true,
        },
      },
      'acorn-node': {
        'globals': {
          'BigInt': true,
        },
        'packages': {
          'acorn': true,
          'acorn-walk': true,
          'xtend': true,
        },
      },
      'acorn-walk': {
        'globals': {
          'define': true,
        },
      },
      'browser-pack': {
        'builtin': {
          'fs.readFileSync': true,
          'path.join': true,
          'path.relative': true,
        },
        'globals': {
          '__dirname': true,
          'process.cwd': true,
        },
        'packages': {
          'JSONStream': true,
          'combine-source-map': true,
          'defined': true,
          'safe-buffer': true,
          'through2': true,
          'umd': true,
        },
      },
      'browser-resolve': {
        'builtin': {
          'fs.readFile': true,
          'fs.readFileSync': true,
          'path': true,
        },
        'globals': {
          '__dirname': true,
          'process.platform': true,
        },
        'packages': {
          'resolve': true,
        },
      },
      'browserify': {
        'builtin': {
          'events.EventEmitter': true,
          'fs.realpath': true,
          'path.dirname': true,
          'path.join': true,
          'path.relative': true,
          'path.resolve': true,
          'path.sep': true,
        },
        'globals': {
          '__dirname': true,
          'process.cwd': true,
          'process.nextTick': true,
          'process.platform': true,
        },
        'packages': {
          'browser-pack': true,
          'browser-resolve': true,
          'cached-path-relative': true,
          'concat-stream': true,
          'defined': true,
          'deps-sort': true,
          'has': true,
          'htmlescape': true,
          'inherits': true,
          'insert-module-globals': true,
          'labeled-stream-splicer': true,
          'module-deps': true,
          'read-only-stream': true,
          'resolve': true,
          'shasum-object': true,
          'syntax-error': true,
          'through2': true,
          'xtend': true,
        },
      },
      'browserify-package-json': {
        'builtin': {
          'stream.PassThrough': true,
          'stream.Transform': true,
        },
      },
      'buffer-from': {
        'globals': {
          'Buffer': true,
        },
      },
      'cached-path-relative': {
        'builtin': {
          'path': true,
        },
        'globals': {
          'process.cwd': true,
        },
      },
      'combine-source-map': {
        'builtin': {
          'path.dirname': true,
          'path.join': true,
        },
        'globals': {
          'process.platform': true,
        },
        'packages': {
          'convert-source-map': true,
          'inline-source-map': true,
          'lodash.memoize': true,
          'source-map': true,
        },
      },
      'concat-stream': {
        'globals': {
          'Buffer.concat': true,
          'Buffer.isBuffer': true,
        },
        'packages': {
          'buffer-from': true,
          'inherits': true,
          'readable-stream': true,
          'typedarray': true,
        },
      },
      'convert-source-map': {
        'builtin': {
          'fs.readFileSync': true,
          'path.join': true,
        },
        'globals': {
          'Buffer': true,
        },
      },
      'core-util-is': {
        'globals': {
          'Buffer.isBuffer': true,
        },
      },
      'dash-ast': {
        'builtin': {
          'assert': true,
        },
      },
      'deps-sort': {
        'packages': {
          'shasum-object': true,
          'through2': true,
        },
      },
      'detective': {
        'packages': {
          'acorn-node': true,
          'defined': true,
        },
      },
      'duplexer2': {
        'packages': {
          'readable-stream': true,
        },
      },
      'get-assigned-identifiers': {
        'builtin': {
          'assert.equal': true,
        },
      },
      'has': {
        'packages': {
          'function-bind': true,
        },
      },
      'inherits': {
        'builtin': {
          'util.inherits': true,
        },
      },
      'inline-source-map': {
        'globals': {
          'Buffer': true,
        },
        'packages': {
          'source-map': true,
        },
      },
      'insert-module-globals': {
        'builtin': {
          'path.dirname': true,
          'path.isAbsolute': true,
          'path.relative': true,
          'path.sep': true,
        },
        'globals': {
          'Buffer.concat': true,
          'Buffer.isBuffer': true,
        },
        'packages': {
          'acorn-node': true,
          'combine-source-map': true,
          'path-is-absolute': true,
          'through2': true,
          'undeclared-identifiers': true,
          'xtend': true,
        },
      },
      'is-core-module': {
        'globals': {
          'process.versions': true,
        },
        'packages': {
          'has': true,
        },
      },
      'jsonparse': {
        'globals': {
          'Buffer': true,
        },
      },
      'labeled-stream-splicer': {
        'packages': {
          'inherits': true,
          'stream-splicer': true,
        },
      },
      'module-deps': {
        'builtin': {
          'fs.createReadStream': true,
          'fs.readFile': true,
          'path.delimiter': true,
          'path.dirname': true,
          'path.join': true,
          'path.resolve': true,
        },
        'globals': {
          'process.cwd': true,
          'process.env.NODE_PATH': true,
          'process.nextTick': true,
          'process.platform': true,
          'setTimeout': true,
          'tr': true,
        },
        'packages': {
          'browser-resolve': true,
          'cached-path-relative': true,
          'concat-stream': true,
          'defined': true,
          'detective': true,
          'duplexer2': true,
          'inherits': true,
          'parents': true,
          'readable-stream': true,
          'resolve': true,
          'stream-combiner2': true,
          'through2': true,
          'xtend': true,
        },
      },
      'package-json-versionify': {
        'packages': {
          'browserify-package-json': true,
        },
      },
      'parents': {
        'globals': {
          'process.cwd': true,
          'process.platform': true,
        },
        'packages': {
          'path-platform': true,
        },
      },
      'path-is-absolute': {
        'globals': {
          'process.platform': true,
        },
      },
      'path-parse': {
        'globals': {
          'process.platform': true,
        },
      },
      'path-platform': {
        'builtin': {
          'path': true,
          'util.isObject': true,
          'util.isString': true,
        },
        'globals': {
          'process.cwd': true,
          'process.env': true,
          'process.platform': true,
        },
      },
      'process-nextick-args': {
        'globals': {
          'process': true,
        },
      },
      'read-only-stream': {
        'packages': {
          'readable-stream': true,
        },
      },
      'readable-stream': {
        'builtin': {
          'events.EventEmitter': true,
          'stream': true,
          'util': true,
        },
        'globals': {
          'process.browser': true,
          'process.env.READABLE_STREAM': true,
          'process.stderr': true,
          'process.stdout': true,
          'process.version.slice': true,
          'setImmediate': true,
        },
        'packages': {
          'core-util-is': true,
          'inherits': true,
          'isarray': true,
          'process-nextick-args': true,
          'safe-buffer': true,
          'string_decoder': true,
          'util-deprecate': true,
        },
      },
      'resolve': {
        'builtin': {
          'fs.readFile': true,
          'fs.readFileSync': true,
          'fs.realpath': true,
          'fs.realpathSync': true,
          'fs.stat': true,
          'fs.statSync': true,
          'path.dirname': true,
          'path.join': true,
          'path.parse': true,
          'path.relative': true,
          'path.resolve': true,
        },
        'globals': {
          'process.nextTick': true,
          'process.platform': true,
          'process.versions': true,
        },
        'packages': {
          'is-core-module': true,
          'path-parse': true,
        },
      },
      'safe-buffer': {
        'builtin': {
          'buffer': true,
        },
      },
      'shasum-object': {
        'builtin': {
          'crypto.createHash': true,
        },
        'globals': {
          'Buffer.isBuffer': true,
        },
        'packages': {
          'fast-safe-stringify': true,
        },
      },
      'stream-combiner2': {
        'packages': {
          'duplexer2': true,
          'readable-stream': true,
        },
      },
      'stream-splicer': {
        'globals': {
          'process.nextTick': true,
          'setImmediate': true,
        },
        'packages': {
          'inherits': true,
          'readable-stream': true,
        },
      },
      'string_decoder': {
        'packages': {
          'safe-buffer': true,
        },
      },
      'syntax-error': {
        'packages': {
          'acorn-node': true,
        },
      },
      'through': {
        'builtin': {
          'stream': true,
        },
        'globals': {
          'process.nextTick': true,
        },
      },
      'through2': {
        'builtin': {
          'util.inherits': true,
        },
        'globals': {
          'process.nextTick': true,
        },
        'packages': {
          'readable-stream': true,
          'xtend': true,
        },
      },
      'undeclared-identifiers': {
        'packages': {
          'acorn-node': true,
          'dash-ast': true,
          'get-assigned-identifiers': true,
          'xtend': true,
        },
      },
      'util-deprecate': {
        'builtin': {
          'util.deprecate': true,
        },
      },
    },
  },
}
